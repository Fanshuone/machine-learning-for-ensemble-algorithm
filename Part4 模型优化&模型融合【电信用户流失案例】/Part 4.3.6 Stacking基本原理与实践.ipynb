{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e987d01e-5757-4485-90eb-2594121ffb0d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# <center> 【Kaggle】Telco Customer Churn 电信用户流失预测案例"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ada6a5-40ef-4ac5-8e26-6e6c66912388",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d53101-e876-48af-9b8b-fdd24970c706",
   "metadata": {},
   "source": [
    "## <font face=\"仿宋\">第四部分导读"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84aa4a8-6284-43f5-b820-f5c1450921a9",
   "metadata": {},
   "source": [
    "&emsp;&emsp;<font face=\"仿宋\">在案例的第二、三部分中，我们详细介绍了关于特征工程的各项技术，特征工程技术按照大类来分可以分为数据预处理、特征衍生、特征筛选三部分，其中特征预处理的目的是为了将数据集整理、清洗到可以建模的程度，具体技术包括缺失值处理、异常值处理、数据重编码等，是建模之前必须对数据进行的处理和操作；而特征衍生和特征筛选则更像是一类优化手段，能够帮助模型突破当前数据集建模的效果上界。并且我们在第二部分完整详细的介绍机器学习可解释性模型的训练、优化和解释方法，也就是逻辑回归和决策树模型。并且此前我们也一直以这两种算法为主，来进行各个部分的模型测试。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59420105-1a1c-45eb-bbb7-a44505a5439c",
   "metadata": {},
   "source": [
    "&emsp;&emsp;<font face=\"仿宋\">而第四部分，我们将开始介绍集成学习的训练和优化的实战技巧，尽管从可解释性角度来说，集成学习的可解释性并不如逻辑回归和决策树，但在大多数建模场景下，集成学习都将获得一个更好的预测结果，这也是目前效果优先的建模场景下最常使用的算法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278d8117-2312-4ffb-b5df-3c6abef65bd2",
   "metadata": {},
   "source": [
    "&emsp;&emsp;<font face=\"仿宋\">总的来说，本部分内容只有一个目标，那就是借助各类优化方法，抵达每个主流集成学习的效果上界。换而言之，本部分我们将围绕单模优化策略展开详细的探讨，涉及到的具体集成学习包括随机森林、XGBoost、LightGBM、和CatBoost等目前最主流的集成学习算法，而具体的优化策略则包括超参数优化器的使用、特征衍生和筛选方法的使用、单模型自融合方法的使用，这些优化方法也是截至目前，提升单模效果最前沿、最有效、同时也是最复杂的方法。其中有很多较为艰深的理论，也有很多是经验之谈，但无论如何，我们希望能够围绕当前数据集，让每个集成学习算法优化到极限。值得注意的是，在这个过程中，我们会将此前介绍的特征衍生和特征筛选视作是一种模型优化方法，衍生和筛选的效果，一律以模型的最终结果来进行评定。而围绕集成学习进行海量特征衍生和筛选，也才是特征衍生和筛选技术能发挥巨大价值的主战场。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fba1585-83d7-43c6-a4a7-107efc85d90b",
   "metadata": {},
   "source": [
    "&emsp;&emsp;<font face=\"仿宋\">而在抵达了单模的极限后，我们就会进入到下一阶段，也就是模型融合阶段。需要知道的是，只有单模的效果到达了极限，进一步的多模型融合、甚至多层融合，才是有意义的，才是有效果的。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69661022-b4a1-47c1-a9bd-117839d2b35b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62131f8-7c2c-42c0-90ee-f5f1cedae00e",
   "metadata": {},
   "source": [
    "# <center>Part 4.集成算法的训练与优化技巧"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abadc0dc-e6bf-4f03-95c9-71749be9ccc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 基础数据科学运算库\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 可视化库\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 时间模块\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# sklearn库\n",
    "# 数据预处理\n",
    "from sklearn import preprocessing\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# 实用函数\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 常用评估器\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 网格搜索\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 自定义评估器支持模块\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, ClassifierMixin\n",
    "\n",
    "# 自定义模块\n",
    "from telcoFunc import *\n",
    "# 导入特征衍生模块\n",
    "import features_creation as fc\n",
    "from features_creation import *\n",
    "\n",
    "# re模块相关\n",
    "import inspect, re\n",
    "\n",
    "# 其他模块\n",
    "from tqdm import tqdm\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9cea10-6c46-448a-89fe-1ef17f500bcd",
   "metadata": {},
   "source": [
    "&emsp;&emsp;然后执行Part 1中的数据清洗相关工作："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a229323-f851-41ba-a031-f212bfa9ef24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "tcc = pd.read_csv('WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
    "\n",
    "# 标注连续/离散字段\n",
    "# 离散字段\n",
    "category_cols = ['gender', 'SeniorCitizen', 'Partner', 'Dependents',\n",
    "                'PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', \n",
    "                'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling',\n",
    "                'PaymentMethod']\n",
    "\n",
    "# 连续字段\n",
    "numeric_cols = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
    " \n",
    "# 标签\n",
    "target = 'Churn'\n",
    "\n",
    "# ID列\n",
    "ID_col = 'customerID'\n",
    "\n",
    "# 验证是否划分能完全\n",
    "assert len(category_cols) + len(numeric_cols) + 2 == tcc.shape[1]\n",
    "\n",
    "# 连续字段转化\n",
    "tcc['TotalCharges']= tcc['TotalCharges'].apply(lambda x: x if x!= ' ' else np.nan).astype(float)\n",
    "tcc['MonthlyCharges'] = tcc['MonthlyCharges'].astype(float)\n",
    "\n",
    "# 缺失值填补\n",
    "tcc['TotalCharges'] = tcc['TotalCharges'].fillna(0)\n",
    "\n",
    "# 标签值手动转化 \n",
    "tcc['Churn'].replace(to_replace='Yes', value=1, inplace=True)\n",
    "tcc['Churn'].replace(to_replace='No',  value=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2d7e992-a8ec-43ca-bf06-d40c2508ef9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = tcc.drop(columns=[ID_col, target]).copy()\n",
    "labels = tcc['Churn'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ef555c-3c24-43a4-91ed-9a38b7071966",
   "metadata": {},
   "source": [
    "&emsp;&emsp;同时，创建自然编码后的数据集以及经过时序特征衍生的数据集："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a17ae8b-70ce-4e41-a4c6-57f545605487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分训练集和测试集\n",
    "train, test = train_test_split(tcc, random_state=22)\n",
    "\n",
    "X_train = train.drop(columns=[ID_col, target]).copy()\n",
    "X_test = test.drop(columns=[ID_col, target]).copy()\n",
    "\n",
    "y_train = train['Churn'].copy()\n",
    "y_test = test['Churn'].copy()\n",
    "\n",
    "X_train_seq = pd.DataFrame()\n",
    "X_test_seq = pd.DataFrame()\n",
    "\n",
    "# 年份衍生\n",
    "X_train_seq['tenure_year'] = ((72 - X_train['tenure']) // 12) + 2014\n",
    "X_test_seq['tenure_year'] = ((72 - X_test['tenure']) // 12) + 2014\n",
    "\n",
    "# 月份衍生\n",
    "X_train_seq['tenure_month'] = (72 - X_train['tenure']) % 12 + 1\n",
    "X_test_seq['tenure_month'] = (72 - X_test['tenure']) % 12 + 1\n",
    "\n",
    "# 季度衍生\n",
    "X_train_seq['tenure_quarter'] = ((X_train_seq['tenure_month']-1) // 3) + 1\n",
    "X_test_seq['tenure_quarter'] = ((X_test_seq['tenure_month']-1) // 3) + 1\n",
    "\n",
    "# 独热编码\n",
    "enc = preprocessing.OneHotEncoder()\n",
    "enc.fit(X_train_seq)\n",
    "\n",
    "seq_new = list(X_train_seq.columns)\n",
    "\n",
    "# 创建带有列名称的独热编码之后的df\n",
    "X_train_seq = pd.DataFrame(enc.transform(X_train_seq).toarray(), \n",
    "                           columns = cate_colName(enc, seq_new, drop=None))\n",
    "\n",
    "X_test_seq = pd.DataFrame(enc.transform(X_test_seq).toarray(), \n",
    "                          columns = cate_colName(enc, seq_new, drop=None))\n",
    "\n",
    "# 调整index\n",
    "X_train_seq.index = X_train.index\n",
    "X_test_seq.index = X_test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "300b7a2b-8771-45a7-8f17-63e4ab4d58e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ord_enc = OrdinalEncoder()\n",
    "ord_enc.fit(X_train[category_cols])\n",
    "\n",
    "X_train_OE = pd.DataFrame(ord_enc.transform(X_train[category_cols]), columns=category_cols)\n",
    "X_train_OE.index = X_train.index\n",
    "X_train_OE = pd.concat([X_train_OE, X_train[numeric_cols]], axis=1)\n",
    "\n",
    "X_test_OE = pd.DataFrame(ord_enc.transform(X_test[category_cols]), columns=category_cols)\n",
    "X_test_OE.index = X_test.index\n",
    "X_test_OE = pd.concat([X_test_OE, X_test[numeric_cols]], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86c4cbd-70b9-414b-aa3c-d5ecd2347168",
   "metadata": {},
   "source": [
    "然后是模型融合部分所需的第三方库、准备的数据以及训练好的模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a726f66c-9e76-4a76-84a6-c6e3f5e29f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 本节新增第三方库\n",
    "from joblib import dump, load\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from hyperopt import hp, fmin, tpe\n",
    "from numpy.random import RandomState\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72872795-f559-4f30-9ee7-135fb9adc44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VotingClassifier_threshold(BaseEstimator, ClassifierMixin, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, estimators, voting='hard', weights=None, thr=0.5):\n",
    "        self.estimators = estimators\n",
    "        self.voting = voting\n",
    "        self.weights = weights\n",
    "        self.thr = thr\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        VC = VotingClassifier(estimators = self.estimators, \n",
    "                              voting = self.voting, \n",
    "                              weights = self.weights)\n",
    "        \n",
    "        VC.fit(X, y)\n",
    "        self.clf = VC\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    def predict_proba(self, X):\n",
    "        if self.voting == 'soft':\n",
    "            res_proba = self.clf.predict_proba(X)\n",
    "        else:\n",
    "            res_proba = None\n",
    "        return res_proba\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if self.voting == 'soft':\n",
    "            res = (self.clf.predict_proba(X)[:, 1] >= self.thr) * 1\n",
    "        else:\n",
    "            res = self.clf.predict(X)\n",
    "        return res\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        acc = accuracy_score(self.predict(X), y)\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b19c7745-531a-4009-b21e-8c4ee5685274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实例化KFold评估器\n",
    "kf = KFold(n_splits=5, random_state=12, shuffle=True)\n",
    "\n",
    "# 重置训练集和测试集的index\n",
    "X_train_OE = X_train_OE.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "\n",
    "train_part_index_l = []\n",
    "eval_index_l = []\n",
    "\n",
    "for train_part_index, eval_index in kf.split(X_train_OE, y_train):\n",
    "    train_part_index_l.append(train_part_index)\n",
    "    eval_index_l.append(eval_index)\n",
    "    \n",
    "# 训练集特征\n",
    "X_train1 = X_train_OE.loc[train_part_index_l[0]]\n",
    "X_train2 = X_train_OE.loc[train_part_index_l[1]]\n",
    "X_train3 = X_train_OE.loc[train_part_index_l[2]]\n",
    "X_train4 = X_train_OE.loc[train_part_index_l[3]]\n",
    "X_train5 = X_train_OE.loc[train_part_index_l[4]]\n",
    "\n",
    "# 验证集特征\n",
    "X_eval1 = X_train_OE.loc[eval_index_l[0]]\n",
    "X_eval2 = X_train_OE.loc[eval_index_l[1]]\n",
    "X_eval3 = X_train_OE.loc[eval_index_l[2]]\n",
    "X_eval4 = X_train_OE.loc[eval_index_l[3]]\n",
    "X_eval5 = X_train_OE.loc[eval_index_l[4]]\n",
    "\n",
    "# 训练集标签\n",
    "y_train1 = y_train.loc[train_part_index_l[0]]\n",
    "y_train2 = y_train.loc[train_part_index_l[1]]\n",
    "y_train3 = y_train.loc[train_part_index_l[2]]\n",
    "y_train4 = y_train.loc[train_part_index_l[3]]\n",
    "y_train5 = y_train.loc[train_part_index_l[4]]\n",
    "\n",
    "# 验证集标签\n",
    "y_eval1 = y_train.loc[eval_index_l[0]]\n",
    "y_eval2 = y_train.loc[eval_index_l[1]]\n",
    "y_eval3 = y_train.loc[eval_index_l[2]]\n",
    "y_eval4 = y_train.loc[eval_index_l[3]]\n",
    "y_eval5 = y_train.loc[eval_index_l[4]]\n",
    "\n",
    "train_set = [(X_train1, y_train1), \n",
    "             (X_train2, y_train2), \n",
    "             (X_train3, y_train3), \n",
    "             (X_train4, y_train4), \n",
    "             (X_train5, y_train5)]\n",
    "\n",
    "eval_set = [(X_eval1, y_eval1), \n",
    "            (X_eval2, y_eval2), \n",
    "            (X_eval3, y_eval3), \n",
    "            (X_eval4, y_eval4), \n",
    "            (X_eval5, y_eval5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbd45133-6e80-4442-b108-fa5154bb823b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 随机森林模型组\n",
    "grid_RF_1 = load('./models/grid_RF_1.joblib') \n",
    "grid_RF_2 = load('./models/grid_RF_2.joblib') \n",
    "grid_RF_3 = load('./models/grid_RF_3.joblib') \n",
    "grid_RF_4 = load('./models/grid_RF_4.joblib') \n",
    "grid_RF_5 = load('./models/grid_RF_5.joblib') \n",
    "\n",
    "RF_1 = grid_RF_1.best_estimator_\n",
    "RF_2 = grid_RF_2.best_estimator_\n",
    "RF_3 = grid_RF_3.best_estimator_\n",
    "RF_4 = grid_RF_4.best_estimator_\n",
    "RF_5 = grid_RF_5.best_estimator_\n",
    "\n",
    "RF_l = [RF_1, RF_2, RF_3, RF_4, RF_5]\n",
    "\n",
    "# 决策树模型组\n",
    "grid_tree_1 = load('./models/grid_tree_1.joblib')\n",
    "grid_tree_2 = load('./models/grid_tree_2.joblib')\n",
    "grid_tree_3 = load('./models/grid_tree_3.joblib')\n",
    "grid_tree_4 = load('./models/grid_tree_4.joblib')\n",
    "grid_tree_5 = load('./models/grid_tree_5.joblib')\n",
    "\n",
    "tree_1 = grid_tree_1.best_estimator_\n",
    "tree_2 = grid_tree_2.best_estimator_\n",
    "tree_3 = grid_tree_3.best_estimator_\n",
    "tree_4 = grid_tree_4.best_estimator_\n",
    "tree_5 = grid_tree_5.best_estimator_\n",
    "\n",
    "tree_l = [tree_1, tree_2, tree_3, tree_4, tree_5]\n",
    "\n",
    "# 逻辑回归模型组\n",
    "grid_lr_1 = load('./models/grid_lr_1.joblib')\n",
    "grid_lr_2 = load('./models/grid_lr_2.joblib')\n",
    "grid_lr_3 = load('./models/grid_lr_3.joblib')\n",
    "grid_lr_4 = load('./models/grid_lr_4.joblib')\n",
    "grid_lr_5 = load('./models/grid_lr_5.joblib')\n",
    "\n",
    "lr_1 = grid_lr_1.best_estimator_\n",
    "lr_2 = grid_lr_2.best_estimator_\n",
    "lr_3 = grid_lr_3.best_estimator_\n",
    "lr_4 = grid_lr_4.best_estimator_\n",
    "lr_5 = grid_lr_5.best_estimator_\n",
    "\n",
    "lr_l = [lr_1, lr_2, lr_3, lr_4, lr_5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca608cdf-5166-4147-8917-53c62daafa08",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval1_predict_proba_RF = pd.Series(RF_l[0].predict_proba(X_eval1)[:, 1], index=X_eval1.index)\n",
    "eval2_predict_proba_RF = pd.Series(RF_l[1].predict_proba(X_eval2)[:, 1], index=X_eval2.index)\n",
    "eval3_predict_proba_RF = pd.Series(RF_l[2].predict_proba(X_eval3)[:, 1], index=X_eval3.index)\n",
    "eval4_predict_proba_RF = pd.Series(RF_l[3].predict_proba(X_eval4)[:, 1], index=X_eval4.index)\n",
    "eval5_predict_proba_RF = pd.Series(RF_l[4].predict_proba(X_eval5)[:, 1], index=X_eval5.index)\n",
    "\n",
    "eval_predict_proba_RF = pd.concat([eval1_predict_proba_RF, \n",
    "                                   eval2_predict_proba_RF, \n",
    "                                   eval3_predict_proba_RF, \n",
    "                                   eval4_predict_proba_RF, \n",
    "                                   eval5_predict_proba_RF]).sort_index()\n",
    "\n",
    "eval1_predict_proba_tree = pd.Series(tree_l[0].predict_proba(X_eval1)[:, 1], index=X_eval1.index)\n",
    "eval2_predict_proba_tree = pd.Series(tree_l[1].predict_proba(X_eval2)[:, 1], index=X_eval2.index)\n",
    "eval3_predict_proba_tree = pd.Series(tree_l[2].predict_proba(X_eval3)[:, 1], index=X_eval3.index)\n",
    "eval4_predict_proba_tree = pd.Series(tree_l[3].predict_proba(X_eval4)[:, 1], index=X_eval4.index)\n",
    "eval5_predict_proba_tree = pd.Series(tree_l[4].predict_proba(X_eval5)[:, 1], index=X_eval5.index)\n",
    "\n",
    "eval_predict_proba_tree = pd.concat([eval1_predict_proba_tree, \n",
    "                                     eval2_predict_proba_tree, \n",
    "                                     eval3_predict_proba_tree, \n",
    "                                     eval4_predict_proba_tree, \n",
    "                                     eval5_predict_proba_tree]).sort_index()\n",
    "\n",
    "eval1_predict_proba_lr = pd.Series(lr_l[0].predict_proba(X_eval1)[:, 1], index=X_eval1.index)\n",
    "eval2_predict_proba_lr = pd.Series(lr_l[1].predict_proba(X_eval2)[:, 1], index=X_eval2.index)\n",
    "eval3_predict_proba_lr = pd.Series(lr_l[2].predict_proba(X_eval3)[:, 1], index=X_eval3.index)\n",
    "eval4_predict_proba_lr = pd.Series(lr_l[3].predict_proba(X_eval4)[:, 1], index=X_eval4.index)\n",
    "eval5_predict_proba_lr = pd.Series(lr_l[4].predict_proba(X_eval5)[:, 1], index=X_eval5.index)\n",
    "\n",
    "eval_predict_proba_lr = pd.concat([eval1_predict_proba_lr, \n",
    "                                   eval2_predict_proba_lr, \n",
    "                                   eval3_predict_proba_lr, \n",
    "                                   eval4_predict_proba_lr, \n",
    "                                   eval5_predict_proba_lr]).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2fce404-462e-45ff-82ff-6d8862ad5237",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict_proba_RF = []\n",
    "\n",
    "for i in range(5):\n",
    "    test_predict_proba_RF.append(RF_l[i].predict_proba(X_test_OE)[:, 1])\n",
    "\n",
    "test_predict_proba_RF = np.array(test_predict_proba_RF)\n",
    "test_predict_proba_RF = test_predict_proba_RF.mean(0)\n",
    "\n",
    "test_predict_proba_tree = []\n",
    "\n",
    "for i in range(5):\n",
    "    test_predict_proba_tree.append(tree_l[i].predict_proba(X_test_OE)[:, 1])\n",
    "\n",
    "test_predict_proba_tree = np.array(test_predict_proba_tree)\n",
    "test_predict_proba_tree = test_predict_proba_tree.mean(0)\n",
    "\n",
    "test_predict_proba_lr = []\n",
    "\n",
    "for i in range(5):\n",
    "    test_predict_proba_lr.append(lr_l[i].predict_proba(X_test_OE)[:, 1])\n",
    "\n",
    "test_predict_proba_lr = np.array(test_predict_proba_lr)\n",
    "test_predict_proba_lr = test_predict_proba_lr.mean(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1ec465-7729-4de6-909e-a9597e9629c1",
   "metadata": {},
   "source": [
    "## <center>Ch.3 模型融合基础方法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51c8912-7bcb-4b01-8075-3c01fd47e694",
   "metadata": {},
   "source": [
    "## 七、Stacking基本原理与实践"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c00e90-7ca0-44f0-9606-a3a3750c0663",
   "metadata": {},
   "source": [
    "- Stacking方法模型融合方法快速尝试"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40c5ec7-fa24-4863-9e49-9b83000ed8ec",
   "metadata": {},
   "source": [
    "&emsp;&emsp;在介绍完Voting和Averaging融合方法类之后，接下来还有一大类模型融合方法，也就是所谓的学习结合器类方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d29aa28-4923-4047-ba36-1236decfa52d",
   "metadata": {},
   "source": [
    "&emsp;&emsp;在Part 4.3.3的最后一部分，即围绕加权平均融合过程中，权重阈值的超参数搜索过程所遇到的过拟合问题，我们详细的讨论了相关解决方案，其中提出了一种用更加严谨的模型代替权重搜索这一解决问题的思路，其基本过程如下："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2505a76d-c1cf-42bd-9ca1-564389c22cac",
   "metadata": {},
   "source": [
    "<center><img src=\"https://s2.loli.net/2022/05/22/eGR4Cl3dsFDpAES.png\" alt=\"image-20220522174140320\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4213566-e65e-4fc4-ba72-a3dfee2a8583",
   "metadata": {},
   "source": [
    "实际上，在加权平均融合的过程中，我们是通过一个加权平均过程，配合阈值来完成融合，而该融合的本质，其实就是围绕单模输出结果（连续变量，每个样本预测为1的概率），来拟合预测标签（0-1二分类变量），因此其本质上就是一个分类问题，除了搜索权重和阈值外，我们也完全可以用机器学习的分类模型来完成这一预测过程。这里我们可以先迅速尝试使用逻辑回归模型来完成这一预测过程。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7a0300-a038-4981-8fa2-6e84c66d7e41",
   "metadata": {},
   "source": [
    "&emsp;&emsp;首先还是围绕我们训练好的三个模型，输出在训练集上的概率预测结果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03d7a28c-68ab-4dad-bc2d-1fe8c4d58b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取模型\n",
    "logistic_search = load('./models/logistic_search.joblib') \n",
    "tree_model = load('./models/tree_model.joblib') \n",
    "RF_0 = load('./models/RF_0.joblib') \n",
    "\n",
    "# 训练集上的预测概率(预测为1的概率)\n",
    "train_prediction1_proba = logistic_search.best_estimator_.predict_proba(X_train_OE)[:, 1]\n",
    "train_prediction2_proba = tree_model.predict_proba(X_train_OE)[:, 1]\n",
    "train_prediction3_proba = RF_0.predict_proba(X_train_OE)[:, 1]\n",
    "\n",
    "# 测试集上的预测概率\n",
    "test_prediction1_proba = logistic_search.best_estimator_.predict_proba(X_test_OE)[:, 1]\n",
    "test_prediction2_proba = tree_model.predict_proba(X_test_OE)[:, 1]\n",
    "test_prediction3_proba = RF_0.predict_proba(X_test_OE)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "365d2dac-e203-456f-91f2-765898956a1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01069583, 0.56348576, 0.14572695, ..., 0.67546702, 0.05388848,\n",
       "       0.00465571])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_prediction1_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bb6e1d-f3fe-4b8b-8e65-05c4d3579221",
   "metadata": {},
   "source": [
    "然后，以三个模型输出的概率预测结果作为训练数据，原数据集标签作为标签，进行逻辑回归模型训练。首先对原始的模型输出的概率结果进行拼接："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed1f23a7-09ef-4823-9b42-d03c6da76696",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stack = np.vstack([[train_prediction1_proba], \n",
    "                         [train_prediction2_proba], \n",
    "                         [train_prediction3_proba]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f15be057-8136-4a72-9a3a-3de849ceb43f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01069583, 0.02375297, 0.00672967],\n",
       "       [0.56348576, 0.74912281, 0.51874357],\n",
       "       [0.14572695, 0.22331155, 0.10493285],\n",
       "       ...,\n",
       "       [0.67546702, 0.45586298, 0.60729472],\n",
       "       [0.05388848, 0.11384335, 0.0156605 ],\n",
       "       [0.00465571, 0.02375297, 0.00535636]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26182a71-dbd1-4855-a96c-2b1ff8a89bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stack = np.vstack([[test_prediction1_proba], \n",
    "                        [test_prediction2_proba], \n",
    "                        [test_prediction3_proba]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "216319f4-f5c9-49b4-a2df-e402303e464b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03485521, 0.02375297, 0.01044425],\n",
       "       [0.2346808 , 0.11384335, 0.32168142],\n",
       "       [0.00547175, 0.02375297, 0.00523215],\n",
       "       ...,\n",
       "       [0.13542354, 0.11384335, 0.15824046],\n",
       "       [0.50080841, 0.45586298, 0.59381813],\n",
       "       [0.06614044, 0.11384335, 0.10725971]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b062ff31-2820-4bfa-a675-243bea8e3ce2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "5277    0\n",
       "5278    0\n",
       "5279    1\n",
       "5280    0\n",
       "5281    0\n",
       "Name: Churn, Length: 5282, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6b0136-0fe8-427f-9b06-00cd5a8bd366",
   "metadata": {},
   "source": [
    "然后带入模型进行训练，并输出准确率评分结果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd096e17-6b15-4988-b119-604a3ffbb93e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8782658084059068, 0.7898921067575241)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_final = LogisticRegression().fit(train_stack, y_train)\n",
    "lr_final.score(train_stack, y_train), lr_final.score(test_stack, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1c883a-c0a1-4e92-b93c-e070a740a4be",
   "metadata": {},
   "source": [
    "能够发现，逻辑回归模型能够顺利输出最终预测结果，模型融合能够顺利进行，而这种融合方法则被称为Stacking模型融合，该方法也是目前最为重要的一类模型融合方法，同时也是所谓学习结合器中效果最好的一类方法。当然，和其他模型融合方法类似，该方法在初次尝试的时候也遇到明显的过拟合现象，接下来，我们从更加严谨的角度介绍Stacking模型融合方法的基本原理，以及Stacking模型融合方法的优化策略。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51eb251d-34a9-49ed-9ed7-fc53bb226355",
   "metadata": {},
   "source": [
    "### 1.Stacking模型融合基本原理与手动实现"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8be730-d49d-41e2-88c6-53089f8cc091",
   "metadata": {},
   "source": [
    "&emsp;&emsp;和投票法&平局法类似，Stacking方法本质上也是一类结合方法，并与1992年由Wolpert等人提出，并在此后的数十年间不断完善与迭代，并且，该方法提出的核心目的同样也是为了有效结合多个弱学习器组成一个更强的学习器，但是，和投票法&平均法不同的是，Stacking是希望通过训练一个模型（而非找到某种加权平均的过程），来完成结合这一过程，在这个过程中，原始的个体学习器也被称为一级学习器，而结合过程用到的模型，则被称为二级学习器，或者元学习器。例如上述快速Stacking实践过程中，原始训练好的随机森林、逻辑回归和决策树三个模型就是一级学习器，而用于结合的逻辑回归模型则被称为元学习器（meta learner）。很明显，这是一种简单的双层级架构，而这种层级结构也就是Stacking（堆叠）名称的由来。Stacking中中元学习的训练和预测过程如下："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6dec52-57d6-419b-8dfa-a3f79d448eee",
   "metadata": {},
   "source": [
    "<center><img src=\"http://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20220919215031456.png\" alt=\"image-20220522174140320\" style=\"zoom:50%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3255265f-ce37-4a48-8d3c-d1f53c27adb7",
   "metadata": {},
   "source": [
    "> 有时元学习器也被称为final model（最终学习器）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae43551-7d21-4240-b407-171298fe4a46",
   "metadata": {},
   "source": [
    "&emsp;&emsp;当然，和其他结合方法一样，Stacking等学习结合器也有非常完整的基础理论，但同样，由于一级模型无法保证其独立性，因此大多数理论并不能很好的指导Stacking模型融合过程。此处我们先从中挑选部分有用的结论进行介绍，然后更多的从当前实践情况出发，介绍如何围绕Stacking融合过程进行优化。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f63fa3-dc66-40ca-a8c4-bc72df43dfca",
   "metadata": {},
   "source": [
    "- Stacking与Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d4c2d7-07cd-4cfa-9dd4-c8a7ccaa42d2",
   "metadata": {},
   "source": [
    "&emsp;&emsp;如果说投票法&均值法和Bagging的集成过程一致，那么Stacking则和Boosting算法有着千丝万缕的联系。从技术衍化发展角度来说，Stacking是Boosting的前身，Stacking为Boosting集成范式提供了非常多的基础理论支撑，可以说，正是由于Stacking方法的发明，才有了后续Boosting算法的突破；而从算法原理角度来说，Stacking和Boosting本质也是类似，Stacking也可以看成是是堆叠多层学习器，并通过不断拟合误差来提升效果。只不过相比之下Stacking作为结合方法，其过程会相对简单，适用的模型也更加广泛，而Boosting则是严谨的集成范式，只能借助某些某型来构建某种集成算法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5172cb93-3538-4812-aa02-24f40f4ff6e8",
   "metadata": {},
   "source": [
    "- 一级学习器的同质或异质性"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26b35cf-cf67-4246-83e3-781a13fdedb2",
   "metadata": {},
   "source": [
    "&emsp;&emsp;根据Stacking的基本原理，一级学习器可以是相同的一组模型，此时便称一级学习器是同质的，反之，如果一级学习器是不同的模型，则称其为异质的。根据Stacking基本原理描述，一级学习器的同质或异质并不是影响Stacking结果的核心因素，但是，在一级学习器不独立的情况下，经过长期实践发现，异质的一级学习器要明显好于同质的一级学习器。因此，在实际建模过程中，更建议训练异质学习器。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b285c1-18bd-44ed-a23a-805fa0ebfe0c",
   "metadata": {},
   "source": [
    "- Stacking分类和回归"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4827265a-4967-498f-aed9-540b3ddb3ea0",
   "metadata": {},
   "source": [
    "&emsp;&emsp;和其他模型融合方法一样，Stacking也同样可以处理回归问题或分类问题，只需要合理选择元学习器即可。例如，处理分类问题时，元学习器也对应选择分类问题模型，例如逻辑回归、分类树等；而处理回归问题时，元学习器则可以选择线性回归、贝叶斯回归、回归树等模型。当前案例是分类问题，我们将首先重点介绍分类问题的Stacking过程，后续还会有回归案例的讲解，届时将继续介绍Stacking解决回归问题的过程。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6de1635-7f8e-4410-91ef-f0a97f8a8a02",
   "metadata": {},
   "source": [
    "&emsp;&emsp;此外，更多的关于Stacking元学习器如何选择与优化，也将在后续Stacking优化部分内容一并讨论。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b39ec95-5f06-4240-9756-f25faafc4e1d",
   "metadata": {},
   "source": [
    "- Stacking过程中的“硬投票”或者“软投票”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47b4eba-6887-4985-93e4-69a5c66e983d",
   "metadata": {},
   "source": [
    "&emsp;&emsp;其实，除了如上述代码展示的，可以带入一级学习器的概率预测结果到元学习器中参与训练（类似于软投票的过程），我们还可以以一级学习器输出的类别预测结果作为特征，带入到元学习器中进行训练（类似于硬投票的过程）。不过需要注意的是，无论是Stacking的相关理论（Ting & Witten[1999]），还是长期的实践征明，带入概率预测结果进行元学习器训练，不进行任何优化的情况下，和Stacking“软投票”效果不分伯仲，而如果带入某些优化方法（后续会介绍），则Stacking“软投票”效果会好很多。这里我们简单尝试Stacking“硬投票”："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a819b3af-be05-4fe3-92a4-8d56a28ba0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练集上的预测结果\n",
    "train_prediction1 = logistic_search.best_estimator_.predict(X_train_OE)\n",
    "train_prediction2 = tree_model.predict(X_train_OE)\n",
    "train_prediction3 = RF_0.predict(X_train_OE)\n",
    "\n",
    "# 测试集上的预测结果\n",
    "test_prediction1 = logistic_search.best_estimator_.predict(X_test_OE)\n",
    "test_prediction2 = tree_model.predict(X_test_OE)\n",
    "test_prediction3 = RF_0.predict(X_test_OE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b1272f4-b306-4940-a954-b9ad3b338a31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 1, 0, 0])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_prediction1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d94a8725-9167-4c5e-ad6b-5ee6ef1030df",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stack_hard = np.vstack([[train_prediction1], \n",
    "                              [train_prediction2], \n",
    "                              [train_prediction3]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1d8ddfb6-fdb2-4276-87c4-27416d4fe3c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0],\n",
       "       [1, 1, 1],\n",
       "       [0, 0, 0],\n",
       "       ...,\n",
       "       [1, 0, 1],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stack_hard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2951db0c-1905-415d-be98-c07de1bda864",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stack_hard = np.vstack([[test_prediction1], \n",
    "                             [test_prediction2], \n",
    "                             [test_prediction3]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d02c0e4e-bafe-465e-ba2b-1bcaca48015c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0],\n",
       "       [1, 0, 1],\n",
       "       [0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_stack_hard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "720eee44-7bf3-4573-b02e-9bfb2dc189e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8483528966300644, 0.7955706984667802)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_final = LogisticRegression().fit(train_stack_hard, y_train)\n",
    "lr_final.score(train_stack_hard, y_train), lr_final.score(test_stack_hard, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b54d67-5d83-4337-a862-710d9a63b0e2",
   "metadata": {},
   "source": [
    "能够发现，目前Stacking“硬投票”效果略好于“软投票”效果。但需要注意，当我们围绕Stacking过程进行优化时，限于“硬投票”的特征数值表现有限，Stacking“硬投票”效果将明显不如Stacking“软投票”过程，这点和加权平均融合过程类似。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ec57dc-b232-48f3-9445-222f256595e3",
   "metadata": {},
   "source": [
    "> 当然，对于回归问题，并不会存在Stacking的“硬投票”过程，此时一级学习器输出的都是连续变量。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e3cc60-c308-497f-aec7-323c2ea02c0f",
   "metadata": {},
   "source": [
    "&emsp;&emsp;并且，我们不难发现，无论是带入类别预测结果还是概率结果，元学习器最终都表现出了一定程度的过拟合。这当然也是Stacking“理论缺陷”必然导致的结果，而如何优化，则是在执行整个Stacking融合过程中最核心的问题。在此前的模型融合的过程中，我们已经介绍了非常多优化策略，不过截至目前，能适用于Stacking融合过程的只有交叉训练这一种方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded306f2-47e6-4333-879a-d2e3b7d52e04",
   "metadata": {},
   "source": [
    "- Stacking一级学习器的交叉训练过程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d755bef-efac-4a11-a3ea-9bbd82e51eeb",
   "metadata": {},
   "source": [
    "&emsp;&emsp;在介绍更多Stacking优化方法之前，我们先探讨如何借助交叉训练来抑制Stacking过拟合。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0fd6f9-5e0f-4c16-930c-a037f2933a09",
   "metadata": {},
   "source": [
    "&emsp;&emsp;实际上，早在1998年，Smyth & Wolpert等人就从理论角度提出，交叉训练能够有效提升元学习器的泛化能力，其实相比投票法&均值法，交叉训练更像是为Stacking融合过程量身定制的方法，时至今日，交叉训练更是已经成为Stacking过程的“标配”，包括sklearn在内的各机器学习算法库，也是将Stacking模型融合与交叉训练捆绑在一起来进行实现，以提升Stacking效果。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd00148-865e-4478-9f87-edcaaec4ef87",
   "metadata": {},
   "source": [
    "&emsp;&emsp;在Part 4.3.4中，我们已经详细介绍了交叉训练过程，而在Stacking中调用交叉训练过程只会影响元学习器特征（train_stack & test_stack）创建过程：即不再是简单输出训练集上概率预测结果作为训练集和测试集特征，而是用验证集拼接后的数据集作为train_stack，而用测试集的平均概率预测结果作为test_stack。以五折随机森林模型交叉训练为例，该过程创建的某条特征（注意是一个模型创建一个特征）过程如下："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa093520-3387-4c1d-8ed1-3075376cc64c",
   "metadata": {},
   "source": [
    "<center><img src=\"http://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20220920160449348.png\" alt=\"image-20220920160449348\" style=\"zoom:50%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e49363-d9f1-4201-b918-e0a66bb2fe9c",
   "metadata": {},
   "source": [
    "其中具体的代码实现过程在Part 4.3.4中有详细介绍，此处不做赘述，目前我们创建的eval_predict_proba_RF对象就是上图中的train_stack_RF，而test_predict_proba_RF则是上图中的test_stack_RF。而三个模型分别交叉训练得到的特征，拼接而成的数据集，就将是最终用于训练元学习器的数据集train_stack:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "233c2e0e-5a59-4633-8e02-075f55614b7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.044787\n",
       "1       0.572187\n",
       "2       0.161815\n",
       "3       0.250871\n",
       "4       0.122533\n",
       "          ...   \n",
       "5277    0.082653\n",
       "5278    0.346562\n",
       "5279    0.551481\n",
       "5280    0.049011\n",
       "5281    0.002783\n",
       "Length: 5282, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_predict_proba_RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "596d8105-8d2f-495c-8895-03e084338d58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_stack_RF</th>\n",
       "      <th>train_stack_lr</th>\n",
       "      <th>train_stack_tree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.044787</td>\n",
       "      <td>0.011289</td>\n",
       "      <td>0.037669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.572187</td>\n",
       "      <td>0.542331</td>\n",
       "      <td>0.787986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.161815</td>\n",
       "      <td>0.154121</td>\n",
       "      <td>0.222819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.250871</td>\n",
       "      <td>0.273393</td>\n",
       "      <td>0.259434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.122533</td>\n",
       "      <td>0.158399</td>\n",
       "      <td>0.107345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5277</th>\n",
       "      <td>0.082653</td>\n",
       "      <td>0.083575</td>\n",
       "      <td>0.062959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5278</th>\n",
       "      <td>0.346562</td>\n",
       "      <td>0.365228</td>\n",
       "      <td>0.222819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5279</th>\n",
       "      <td>0.551481</td>\n",
       "      <td>0.674365</td>\n",
       "      <td>0.438538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5280</th>\n",
       "      <td>0.049011</td>\n",
       "      <td>0.050536</td>\n",
       "      <td>0.066419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5281</th>\n",
       "      <td>0.002783</td>\n",
       "      <td>0.005250</td>\n",
       "      <td>0.026367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5282 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      train_stack_RF  train_stack_lr  train_stack_tree\n",
       "0           0.044787        0.011289          0.037669\n",
       "1           0.572187        0.542331          0.787986\n",
       "2           0.161815        0.154121          0.222819\n",
       "3           0.250871        0.273393          0.259434\n",
       "4           0.122533        0.158399          0.107345\n",
       "...              ...             ...               ...\n",
       "5277        0.082653        0.083575          0.062959\n",
       "5278        0.346562        0.365228          0.222819\n",
       "5279        0.551481        0.674365          0.438538\n",
       "5280        0.049011        0.050536          0.066419\n",
       "5281        0.002783        0.005250          0.026367\n",
       "\n",
       "[5282 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 元学习器训练集\n",
    "train_stack = pd.DataFrame({'train_stack_RF': eval_predict_proba_RF, \n",
    "                            'train_stack_lr': eval_predict_proba_lr, \n",
    "                            'train_stack_tree': eval_predict_proba_tree})\n",
    "\n",
    "train_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b884f207-0b04-4f39-adfd-f4f341c30303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_stack_RF</th>\n",
       "      <th>test_stack_lr</th>\n",
       "      <th>test_stack_tree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.029220</td>\n",
       "      <td>0.045946</td>\n",
       "      <td>0.046473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.311980</td>\n",
       "      <td>0.233711</td>\n",
       "      <td>0.158900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.016244</td>\n",
       "      <td>0.005192</td>\n",
       "      <td>0.046473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.025769</td>\n",
       "      <td>0.035878</td>\n",
       "      <td>0.046473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.035476</td>\n",
       "      <td>0.056142</td>\n",
       "      <td>0.051573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1756</th>\n",
       "      <td>0.193367</td>\n",
       "      <td>0.169545</td>\n",
       "      <td>0.212513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1757</th>\n",
       "      <td>0.048821</td>\n",
       "      <td>0.040112</td>\n",
       "      <td>0.046473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1758</th>\n",
       "      <td>0.145346</td>\n",
       "      <td>0.125325</td>\n",
       "      <td>0.158900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1759</th>\n",
       "      <td>0.530686</td>\n",
       "      <td>0.501991</td>\n",
       "      <td>0.437401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1760</th>\n",
       "      <td>0.106832</td>\n",
       "      <td>0.062787</td>\n",
       "      <td>0.130399</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1761 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      test_stack_RF  test_stack_lr  test_stack_tree\n",
       "0          0.029220       0.045946         0.046473\n",
       "1          0.311980       0.233711         0.158900\n",
       "2          0.016244       0.005192         0.046473\n",
       "3          0.025769       0.035878         0.046473\n",
       "4          0.035476       0.056142         0.051573\n",
       "...             ...            ...              ...\n",
       "1756       0.193367       0.169545         0.212513\n",
       "1757       0.048821       0.040112         0.046473\n",
       "1758       0.145346       0.125325         0.158900\n",
       "1759       0.530686       0.501991         0.437401\n",
       "1760       0.106832       0.062787         0.130399\n",
       "\n",
       "[1761 rows x 3 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 元学习器测试集\n",
    "test_stack = pd.DataFrame({'test_stack_RF': test_predict_proba_RF, \n",
    "                           'test_stack_lr': test_predict_proba_lr, \n",
    "                           'test_stack_tree': test_predict_proba_tree})\n",
    "\n",
    "test_stack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ba7e9b-fe1e-438c-a1b7-72a26d58f61a",
   "metadata": {},
   "source": [
    "接下来尝试带入训练元学习器："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f3bbfa9d-4d27-4bcf-92ae-2ea07b42e316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8178720181749337, 0.7955706984667802)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_final = LogisticRegression().fit(train_stack, y_train)\n",
    "lr_final.score(train_stack, y_train), lr_final.score(test_stack, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffff969-7aa2-496e-bde7-5550a5b3bf25",
   "metadata": {},
   "source": [
    "能够发现，模型过拟合现象得到了有效抑制。不难理解，对于Stacking来说，同样是因为交叉训练能够非常好的做到信息隔离，从而能够一定程度提高元学习的泛化能力。在没借助其他优化方法的情况下，Stacking能够有如此效果，也足见Stacking过程本身的威力。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fe69d9-e74a-4b75-ac67-0c15f34f35c5",
   "metadata": {},
   "source": [
    "> 注，不同模型验证集拼接成的训练集很多时候也被标注为oof，意为out-of-fold predictions，验证集预测结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512b6581-9a44-4d30-8062-30a3b095aa54",
   "metadata": {},
   "source": [
    "至此，我们就完整实现的手动Stacking的全过程。接下来我们进一步介绍如何借助sklearn来进行Stacking模型融合。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6341bf-9c69-4693-a084-8caa60d57f14",
   "metadata": {},
   "source": [
    "### 2.Stacking模型融合的sklearn实现过程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc03f5a5-ca15-474b-9cad-afb35c35437a",
   "metadata": {},
   "source": [
    "#### 2.1 评估器参数介绍与调用过程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84892ba0-72f0-4071-9afd-335e9fa2337a",
   "metadata": {},
   "source": [
    "&emsp;&emsp;自0.22版本开始，sklearn也集成了Stacking模型融合相关功能，并支持自动交叉训练和“软硬投票”等各种功能。这里首先导入分类问题的Stacking融合评估器："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "77171dea-3548-45b9-bc28-8d0f29c5fbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bf55826e-1aa7-44f5-97a1-fb80803a1986",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m\n",
       "\u001b[0mStackingClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mestimators\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mfinal_estimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mstack_method\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'auto'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mpassthrough\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m     \n",
       "Stack of estimators with a final classifier.\n",
       "\n",
       "Stacked generalization consists in stacking the output of individual\n",
       "estimator and use a classifier to compute the final prediction. Stacking\n",
       "allows to use the strength of each individual estimator by using their\n",
       "output as input of a final estimator.\n",
       "\n",
       "Note that `estimators_` are fitted on the full `X` while `final_estimator_`\n",
       "is trained using cross-validated predictions of the base estimators using\n",
       "`cross_val_predict`.\n",
       "\n",
       "Read more in the :ref:`User Guide <stacking>`.\n",
       "\n",
       ".. versionadded:: 0.22\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "estimators : list of (str, estimator)\n",
       "    Base estimators which will be stacked together. Each element of the\n",
       "    list is defined as a tuple of string (i.e. name) and an estimator\n",
       "    instance. An estimator can be set to 'drop' using `set_params`.\n",
       "\n",
       "final_estimator : estimator, default=None\n",
       "    A classifier which will be used to combine the base estimators.\n",
       "    The default classifier is a\n",
       "    :class:`~sklearn.linear_model.LogisticRegression`.\n",
       "\n",
       "cv : int, cross-validation generator or an iterable, default=None\n",
       "    Determines the cross-validation splitting strategy used in\n",
       "    `cross_val_predict` to train `final_estimator`. Possible inputs for\n",
       "    cv are:\n",
       "\n",
       "    * None, to use the default 5-fold cross validation,\n",
       "    * integer, to specify the number of folds in a (Stratified) KFold,\n",
       "    * An object to be used as a cross-validation generator,\n",
       "    * An iterable yielding train, test splits.\n",
       "\n",
       "    For integer/None inputs, if the estimator is a classifier and y is\n",
       "    either binary or multiclass,\n",
       "    :class:`~sklearn.model_selection.StratifiedKFold` is used.\n",
       "    In all other cases, :class:`~sklearn.model_selection.KFold` is used.\n",
       "    These splitters are instantiated with `shuffle=False` so the splits\n",
       "    will be the same across calls.\n",
       "\n",
       "    Refer :ref:`User Guide <cross_validation>` for the various\n",
       "    cross-validation strategies that can be used here.\n",
       "\n",
       "    .. note::\n",
       "       A larger number of split will provide no benefits if the number\n",
       "       of training samples is large enough. Indeed, the training time\n",
       "       will increase. ``cv`` is not used for model evaluation but for\n",
       "       prediction.\n",
       "\n",
       "stack_method : {'auto', 'predict_proba', 'decision_function', 'predict'},             default='auto'\n",
       "    Methods called for each base estimator. It can be:\n",
       "\n",
       "    * if 'auto', it will try to invoke, for each estimator,\n",
       "      `'predict_proba'`, `'decision_function'` or `'predict'` in that\n",
       "      order.\n",
       "    * otherwise, one of `'predict_proba'`, `'decision_function'` or\n",
       "      `'predict'`. If the method is not implemented by the estimator, it\n",
       "      will raise an error.\n",
       "\n",
       "n_jobs : int, default=None\n",
       "    The number of jobs to run in parallel all `estimators` `fit`.\n",
       "    `None` means 1 unless in a `joblib.parallel_backend` context. -1 means\n",
       "    using all processors. See Glossary for more details.\n",
       "\n",
       "passthrough : bool, default=False\n",
       "    When False, only the predictions of estimators will be used as\n",
       "    training data for `final_estimator`. When True, the\n",
       "    `final_estimator` is trained on the predictions as well as the\n",
       "    original training data.\n",
       "\n",
       "verbose : int, default=0\n",
       "    Verbosity level.\n",
       "\n",
       "Attributes\n",
       "----------\n",
       "classes_ : ndarray of shape (n_classes,)\n",
       "    Class labels.\n",
       "\n",
       "estimators_ : list of estimators\n",
       "    The elements of the estimators parameter, having been fitted on the\n",
       "    training data. If an estimator has been set to `'drop'`, it\n",
       "    will not appear in `estimators_`.\n",
       "\n",
       "named_estimators_ : :class:`~sklearn.utils.Bunch`\n",
       "    Attribute to access any fitted sub-estimators by name.\n",
       "\n",
       "n_features_in_ : int\n",
       "    Number of features seen during :term:`fit`. Only defined if the\n",
       "    underlying classifier exposes such an attribute when fit.\n",
       "\n",
       "    .. versionadded:: 0.24\n",
       "\n",
       "feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
       "    Names of features seen during :term:`fit`. Only defined if the\n",
       "    underlying estimators expose such an attribute when fit.\n",
       "    .. versionadded:: 1.0\n",
       "\n",
       "final_estimator_ : estimator\n",
       "    The classifier which predicts given the output of `estimators_`.\n",
       "\n",
       "stack_method_ : list of str\n",
       "    The method used by each base estimator.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "StackingRegressor : Stack of estimators with a final regressor.\n",
       "\n",
       "Notes\n",
       "-----\n",
       "When `predict_proba` is used by each estimator (i.e. most of the time for\n",
       "`stack_method='auto'` or specifically for `stack_method='predict_proba'`),\n",
       "The first column predicted by each estimator will be dropped in the case\n",
       "of a binary classification problem. Indeed, both feature will be perfectly\n",
       "collinear.\n",
       "\n",
       "References\n",
       "----------\n",
       ".. [1] Wolpert, David H. \"Stacked generalization.\" Neural networks 5.2\n",
       "   (1992): 241-259.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> from sklearn.datasets import load_iris\n",
       ">>> from sklearn.ensemble import RandomForestClassifier\n",
       ">>> from sklearn.svm import LinearSVC\n",
       ">>> from sklearn.linear_model import LogisticRegression\n",
       ">>> from sklearn.preprocessing import StandardScaler\n",
       ">>> from sklearn.pipeline import make_pipeline\n",
       ">>> from sklearn.ensemble import StackingClassifier\n",
       ">>> X, y = load_iris(return_X_y=True)\n",
       ">>> estimators = [\n",
       "...     ('rf', RandomForestClassifier(n_estimators=10, random_state=42)),\n",
       "...     ('svr', make_pipeline(StandardScaler(),\n",
       "...                           LinearSVC(random_state=42)))\n",
       "... ]\n",
       ">>> clf = StackingClassifier(\n",
       "...     estimators=estimators, final_estimator=LogisticRegression()\n",
       "... )\n",
       ">>> from sklearn.model_selection import train_test_split\n",
       ">>> X_train, X_test, y_train, y_test = train_test_split(\n",
       "...     X, y, stratify=y, random_state=42\n",
       "... )\n",
       ">>> clf.fit(X_train, y_train).score(X_test, y_test)\n",
       "0.9...\n",
       "\u001b[1;31mFile:\u001b[0m           c:\\users\\vdmion\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_stacking.py\n",
       "\u001b[1;31mType:\u001b[0m           ABCMeta\n",
       "\u001b[1;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "StackingClassifier?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05415f7-417e-41be-b267-5530893f3ce5",
   "metadata": {},
   "source": [
    "该评估器的核心参数解释如下："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b2d468-23cf-41de-9560-7514fc2a3fb6",
   "metadata": {
    "tags": []
   },
   "source": [
    "|参数|解释|\n",
    "|:--:|:--:|\n",
    "|estimators|一级评估器|\n",
    "|final_estimator|二级评估器，默认是逻辑回归|\n",
    "|cv|一级评估器基交叉训练折数|\n",
    "|stack_method|选择概率结果还是类别结果进行元学习器的训练|\n",
    "|passthrough|是否额外带入原始数据特征进行元学习器的训练|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22dab9d3-4fa4-4740-95a5-a286efbc1d8f",
   "metadata": {},
   "source": [
    "其中estimators参数结构和投票法评估器结构一致，都是需要创建一个由（模型名称、模型）所组成的一个列表。例如，当我们采用逻辑回归、决策树和随机森林三个模型进行Stacking模型融合时，estimators应该按照如下格式进行创建："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "180dd958-1743-4ab4-90df-11c658e114b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [('lr', logistic_search.best_estimator_), ('tree', tree_model), ('rf', RF_0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5110717-9cf0-4dff-b082-c42b3c9d403c",
   "metadata": {},
   "source": [
    "而final_estimator就是元学习器，只需要实例化一个sklearn中的评估器即可；CV就是一级评估器交叉训练的折数，默认是五折。        \n",
    "&emsp;&emsp;stack_method则可以选择元学习器的训练数据类型，可选'auto'、'predict_proba'、'decision_function'、'predict'四个不同取值。当输入'predict_proba'时，即带入样本类别概率进行训练，而'decision_function'则是SVM特殊的一种模型输出结果，代表样本到分割超平面的（置信）距离，同样也可以充当类似概率的作用，距离越短，则模型判断越不肯定（相当于概率越趋近于0.5），而'predict'则是样本类别结果，相当于是Stacking“硬投票”，在默认情况下，参数选择为'aotu'，即根据不同模型，按照'predict_proba'>'decision_function'>'predict'的优先级进行参数选择。当然，对于逻辑回归、决策树和随机森林来说，参数输入aotu时就是根据预测概率训练元学习器。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13bf7fd-80e6-4d29-b637-6f296f12b4dd",
   "metadata": {},
   "source": [
    "> 同时，根据sklearn的相关说明，当stack_method选择'predict_proba'时，元学习器会带入预测为1的概率进行计算，这一点和手动实现过程完全一致。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00978e9-fd9e-401f-adb4-9cf871251a67",
   "metadata": {},
   "source": [
    "&emsp;&emsp;最后一个参数passthrough，也是最为特殊的一个参数，那就是是否额外带入原始数据集特征进行元学习器训练，默认参数是False：只带入一级学习器的预测结果训练元学习器。但当我们选择参数为True时，会拼凑一个由一级学习器输出结果和原始特征共同拼接而成的数据集，用于元学习器的训练。该操作本质上其实是一种特征增强方法，常常用于层级堆叠结构的模型训练过程，包括某些Boosting、深度森林的级联训练等，都有可能用到特征增强技术。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff4f8ec-4962-4648-b689-456189c45cde",
   "metadata": {},
   "source": [
    "&emsp;&emsp;但是，特征增强本身是一项较为复杂的技术，其实现过程非常灵活，可以在一个堆叠的模型结构的任意层增加任意任意特征，甚至是衍生特征，但目前来看，除了深度森林和Blending（一种模型融合方法）给出了明确的能提升效果的特征增强方法外，其他场景的特征增强方法效果都不确定，也就是说需要反复多次尝试，来找到可能能提升效果的特征增强方法。基于此，sklearn的Stacking评估器中passthrough参数取值，也是需要多加尝试的，并非一定带入或者不带入原始数据集特征就能获得更好的效果。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1083d7-4730-42d5-a977-ed470db23e80",
   "metadata": {},
   "source": [
    "&emsp;&emsp;更多关于特征增强的相关方法介绍，我们将在模型融合部分内容结束后详细讨论。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cde6ef8-b459-4555-9cfd-98e130a73545",
   "metadata": {},
   "source": [
    "- Stacking评估器调用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bcfb3e-77a8-4407-89f9-c60efba378ce",
   "metadata": {},
   "source": [
    "&emsp;&emsp;接下来，我们尝试调用sklearn中Stacking评估器来执行模型融合："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c5257269-f383-4755-b4c6-2418eedbe00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实例化Stacking评估器\n",
    "# 元学习器选择逻辑回归模型，这也是默认参数\n",
    "clf = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2f476865-56a7-4e9d-a692-ab3b774c9f3e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingClassifier(estimators=[('lr',\n",
       "                                Pipeline(steps=[('columntransformer',\n",
       "                                                 ColumnTransformer(transformers=[('cat',\n",
       "                                                                                  OneHotEncoder(drop='if_binary'),\n",
       "                                                                                  ['gender',\n",
       "                                                                                   'SeniorCitizen',\n",
       "                                                                                   'Partner',\n",
       "                                                                                   'Dependents',\n",
       "                                                                                   'PhoneService',\n",
       "                                                                                   'MultipleLines',\n",
       "                                                                                   'InternetService',\n",
       "                                                                                   'OnlineSecurity',\n",
       "                                                                                   'OnlineBackup',\n",
       "                                                                                   'DeviceProtection',\n",
       "                                                                                   'TechSupport',\n",
       "                                                                                   'StreamingTV',\n",
       "                                                                                   'StreamingMovies',\n",
       "                                                                                   'Contract'...\n",
       "                                                 logit_threshold(C=0.30000000000000004,\n",
       "                                                                 max_iter=100000000,\n",
       "                                                                 penalty='l1',\n",
       "                                                                 solver='saga'))])),\n",
       "                               ('tree',\n",
       "                                DecisionTreeClassifier(ccp_alpha=0, max_depth=5,\n",
       "                                                       max_leaf_nodes=8,\n",
       "                                                       random_state=12)),\n",
       "                               ('rf',\n",
       "                                RandomForestClassifier(max_depth=10,\n",
       "                                                       max_features='sqrt',\n",
       "                                                       max_samples=2000,\n",
       "                                                       min_samples_leaf=2,\n",
       "                                                       min_samples_split=7,\n",
       "                                                       n_estimators=97,\n",
       "                                                       random_state=12))],\n",
       "                   final_estimator=LogisticRegression())"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train_OE, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f26195-7162-4302-8ad6-b2e14f137f70",
   "metadata": {},
   "source": [
    "对于Stacking评估器，我们也可以非常方便的查看一级、二级学习器的基本情况："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0643a857-93c8-4ac3-880a-942d77c107b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lr',\n",
       "  Pipeline(steps=[('columntransformer',\n",
       "                   ColumnTransformer(transformers=[('cat',\n",
       "                                                    OneHotEncoder(drop='if_binary'),\n",
       "                                                    ['gender', 'SeniorCitizen',\n",
       "                                                     'Partner', 'Dependents',\n",
       "                                                     'PhoneService',\n",
       "                                                     'MultipleLines',\n",
       "                                                     'InternetService',\n",
       "                                                     'OnlineSecurity',\n",
       "                                                     'OnlineBackup',\n",
       "                                                     'DeviceProtection',\n",
       "                                                     'TechSupport', 'StreamingTV',\n",
       "                                                     'StreamingMovies',\n",
       "                                                     'Contract',\n",
       "                                                     'PaperlessBilling',\n",
       "                                                     'PaymentMethod']),\n",
       "                                                   ('num', StandardScaler(),\n",
       "                                                    ['tenure', 'MonthlyCharges',\n",
       "                                                     'TotalCharges'])])),\n",
       "                  ('logit_threshold',\n",
       "                   logit_threshold(C=0.30000000000000004, max_iter=100000000,\n",
       "                                   penalty='l1', solver='saga'))])),\n",
       " ('tree',\n",
       "  DecisionTreeClassifier(ccp_alpha=0, max_depth=5, max_leaf_nodes=8,\n",
       "                         random_state=12)),\n",
       " ('rf',\n",
       "  RandomForestClassifier(max_depth=10, max_features='sqrt', max_samples=2000,\n",
       "                         min_samples_leaf=2, min_samples_split=7, n_estimators=97,\n",
       "                         random_state=12))]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 一级学习器\n",
    "clf.estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3fb5221d-1e81-48ef-8036-9039ace3b562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('tree',\n",
       " DecisionTreeClassifier(ccp_alpha=0, max_depth=5, max_leaf_nodes=8,\n",
       "                        random_state=12))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.estimators[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c710ebb7-f26d-4fae-b17e-202333c15b3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 二级学习器调用\n",
    "clf.final_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6e51b929-55a3-4c6c-9068-ee2ddd918f7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'class_weight': None,\n",
       " 'dual': False,\n",
       " 'fit_intercept': True,\n",
       " 'intercept_scaling': 1,\n",
       " 'l1_ratio': None,\n",
       " 'max_iter': 100,\n",
       " 'multi_class': 'auto',\n",
       " 'n_jobs': None,\n",
       " 'penalty': 'l2',\n",
       " 'random_state': None,\n",
       " 'solver': 'lbfgs',\n",
       " 'tol': 0.0001,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看训练完成后二级学习器的参数\n",
    "clf.final_estimator.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3840ff8-ae33-4796-9332-77b8669aa2fd",
   "metadata": {},
   "source": [
    "以及其他的一些关键参数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4140fc53-738e-4f67-94a8-baecd12fa9d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'auto'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.stack_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ac4b4726-c457-4b99-8d27-91c74204720d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.passthrough"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9093251b-3aa6-49ff-bd2f-82cb6ff4a2b7",
   "metadata": {},
   "source": [
    "然后查看模型融合性能："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ab9f1bd7-179c-4fcb-8ec3-f80d630cef7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8273381294964028, 0.787052810902896)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_train_OE, y_train), clf.score(X_test_OE, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011087dc-ca19-4778-a749-6b0f255f0792",
   "metadata": {},
   "source": [
    "能够发现，尽管都是5折交叉训练，尽管都是默认参数的逻辑回归作为元学习器，尽管都是相同的一级学习器，Stacking评估器的性能要弱于手动实现的Stacking过程。这是为什么呢？究其原因还是因为Stacking评估器中训练的多组模型，每一组模型的超参数是固定的，并不能像手动实现过程那样非常精细的去给每一组的每一个模型进行超参数优化。很明显，每一组模型共用一组超参数，还是会一定程度影响融合性能。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5121d0bf-fafd-46b3-b35c-219d160d4930",
   "metadata": {},
   "source": [
    "&emsp;&emsp;当然，我们还可以尝试进行Stacking“硬投票”，即选择stack_method为predict："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "67a5c742-159f-4c58-ac60-8c4dc528029c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = StackingClassifier(estimators=estimators, stack_method='predict').fit(X_train_OE, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7c686e61-8643-434f-8d5f-e7580d0ee1d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'predict'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.stack_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b4b22d29-6f15-4e67-8c6b-491d95dce96b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8290420295342673, 0.7859170925610448)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_train_OE, y_train), clf.score(X_test_OE, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a6e99b-dd8b-48f8-aada-ff873d3cac17",
   "metadata": {},
   "source": [
    "能够发现，在基于交叉训练的Stacking融合过程中，“软投票”过程要好于“硬投票”过程。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67117f4e-36ad-43b4-8f9f-dea1adb797a8",
   "metadata": {},
   "source": [
    "#### 2.2 Stacking评估器优化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10cd97c-6557-40e5-8754-010741ee9a8e",
   "metadata": {},
   "source": [
    "&emsp;&emsp;尽管sklearn中Stacking评估器的适用不如手动实现Stacking过程那么灵活，但作为sklearn内部的评估器，是可以非常便捷的调用sklearn中其他功能，以此来快速实现诸如级联优化、多层Stacking等更复杂的过程。而这些其实也都是后续我们将要详细介绍的Stacking优化的核心方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b895b7e-b21f-4577-824b-943b0beb8bb5",
   "metadata": {},
   "source": [
    "&emsp;&emsp;因此，我们先借助sklearn的Stacking评估器来进行一些优化实验和尝试，在得到一些基本结论与经验后，我们再通过手动实现的方式，进行更加精准深度的优化。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c19a8ae-aa07-4b36-a06d-3d72c4fb2611",
   "metadata": {},
   "source": [
    "- Stacking评估器内部的超参数优化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f43b55-cf8f-4c80-b529-301e7631ed61",
   "metadata": {},
   "source": [
    "&emsp;&emsp;这里首先我们尝试着对Stacking评估器内部的一些超参数进行优化。主要是三个核心参数，分别是cv、stack_method和passthrough。这三个参数取值的组合有限，我们可以借助网格搜索对其完成最佳超参数搜索："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bd4e35e6-fe84-4b75-bc45-b7a064abdc72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.35744905471802\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# 设置超参数空间\n",
    "parameter_space = {\"cv\": range(1, 11), \n",
    "                   \"stack_method\": ['predict_proba', 'decision_function', 'predict'],\n",
    "                   \"passthrough\": [True, False]}\n",
    "\n",
    "# 实例化Stacking评估器\n",
    "clf = StackingClassifier(estimators=estimators)\n",
    "stack_grid = GridSearchCV(clf, parameter_space, n_jobs=15)\n",
    "\n",
    "# 模型训练\n",
    "stack_grid.fit(X_train_OE, y_train)\n",
    "\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cfc56195-3fb6-4421-8f73-5adfbbb8177b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cv': 2, 'passthrough': False, 'stack_method': 'predict_proba'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c80eb6e4-8100-4f16-9fb4-57bd836b9a6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8116245233794903"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "77a1944f-9471-4555-ad8a-f504d88ed0a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8256342294585385, 0.7876206700738216)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack_grid.score(X_train_OE, y_train), stack_grid.score(X_test_OE, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce494ed-c65a-4b95-a8b5-1410b2c9f77c",
   "metadata": {},
   "source": [
    "能够发现，经过网格搜索后，确实得到了一组测试集上表现更好的一组超参数。passthrough和stack_method参数的最佳取值和默认参数一致（其中stack_method为auto时也就是predict_proba），而CV的最佳取值是2，可能和“交叉验证折数越高、泛化能力越强”这一判断有悖。但实际上，在样本量较少的时候折数设置更小往往可能会有更好的效果，这就类似软投票过程中进行阈值移动时采用的三折验证而不是五折验证。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bbdd1b-b26f-4024-83ec-c7953571d7e0",
   "metadata": {},
   "source": [
    "&emsp;&emsp;当然，具体几折验证，其实很大程度也会参与Stacking的模型相关，模型不同、训练方式不同，最佳折数也会随之发生变化。这里我们重点需要强调的是passthrough和stack_method两个参数的取值选取，一般来说，尤其是在调用sklearn进行Stacking的时候，往往不不带入原始数据、只带入一级模型输出的概率预测结果，进行元学习器的训练，能得到一个更好的结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41594089-4988-41bf-8091-1f38ad78aba0",
   "metadata": {},
   "source": [
    "- 元学习器模型选择"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14381b14-66de-4afe-baf1-19ef8b38d046",
   "metadata": {},
   "source": [
    "&emsp;&emsp;对于一个层级结构融合过程来说，每个阶段的模型肯定是对最终结果有着至关重要的影响。接下来我们进一步在网格搜索中加入不同元学习器进行筛选，看是否会获得一个更好的Stacking效果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5262850d-3ea8-43df-a77b-c3e15eb20046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96.94286322593689\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# 设置超参数空间\n",
    "clf1 = DecisionTreeClassifier()\n",
    "clf2 = LogisticRegression()\n",
    "clf3 = RandomForestClassifier()\n",
    "\n",
    "parameter_space = {\"cv\": range(1, 11), \n",
    "                   \"stack_method\": ['predict_proba', 'decision_function', 'predict'],\n",
    "                   \"final_estimator\": [clf1, clf2, clf3],\n",
    "                   \"passthrough\": [True, False]}\n",
    "\n",
    "# 实例化Stacking评估器\n",
    "clf = StackingClassifier(estimators=estimators)\n",
    "stack_grid = GridSearchCV(clf, parameter_space, n_jobs=15)\n",
    "\n",
    "# 模型训练\n",
    "stack_grid.fit(X_train_OE, y_train)\n",
    "\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a4055728-a8a4-4a5a-bf3a-87426797fbaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cv': 2,\n",
       " 'final_estimator': LogisticRegression(),\n",
       " 'passthrough': False,\n",
       " 'stack_method': 'predict_proba'}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "90583412-af3b-45c8-976a-851453485303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8116245233794903"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d1924840-780d-4d19-91d2-a45cd5046f3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8256342294585385, 0.7876206700738216)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack_grid.score(X_train_OE, y_train), stack_grid.score(X_test_OE, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5581c355-0897-4032-be5d-6ceec809b61a",
   "metadata": {},
   "source": [
    "能够发现，相比决策树和随机森林，逻辑回归表现更好。其实在Stacking的元学习器的选择中，并不是越复杂的模型效果越好，而是视具体情况而定，一般来说，如果一级学习器比此独立性越强，则元学习器学习能力越强越好，但如果一级学习器彼此独立型较弱，则元学习器则需要具备一定的天然抗过拟合特性，才能够获得一个更好的输出结果。当前的一级学习器尽管是经过了交叉训练，但sklearn自带交叉训练过程并不能在超参数层面进行信息隔离，因此实际效力有限，外加一级学习器都是在相同的数据集上进行模型训练，因此独立性是有限的，此时就需要一个抗过拟合较好的元学习器。而对于逻辑回归模型来说，首先其学习能力有限，其次sklearn的逻辑回归模型自带正则化项，因此在默认参数设置情况下，就能一定程度规避过拟合问题，因此该模型也是当前情况下拟合效果最好的元学习器。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9b4a40-e524-40f7-8c65-75905889af77",
   "metadata": {},
   "source": [
    "> 类似的，如果是回归类问题，在一级学习器独立性较弱的情况下，元学习器选择贝叶斯回归、Lasso、岭回归等模型效果会比较好。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb36580-c9dc-486d-b438-2e4e43589c65",
   "metadata": {},
   "source": [
    "> 尽管逻辑回归并不是预测能力最强的模型，但逻辑回归其实用途很广，除了作为为数不多的机器学习领域的可解释型模型，同时还在模型融合、推荐系统中数据编码等领域发挥着重要作用，在Kaggle举办的2021年最受欢迎模型评选中，逻辑回归更是名列榜首。这也是为何课程中会花费大量篇幅来介绍逻辑回归模型的原因。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d28b97-3c2d-4363-87b0-fabeadea551d",
   "metadata": {},
   "source": [
    "- 元学习器手动超参数优化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114bb2d9-5166-4865-9091-9f375b5f3938",
   "metadata": {},
   "source": [
    "&emsp;&emsp;而既然更好的抗过拟合特性能够帮助元学习提高融合效果，那么对于逻辑回归模型来说，我们将惩罚项手动调整为l1正则化，或许能够提升Stacking融合效果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a8535b88-2728-45ce-826c-d0f362fcc0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_lr = LogisticRegression(penalty='l1', solver='saga')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "2368538a-6c3e-4c5c-bbb0-76eb7ccd3f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = StackingClassifier(estimators=estimators, final_estimator=final_lr).fit(X_train_OE, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "dc4bf93d-5971-49d5-afb7-f027323e087c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8271488072699735, 0.7893242475865985)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_train_OE, y_train), clf.score(X_test_OE, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdf94dd-d496-4f50-995d-9c7f60a70085",
   "metadata": {},
   "source": [
    "> 这里需要注意，惩罚项调整为l1正则化后，优化器也需要调整为saga，否则损失函数无法求解。关于逻辑回归的参数讲解，可以回顾Lesson 6的相关内容。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f749170c-cd31-49b3-a6bd-10882b84730b",
   "metadata": {},
   "source": [
    "不出所料，最终融合效果有所提升。当然，对于其他模型来说，通过超参数的设计调整，也是能提升模型抗过拟合特性的。例如在决策树模型设置最大树深度为2，通过降低模型复杂度来提升模型抗过拟合特性："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a3be5f5d-ce89-4874-86bd-1b65e8a9db80",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_tree = DecisionTreeClassifier(max_depth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "50a64142-e124-4306-8952-26ff4ae4f271",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = StackingClassifier(estimators=estimators, final_estimator=final_tree).fit(X_train_OE, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "b34decc0-aad9-4590-a8af-5c412f2faf93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8131389625141991, 0.7904599659284497)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_train_OE, y_train), clf.score(X_test_OE, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf00e702-6e62-4430-8388-61a52431232a",
   "metadata": {},
   "source": [
    "能够发现，融合效果确实有所提升，该思路确实有效。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9326ea-cb75-4f0e-a6ed-b20a387b462e",
   "metadata": {},
   "source": [
    "- 元学习器自动超参数搜索"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae1e5ec-9ceb-42ef-b12b-4c64e72eba3f",
   "metadata": {},
   "source": [
    "&emsp;&emsp;不过，尽管我们发现降低元学习器的复杂度、提升元学习器的抗过拟合特性，能够提升Stacking融合效果，但手动的超参数调整终究效果有限，能否借助优化器来进行元学习器的超参数优化呢？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ba79c3-5760-47ca-aa16-a771c845f61a",
   "metadata": {},
   "source": [
    "&emsp;&emsp;方法是有的，不过首先我们需要明确的是，我们无法在Stacking评估器层面对元学习器的超参数进行搜索，Stacking评估器层面只能优化Stacking评估器自己的超参数。要解决这个问题，我们必须把元学习器和Stacking评估器串联起来，然后联动调参，即主要调整元学习器的超参数，然后根据Stacking输出作为反馈，来不断修正元学习器的最佳超参数取值。很明显，这个过程需要修改Stacking评估器。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876e0764-2fc3-4668-920a-23a220b07a01",
   "metadata": {},
   "source": [
    "&emsp;&emsp;此处选取决策树模型作为元学习器，来尝试进行Stacking的元学习器超参数优化："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "db37c97b-b01d-4c4c-af97-92f5895e0f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stacking_tree_Cascade(BaseEstimator, ClassifierMixin, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, estimators, cv=None, passthrough='auto', max_depth=None, min_samples_split=2, min_samples_leaf=1, max_leaf_nodes=None):\n",
    "        self.estimators = estimators\n",
    "        self.cv = cv\n",
    "        self.passthrough = passthrough\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.max_leaf_nodes = max_leaf_nodes\n",
    "        self.final_estimator = DecisionTreeClassifier(max_depth=self.max_depth, \n",
    "                                                      min_samples_split=self.min_samples_split, \n",
    "                                                      min_samples_leaf=self.min_samples_leaf, \n",
    "                                                      max_leaf_nodes=self.max_leaf_nodes)\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        SC = StackingClassifier(estimators = self.estimators, \n",
    "                                final_estimator = self.final_estimator,\n",
    "                                cv = self.cv, \n",
    "                                passthrough = self.passthrough)\n",
    "\n",
    "        SC.fit(X, y)\n",
    "        self.clf = SC\n",
    "        self.classes_ = pd.Series(y).unique()\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        res_proba = self.clf.predict_proba(X)\n",
    "        return res_proba\n",
    "\n",
    "    def predict(self, X):\n",
    "        res = self.clf.predict(X)\n",
    "        return res\n",
    "\n",
    "    def score(self, X, y):\n",
    "        acc = accuracy_score(self.predict(X), y)\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b164a4-3644-45a8-afc8-ace8bef0852a",
   "metadata": {},
   "source": [
    "然后测试支持元学习器超参数优化的Stacking评估器能否正常运行："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "836bbe25-3ddb-4b9d-808f-2118e4170dcf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "STC = Stacking_tree_Cascade(estimators).fit(X_train_OE, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9389c4cc-f070-4835-80f3-87f94a456acf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8112457402499054, 0.7387847813742192)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STC.score(X_train_OE, y_train), STC.score(X_test_OE, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131faa51-2dec-46d6-8931-c1cfba456eb2",
   "metadata": {},
   "source": [
    "此时元学习器的超参数就也可以作为外层评估器的超参数进行调整："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "223a7239-2ef4-4486-9ccd-9a5621a1a1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "STC = Stacking_tree_Cascade(estimators, max_depth=2).fit(X_train_OE, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "67620fbd-e060-4365-be8d-43daa8abff74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8131389625141991, 0.7904599659284497)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STC.score(X_train_OE, y_train), STC.score(X_test_OE, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c9169346-6092-4ac9-ad0f-a4054498e096",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1507.0625259876251\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "parameter_space =  {'max_depth': np.arange(2, 7, 1).tolist(), \n",
    "                    'min_samples_split': np.arange(2, 7, 1).tolist(), \n",
    "                    'min_samples_leaf': np.arange(2, 7, 1).tolist(), \n",
    "                    'max_leaf_nodes':np.arange(4, 10, 1).tolist(), \n",
    "                    'cv':np.arange(2, 6, 1).tolist()}\n",
    "\n",
    "# 实例化Stacking评估器\n",
    "STC = Stacking_tree_Cascade(estimators)\n",
    "STC_grid = GridSearchCV(STC, parameter_space, n_jobs=15)\n",
    "\n",
    "# 模型训练\n",
    "STC_grid.fit(X_train_OE, y_train)\n",
    "\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9655176d-3839-43ba-bfdd-6739850771fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cv': 4,\n",
       " 'max_depth': 3,\n",
       " 'max_leaf_nodes': 8,\n",
       " 'min_samples_leaf': 6,\n",
       " 'min_samples_split': 3}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STC_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "dcdd142b-a92f-4dbe-b2c9-24742b95a78b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8118137069291935, 0.7887563884156729)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STC_grid.score(X_train_OE, y_train), STC_grid.score(X_test_OE, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602a75a8-ddf3-4e66-9577-eac817052d15",
   "metadata": {},
   "source": [
    "&emsp;&emsp;至此，我们就完成了一次简单的元学习器超参数搜索优化实践。当然，元学习器的优化对于Stacking最终建模效果影响非常巨大，更多的元学习器的选择与优化策略将在下一小节进行详细讨论。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006e8cb2-4d2c-461a-a085-86830374cf1c",
   "metadata": {},
   "source": [
    "- 多层Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1824f91f-5ccc-47ec-9f6f-58418b0692ce",
   "metadata": {},
   "source": [
    "&emsp;&emsp;当然，除了元学习器优化外，Stacking的另一个重要的优化方向就是多层Stacking。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67b050b-a08e-47ff-8458-302ed96f9464",
   "metadata": {},
   "source": [
    "&emsp;&emsp;其实从此前的介绍不难看出，Stacking的本质就是围绕上一层模型输出结果进行学习，借此提升最终预测效果。而在这个过程中，元学习器本身也是可以输出概率预测结果的，也就是说，某个元学习器之后还可以再堆叠一层元学习器。而如果两层的堆叠能够提升单模效果，那么双层的堆叠则能够进一步提升学习能力，从而进一步提升模型效果。当然，伴随着Stacking结构更加复杂，融合的过拟合风险也会更高。本节我们先讨论如何实现多层的Stacking，下一小节开始将重点介绍如何优化。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7474fdf8-c1c1-4530-a59a-1974d62f7d97",
   "metadata": {},
   "source": [
    "&emsp;&emsp;例如，我们可以借助逻辑回归、决策树和随机森林三个模型，构建如下三层Stacking堆叠融合："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db66b9fc-328c-48d1-9ab2-195acc753c6c",
   "metadata": {},
   "source": [
    "<center><img src=\"http://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20220920225821282.png\" alt=\"image-20220920225821282\" style=\"zoom:50%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806149f7-e936-492d-8ce8-bfa587141714",
   "metadata": {},
   "source": [
    "在上述三层评估器堆叠的情况下，两个一级元学习器接受的数据是相同的，而各自的预测结果则会为二级元学习器提供一个特征。该过程的实现代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3e09954b-a6e4-48c5-9895-3911a5fddca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 先实例化一级元学习器\n",
    "tree_final = DecisionTreeClassifier()\n",
    "RF_final = RandomForestClassifier()\n",
    "\n",
    "# 然后构建两层元学习器之间的Stacking评估器\n",
    "final_layer = StackingClassifier(estimators=[('tree_final', tree_final), ('RF_final', RF_final)], \n",
    "                                 final_estimator=LogisticRegression(penalty='l1', solver='saga'))\n",
    "\n",
    "# 然后构建一级学习器\n",
    "multi_layer = StackingClassifier(estimators=estimators, final_estimator=final_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55dfd998-7117-445b-90c6-f0d7a6819125",
   "metadata": {},
   "source": [
    "然后进行训练："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "33da0449-97da-4ebb-bb12-4e8b49346bec",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingClassifier(estimators=[('lr',\n",
       "                                Pipeline(steps=[('columntransformer',\n",
       "                                                 ColumnTransformer(transformers=[('cat',\n",
       "                                                                                  OneHotEncoder(drop='if_binary'),\n",
       "                                                                                  ['gender',\n",
       "                                                                                   'SeniorCitizen',\n",
       "                                                                                   'Partner',\n",
       "                                                                                   'Dependents',\n",
       "                                                                                   'PhoneService',\n",
       "                                                                                   'MultipleLines',\n",
       "                                                                                   'InternetService',\n",
       "                                                                                   'OnlineSecurity',\n",
       "                                                                                   'OnlineBackup',\n",
       "                                                                                   'DeviceProtection',\n",
       "                                                                                   'TechSupport',\n",
       "                                                                                   'StreamingTV',\n",
       "                                                                                   'StreamingMovies',\n",
       "                                                                                   'Contract'...\n",
       "                                                       random_state=12)),\n",
       "                               ('rf',\n",
       "                                RandomForestClassifier(max_depth=10,\n",
       "                                                       max_features='sqrt',\n",
       "                                                       max_samples=2000,\n",
       "                                                       min_samples_leaf=2,\n",
       "                                                       min_samples_split=7,\n",
       "                                                       n_estimators=97,\n",
       "                                                       random_state=12))],\n",
       "                   final_estimator=StackingClassifier(estimators=[('tree_final',\n",
       "                                                                   DecisionTreeClassifier()),\n",
       "                                                                  ('RF_final',\n",
       "                                                                   LogisticRegression())],\n",
       "                                                      final_estimator=LogisticRegression(penalty='l1',\n",
       "                                                                                         solver='saga')))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_layer.fit(X_train_OE, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc41cfe1-169d-4844-908e-76f1f9dd778a",
   "metadata": {},
   "source": [
    "查看最终模型训练结果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "323603d4-824c-49b9-9374-2a594f8cd060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8275274517228323, 0.7893242475865985)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_layer.score(X_train_OE, y_train), multi_layer.score(X_test_OE, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965ebc03-0a6d-4a75-bfb4-6f2d0a67824e",
   "metadata": {},
   "source": [
    "至此，我们在借助sklearn的情况下，快速构建了一个简易的多层Stacking融合器，不过在大多数情况下，多层Stacking、或者是不同种类融合混合堆叠，其实都会有较为严重的过拟合问题。除非是非常特殊的数据情况，否则一般来说多层融合只有一个应用场景：那就是Blending+均值法两层融合。这方面内容我们将在Part 4.3.10中进行详细的探讨。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c81fc0-2a73-4864-b57d-ec779cea1242",
   "metadata": {},
   "source": [
    "&emsp;&emsp;至此，我们就完整介绍了Stacking的原理和基本实践过程，并简单尝试了部分优化策略。其中有较为进阶的优化方法如特征增强、多层模型融合等，此外也有较为基础但往往行之有效的优化方法，即一级学习器的训练流程优化与元学习器优化。那么从下一小节开始，我们将由浅入深，从Stacking基础优化方法开始，逐步介绍学习器结合器的实战优化策略。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
