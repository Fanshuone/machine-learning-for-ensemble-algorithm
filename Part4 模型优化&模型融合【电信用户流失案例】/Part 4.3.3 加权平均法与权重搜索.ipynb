{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54704f43-1762-4e26-baa9-67e98c7f6b2f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# <center> 【Kaggle】Telco Customer Churn 电信用户流失预测案例"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18931ad4-eab4-4651-bdb8-bfcc09eb64a7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a01312e-3448-48a7-a8ea-18f829381f33",
   "metadata": {},
   "source": [
    "## <font face=\"仿宋\">第四部分导读"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e3fd55-e622-486b-adec-8e5f244d593a",
   "metadata": {},
   "source": [
    "&emsp;&emsp;<font face=\"仿宋\">在案例的第二、三部分中，我们详细介绍了关于特征工程的各项技术，特征工程技术按照大类来分可以分为数据预处理、特征衍生、特征筛选三部分，其中特征预处理的目的是为了将数据集整理、清洗到可以建模的程度，具体技术包括缺失值处理、异常值处理、数据重编码等，是建模之前必须对数据进行的处理和操作；而特征衍生和特征筛选则更像是一类优化手段，能够帮助模型突破当前数据集建模的效果上界。并且我们在第二部分完整详细的介绍机器学习可解释性模型的训练、优化和解释方法，也就是逻辑回归和决策树模型。并且此前我们也一直以这两种算法为主，来进行各个部分的模型测试。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd035b4b-b9e0-4961-95b6-7864a378d0a6",
   "metadata": {},
   "source": [
    "&emsp;&emsp;<font face=\"仿宋\">而第四部分，我们将开始介绍集成学习的训练和优化的实战技巧，尽管从可解释性角度来说，集成学习的可解释性并不如逻辑回归和决策树，但在大多数建模场景下，集成学习都将获得一个更好的预测结果，这也是目前效果优先的建模场景下最常使用的算法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041f9084-88c5-48a9-9815-f5afdef301c2",
   "metadata": {},
   "source": [
    "&emsp;&emsp;<font face=\"仿宋\">总的来说，本部分内容只有一个目标，那就是借助各类优化方法，抵达每个主流集成学习的效果上界。换而言之，本部分我们将围绕单模优化策略展开详细的探讨，涉及到的具体集成学习包括随机森林、XGBoost、LightGBM、和CatBoost等目前最主流的集成学习算法，而具体的优化策略则包括超参数优化器的使用、特征衍生和筛选方法的使用、单模型自融合方法的使用，这些优化方法也是截至目前，提升单模效果最前沿、最有效、同时也是最复杂的方法。其中有很多较为艰深的理论，也有很多是经验之谈，但无论如何，我们希望能够围绕当前数据集，让每个集成学习算法优化到极限。值得注意的是，在这个过程中，我们会将此前介绍的特征衍生和特征筛选视作是一种模型优化方法，衍生和筛选的效果，一律以模型的最终结果来进行评定。而围绕集成学习进行海量特征衍生和筛选，也才是特征衍生和筛选技术能发挥巨大价值的主战场。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c221d2ba-cb28-4a6b-9a9f-a87a58c528d5",
   "metadata": {},
   "source": [
    "&emsp;&emsp;<font face=\"仿宋\">而在抵达了单模的极限后，我们就会进入到下一阶段，也就是模型融合阶段。需要知道的是，只有单模的效果到达了极限，进一步的多模型融合、甚至多层融合，才是有意义的，才是有效果的。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab548f0-7c96-475a-a404-118802c74862",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75475967-342a-48e7-a5b1-a2aaf6a50b02",
   "metadata": {},
   "source": [
    "# <center>Part 4.集成算法的训练与优化技巧"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e9e1ac16-3301-423f-8584-9afda1b439c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 基础数据科学运算库\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 可视化库\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 时间模块\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# sklearn库\n",
    "# 数据预处理\n",
    "from sklearn import preprocessing\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# 实用函数\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 常用评估器\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 网格搜索\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 自定义评估器支持模块\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, ClassifierMixin\n",
    "\n",
    "# 自定义模块\n",
    "from telcoFunc import *\n",
    "# 导入特征衍生模块\n",
    "import features_creation as fc\n",
    "from features_creation import *\n",
    "\n",
    "# re模块相关\n",
    "import inspect, re\n",
    "\n",
    "# 其他模块\n",
    "from tqdm import tqdm\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f037ee6-626b-4256-98c8-57921d855033",
   "metadata": {},
   "source": [
    "&emsp;&emsp;然后执行Part 1中的数据清洗相关工作："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fa7090c8-c7cb-428f-807d-c3cf2d616d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "tcc = pd.read_csv('WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
    "\n",
    "# 标注连续/离散字段\n",
    "# 离散字段\n",
    "category_cols = ['gender', 'SeniorCitizen', 'Partner', 'Dependents',\n",
    "                'PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', \n",
    "                'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling',\n",
    "                'PaymentMethod']\n",
    "\n",
    "# 连续字段\n",
    "numeric_cols = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
    " \n",
    "# 标签\n",
    "target = 'Churn'\n",
    "\n",
    "# ID列\n",
    "ID_col = 'customerID'\n",
    "\n",
    "# 验证是否划分能完全\n",
    "assert len(category_cols) + len(numeric_cols) + 2 == tcc.shape[1]\n",
    "\n",
    "# 连续字段转化\n",
    "tcc['TotalCharges']= tcc['TotalCharges'].apply(lambda x: x if x!= ' ' else np.nan).astype(float)\n",
    "tcc['MonthlyCharges'] = tcc['MonthlyCharges'].astype(float)\n",
    "\n",
    "# 缺失值填补\n",
    "tcc['TotalCharges'] = tcc['TotalCharges'].fillna(0)\n",
    "\n",
    "# 标签值手动转化 \n",
    "tcc['Churn'].replace(to_replace='Yes', value=1, inplace=True)\n",
    "tcc['Churn'].replace(to_replace='No',  value=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "06acdc56-a2ac-480e-904d-e9a682a3f6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = tcc.drop(columns=[ID_col, target]).copy()\n",
    "labels = tcc['Churn'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44eb84d1-2046-4901-b499-4eb1baa0a419",
   "metadata": {},
   "source": [
    "&emsp;&emsp;同时，创建自然编码后的数据集以及经过时序特征衍生的数据集："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1b0e3e70-9b05-47b0-9c3f-d59f1ec6b2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分训练集和测试集\n",
    "train, test = train_test_split(tcc, random_state=22)\n",
    "\n",
    "X_train = train.drop(columns=[ID_col, target]).copy()\n",
    "X_test = test.drop(columns=[ID_col, target]).copy()\n",
    "\n",
    "y_train = train['Churn'].copy()\n",
    "y_test = test['Churn'].copy()\n",
    "\n",
    "X_train_seq = pd.DataFrame()\n",
    "X_test_seq = pd.DataFrame()\n",
    "\n",
    "# 年份衍生\n",
    "X_train_seq['tenure_year'] = ((72 - X_train['tenure']) // 12) + 2014\n",
    "X_test_seq['tenure_year'] = ((72 - X_test['tenure']) // 12) + 2014\n",
    "\n",
    "# 月份衍生\n",
    "X_train_seq['tenure_month'] = (72 - X_train['tenure']) % 12 + 1\n",
    "X_test_seq['tenure_month'] = (72 - X_test['tenure']) % 12 + 1\n",
    "\n",
    "# 季度衍生\n",
    "X_train_seq['tenure_quarter'] = ((X_train_seq['tenure_month']-1) // 3) + 1\n",
    "X_test_seq['tenure_quarter'] = ((X_test_seq['tenure_month']-1) // 3) + 1\n",
    "\n",
    "# 独热编码\n",
    "enc = preprocessing.OneHotEncoder()\n",
    "enc.fit(X_train_seq)\n",
    "\n",
    "seq_new = list(X_train_seq.columns)\n",
    "\n",
    "# 创建带有列名称的独热编码之后的df\n",
    "X_train_seq = pd.DataFrame(enc.transform(X_train_seq).toarray(), \n",
    "                           columns = cate_colName(enc, seq_new, drop=None))\n",
    "\n",
    "X_test_seq = pd.DataFrame(enc.transform(X_test_seq).toarray(), \n",
    "                          columns = cate_colName(enc, seq_new, drop=None))\n",
    "\n",
    "# 调整index\n",
    "X_train_seq.index = X_train.index\n",
    "X_test_seq.index = X_test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0687fea4-d684-4584-a627-97f544bab0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "ord_enc = OrdinalEncoder()\n",
    "ord_enc.fit(X_train[category_cols])\n",
    "\n",
    "X_train_OE = pd.DataFrame(ord_enc.transform(X_train[category_cols]), columns=category_cols)\n",
    "X_train_OE.index = X_train.index\n",
    "X_train_OE = pd.concat([X_train_OE, X_train[numeric_cols]], axis=1)\n",
    "\n",
    "X_test_OE = pd.DataFrame(ord_enc.transform(X_test[category_cols]), columns=category_cols)\n",
    "X_test_OE.index = X_test.index\n",
    "X_test_OE = pd.concat([X_test_OE, X_test[numeric_cols]], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480a59c4-9dd0-4f66-8b52-425e9907ff27",
   "metadata": {},
   "source": [
    "然后是模型融合部分所需的第三方库、准备的数据以及训练好的模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "44524dff-8508-471e-9b01-4f83a9ecee7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 本节新增第三方库\n",
    "from joblib import dump, load\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from hyperopt import hp, fmin, tpe\n",
    "from numpy.random import RandomState\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2bf386a3-5437-41e1-8fef-c9bd68480d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_search = load('logistic_search.joblib') \n",
    "tree_model = load('tree_model.joblib') \n",
    "RF_0 = load('RF_0.joblib') \n",
    "\n",
    "estimators = [('lr', logistic_search.best_estimator_), ('tree', tree_model), ('rf', RF_0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8169c671-4cd9-4c97-9243-5f5295b5f662",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 训练集上的预测结果\n",
    "train_prediction1 = logistic_search.best_estimator_.predict(X_train_OE)\n",
    "train_prediction2 = tree_model.predict(X_train_OE)\n",
    "train_prediction3 = RF_0.predict(X_train_OE)\n",
    "\n",
    "# 训练集上的预测概率(预测为1的概率)\n",
    "train_prediction1_proba = logistic_search.best_estimator_.predict_proba(X_train_OE)[:, 1]\n",
    "train_prediction2_proba = tree_model.predict_proba(X_train_OE)[:, 1]\n",
    "train_prediction3_proba = RF_0.predict_proba(X_train_OE)[:, 1]\n",
    "\n",
    "# 测试集上的预测结果\n",
    "test_prediction1 = logistic_search.best_estimator_.predict(X_test_OE)\n",
    "test_prediction2 = tree_model.predict(X_test_OE)\n",
    "test_prediction3 = RF_0.predict(X_test_OE)\n",
    "\n",
    "# 测试集上的预测概率\n",
    "test_prediction1_proba = logistic_search.best_estimator_.predict_proba(X_test_OE)[:, 1]\n",
    "test_prediction2_proba = tree_model.predict_proba(X_test_OE)[:, 1]\n",
    "test_prediction3_proba = RF_0.predict_proba(X_test_OE)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32f6405-acb5-45b0-bddb-a7dfd1b3ac24",
   "metadata": {},
   "source": [
    "## <center>Ch.3 模型融合基础方法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef2f403-5d0f-423e-a067-a6aefddc9451",
   "metadata": {},
   "source": [
    "## 三、加权投票法与加权平均法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859caf00-23c7-4759-9d13-4a59c83df133",
   "metadata": {},
   "source": [
    "&emsp;&emsp;接下来继续讨论加权平均法的相关内容。所谓加权平均，实际上就是在平均的过程中给不同项以不同权重，从而增强最终结果表现。加权平均的代码计算过程并不复杂，复杂的是应该如何确定这个权重。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a06db2d-1573-4215-ac3b-a4d0cf8c2d10",
   "metadata": {},
   "source": [
    "### 1.基本方法及其实践过程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6186799e-8da2-488f-b545-f3a153e3e753",
   "metadata": {},
   "source": [
    "&emsp;&emsp;首先我们可以按照如下方法简单尝试软投票的加权平均的计算过程，计算公式如下："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb64404e-607e-4147-bc9c-1e9e3898dfee",
   "metadata": {},
   "source": [
    "$$\\bar X = \\frac{x_1*w_1+x_2*w_2+x_3*w_3+...+x_n*w_n}{w_1+w_2+w_3+...+w_n}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfa0b3b-c76c-4899-9a2a-7e9386d5675e",
   "metadata": {},
   "source": [
    "&emsp;&emsp;其中$w_1$到$w_n$是n个项的权重，而$x_1$到$x_n$则是各个评估器预测的概率结果。例如我们随机给与三个评估器1、2、3的权重，然后测试加权软投票平均的结果："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97d87de-018d-4256-885b-8e4b735058e6",
   "metadata": {},
   "source": [
    "> 当然，加权融合过程也可以通过如下方式进行表示：$$\\bar x = w_1x_1+x_2w_2+x3_w3+...+w_nx_n$$此时要求$w_1+w_2+w_3+...+w_n=1$。不过从计算的便捷性角度来看，灵活设置一个权重，然后再除以所有权重之和，可能会更加方便一些。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "56c3574a-47e4-4ce2-b39d-f7ce8d25401f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置三个评估器的权重\n",
    "weight1 = 1\n",
    "weight2 = 2\n",
    "weight3 = 3\n",
    "\n",
    "weights = [weight1, weight2, weight3]\n",
    "\n",
    "# 计算权重总和\n",
    "weight_sum = weight1 + weight2 + weight3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2b49df87-f839-4527-9abe-9559e9be1694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8296099962135555, 0.7876206700738216)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 训练集加权平均\n",
    "Voting_train_soft_weight = (((train_prediction1_proba * weight1 + \n",
    "                              train_prediction2_proba * weight2 + \n",
    "                              train_prediction3_proba * weight3) / weight_sum) > 0.5) * 1\n",
    "\n",
    "# 测试集加权平均\n",
    "Voting_test_soft_weight = (((test_prediction1_proba * weight1 + \n",
    "                             test_prediction2_proba * weight2 + \n",
    "                             test_prediction3_proba * weight3) / weight_sum) > 0.5) * 1\n",
    "\n",
    "accuracy_score(Voting_train_soft_weight, y_train), accuracy_score(Voting_test_soft_weight, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30497ab0-851c-4eda-a7c1-6677d47f14e0",
   "metadata": {},
   "source": [
    "> 注意，这里的加权过程最后会除以所有权重之和，所以不需要权重本身加合为1。实际上每个项最终权重为$\\frac{1}{1+2+3}$、$\\frac{2}{1+2+3}$、$\\frac{3}{1+2+3}$，因此把1、2、3换成2、4、6或者0.1、0.2、0.3，并不会有任何区别（分子分母同比例变化）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40407e7c-07df-4e0a-a146-bf6a70ac342b",
   "metadata": {},
   "source": [
    "也可以借助sklearn中评估器实现上述功能，这里只需要在weights参数位置输出对应每个评估器的权重即可，同时需要注意的是，sklearn中的weights参数不需要归一，即无需各分量求和为1："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "917f9656-60fe-46f1-9dc0-3df56e93c8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Voting_soft_weight = VotingClassifier(estimators=estimators, \n",
    "                                      voting='soft', \n",
    "                                      weights=weights).fit(X_train_OE, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "25073dc1-bec0-45c7-b1d8-4993512b4109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8296099962135555, 0.7876206700738216)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Voting_soft_weight.score(X_train_OE, y_train), Voting_soft_weight.score(X_test_OE, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090be3cf-c9aa-42f2-9285-ed100c40eb2c",
   "metadata": {},
   "source": [
    "当然如果是回归问题，也可以参照上述方法进行加权平均的计算。需要注意的是，除了软投票中我们可以用权重乘以概率然后求加权平均之外，在硬投票中也是可以有加权投票的，并且权重也是可以任意数值，如此一来最终得到的票数也可能是非整数结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "37ea20c7-1c85-4d2e-95eb-07a1dbf2497c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8386974630821659, 0.7921635434412265)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 基于权重的硬投票\n",
    "\n",
    "# 训练集加权平均\n",
    "Voting_train_hard_weight = (((train_prediction1 * weight1 + \n",
    "                              train_prediction2 * weight2 + \n",
    "                              train_prediction3 * weight3) / weight_sum) > 0.5) * 1\n",
    "\n",
    "# 测试集加权平均\n",
    "Voting_test_hard_weight = (((test_prediction1 * weight1 + \n",
    "                             test_prediction2 * weight2 + \n",
    "                             test_prediction3 * weight3) / weight_sum) > 0.5) * 1\n",
    "\n",
    "accuracy_score(Voting_train_hard_weight, y_train), accuracy_score(Voting_test_hard_weight, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85c5326-a956-437e-9950-cb18ca0e8f4a",
   "metadata": {},
   "source": [
    "需要注意的是，对于硬投票法来说，由于每个prediction都乘了一个$\\frac{weight}{weight\\_sum}$，相当于三个评估器0或1的预测结果各自乘以一个最后加和为1的权重，因此最后乘以权重后求和的结果实际上得到的也是一个0-1之间的数，因此此处阈值也是0.5。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3a769c8e-8ac3-4f96-b051-f5f443d0b5b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = (train_prediction1 * weight1 + \n",
    "        train_prediction2 * weight2 + \n",
    "        train_prediction3 * weight3) / weight_sum\n",
    "temp.min(), temp.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f792bcf-eca6-49bc-9e31-8f52b9f6d918",
   "metadata": {},
   "source": [
    "然后尝试借助sklearn实现上述过程："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a8367992-b112-4ec0-907c-79a9bd88ec27",
   "metadata": {},
   "outputs": [],
   "source": [
    "Voting_hard_weight = VotingClassifier(estimators=estimators, \n",
    "                                      voting='hard', \n",
    "                                      weights=weights).fit(X_train_OE, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7a95aa2f-684e-461e-aeb9-f6aef56ea7bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8386974630821659, 0.7921635434412265)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Voting_hard_weight.score(X_train_OE, y_train), Voting_hard_weight.score(X_test_OE, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f627b9-18c6-4e2d-9f0c-a6e820da40cd",
   "metadata": {},
   "source": [
    "能够发现，看似更加死板的加权硬投票法却得到了一个更高的评分，类似的情况也发生在硬投票和软投票的结果比较重。这里需要注意的是，尽管从数值层面来看，加权软投票的数值表现更丰富——都是高精度浮点数运算，并且配如果可以进一步配合阈值移动，则有较大的调优空间。不过，带入权重的硬投票实际上也有自己的优势，其中最大的优势就在于硬投票的过程实际上自带一个将概率转化为投票的过程，而这个过程实际上是非线性的，即概率小于0.5时输出为0、概率大于0.5时输出为1，而这个非线性的过程就极有可能进一步提升最终融合效果。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807313c7-2759-4b46-84e6-32b6e4207e09",
   "metadata": {},
   "source": [
    "&emsp;&emsp;当然，加权的计算过程并复杂，并且很明显的是，权重不同最终的融合效果肯定也会有所区别，那么问题在于，我们应该如何找到一组最佳权重呢？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6d2e9a-8245-4da7-a834-45caeacca029",
   "metadata": {},
   "source": [
    "### 2.权重的理论最优值"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0715fac-db8b-49de-98d0-f580941ac90d",
   "metadata": {},
   "source": [
    "&emsp;&emsp;对于权重如何设计，首先我们想到的就是有没有一套完整的理论推导，直接给出最优权重的结论呢？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3387d9-28f3-43be-84d0-5d6546de6039",
   "metadata": {},
   "source": [
    "&emsp;&emsp;其实是有的。但实践起来会有很大困难，最核心的问题仍然是这些理论推导的最优权重都是基于各分类器彼此独立的假设前提进行的推导，在大多数情况下这一假设前提无法成立。当然我们这里可以看下相关结论，或许能够给我们设置权重时一些启发。需要注意的是，相关理论推导过程都会非常复杂的数学过程，而由于其结论的不可用性，我们不做完整理论推导，仅介绍最终结论。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c40aec-d660-498b-ae22-3f8337ff656d",
   "metadata": {},
   "source": [
    "&emsp;&emsp;首先是分类问题的投票法，通过理论推导能够得出，在各分类器彼此独立的情况下，每个分类器的最佳权重为："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcb9381-ae72-4474-a8e6-af4fccf9efb3",
   "metadata": {},
   "source": [
    "$$w_i = log\\frac{p_i}{1-p_i}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692ed2ac-da5e-472d-8161-4602a467dabd",
   "metadata": {},
   "source": [
    "其中$p_i$是第i个分类器的分类精度，即准确率。这里其实得出了一个非常“奇妙”的结果，理论上每个分类器的最佳权重居然是分类器准确率的对数几率函数。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1c0c6a-c499-47b9-92f3-04dc900e0b32",
   "metadata": {},
   "source": [
    "&emsp;&emsp;我们可以尝试以设置该权重并计算融合结果，这里的准确率我们用验证集的平均准确率来表示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d7d245c4-0d16-4430-9aa0-c958e9f2e97a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8104888764656977, 0.7949637696740346, 0.8104878013818411)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 逻辑回归验证集平均准确率\n",
    "lr_val_score = cross_val_score(logistic_search.best_estimator_, \n",
    "                               X_train_OE, \n",
    "                               y_train).mean()\n",
    "\n",
    "# 决策树验证集平均准确率\n",
    "tree_val_score = cross_val_score(tree_model, X_train_OE, y_train).mean()\n",
    "\n",
    "# 随机森林验证集平均准确率\n",
    "RF_val_score = cross_val_score(RF_0, X_train_OE, y_train).mean()\n",
    "\n",
    "lr_val_score, tree_val_score, RF_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "128dbe96-1575-46f8-8518-975b071f33e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8104888764656977, 0.7949637696740346, 0.8104878013818411)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_val_score, tree_val_score, RF_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ca026ae5-f7a5-4900-b1fb-81cdd987278d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4531898946057384"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(lr_val_score/(1-lr_val_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "adffbade-e3f2-496e-a357-e188de52bb14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.4531898946057384, 1.3551098440584888, 1.4531828952247814]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 设置三个评估器的权重\n",
    "weight1 = np.log(lr_val_score/(1-lr_val_score))\n",
    "weight2 = np.log(tree_val_score/(1-tree_val_score))\n",
    "weight3 = np.log(RF_val_score/(1-RF_val_score))\n",
    "\n",
    "weights = [weight1, weight2, weight3]\n",
    "\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fad533f4-4452-4c42-8b13-eb7903c3505d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8252555850056796, 0.7876206700738216)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 软投票\n",
    "Voting_soft_weight = VotingClassifier(estimators=estimators, \n",
    "                                      voting='soft', \n",
    "                                      weights=weights).fit(X_train_OE, y_train)\n",
    "\n",
    "Voting_soft_weight.score(X_train_OE, y_train), Voting_soft_weight.score(X_test_OE, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "39b0e916-7d50-4cc2-a23b-deae84249d24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8345323741007195, 0.7910278250993753)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 硬投票\n",
    "Voting_hard_weight = VotingClassifier(estimators=estimators, \n",
    "                                      voting='hard', \n",
    "                                      weights=weights).fit(X_train_OE, y_train)\n",
    "\n",
    "Voting_hard_weight.score(X_train_OE, y_train), Voting_hard_weight.score(X_test_OE, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eddcecc-7e85-432e-b2f6-8cca492e4412",
   "metadata": {},
   "source": [
    "不难发现，仍然是因为不同模型权重差异太小，导致最终融合结果并没有提升。不过这也能明显看出理论结果和实践效果之间的差异，以及无法满足模型独立性假设所造成的影响。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4377c28-47cc-473c-a851-e19e82c5a4db",
   "metadata": {},
   "source": [
    "### 3.经验法确定权重"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09550e5f-4a0a-4cb3-97e9-68e79740df91",
   "metadata": {},
   "source": [
    "&emsp;&emsp;既然理论层面给出的最优权重无法在实践过程中有效得出最优解，那么我们就要想办法从实践层面出发，总结行之有效的权重设计策略了。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12638155-e406-42bd-9b91-33d3e9fd5982",
   "metadata": {},
   "source": [
    "&emsp;&emsp;首先最简单、最便捷、甚至很多时候也是最有效的的一种方法——就是根据长期实践经验，给出一组“应该还不错”的权重。一般来说，根据实际模型表现分配权重是较为有效的做法，即给予效果更好的模型相对更高的权重。当然，据此经验法也能进一步分成两个思路，其一是以平均为主的思路，整体给不同评估器分配的权重尽管不同但整体还是比较均匀的，即仍然希望综合采纳各个模型的不同意见，博采众长；其二则是以某一个评估器为核心，剩下评估器为辅助，核心评估器的权重占比超过90%，而辅助的评估器权重只占10%，主要起到局部修正核心评估器判断结果的作用。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac902c4d-13c3-453a-adba-eac8b977d835",
   "metadata": {},
   "source": [
    "#### 3.1 思路一：平均为主，博采众长"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e524f9-8787-42ee-b32b-4f182725156e",
   "metadata": {},
   "source": [
    "&emsp;&emsp;接下来我们尝试这两种思路进行加权模型融合，不要小看经验法的作用，这部分的实验将获得甚至比随机森林单模型更好的结果。首先对于当前的三个模型来说，逻辑回归和随机森林相对较好，因此可以考虑分配给这两个模型更高的权重，而给与决策树较低的权重。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "168cdad7-1172-4c10-a610-9c8c2a5cf7e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8123816736084817"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_train_score = logistic_search.best_estimator_.score(X_train_OE, y_train)\n",
    "lr_train_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bcea4f57-a1e4-40b2-960e-8fb9fbc1f4f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7991291177584249"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_train_score = tree_model.score(X_train_OE, y_train)\n",
    "tree_train_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4bcf86ba-9acb-4ed1-8516-d0cd8279330f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8483528966300644"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_train_score = RF_0.score(X_train_OE, y_train)\n",
    "RF_train_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f39507-bf85-41b1-a234-8e105f99ce04",
   "metadata": {},
   "source": [
    "&emsp;&emsp;不过具体这个差异是多少，我们可以根据模型在训练集上的表现决定，对于当前参与融合的三个模型来说，评分越高模型表现越好、相应的权重也可以更大，因此我们可以简单以准确率作为权重进行融合，效果测试如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d37a250d-fd8d-4218-b316-190e7ed47d4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8123816736084817, 0.7991291177584249, 0.8483528966300644]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 设置三个评估器的权重\n",
    "weight1 = lr_train_score\n",
    "weight2 = tree_train_score\n",
    "weight3 = RF_train_score\n",
    "\n",
    "weights = [weight1, weight2, weight3]\n",
    "\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1599462b-672c-41d0-a19d-f116de3bb7d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8252555850056796, 0.787052810902896)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 软投票\n",
    "Voting_soft_weight = VotingClassifier(estimators=estimators, \n",
    "                                      voting='soft', \n",
    "                                      weights=weights).fit(X_train_OE, y_train)\n",
    "\n",
    "Voting_soft_weight.score(X_train_OE, y_train), Voting_soft_weight.score(X_test_OE, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "dbde14f6-b4a7-41be-8c4f-b45389d25cf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8345323741007195, 0.7910278250993753)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 硬投票\n",
    "Voting_hard_weight = VotingClassifier(estimators=estimators, \n",
    "                                      voting='hard', \n",
    "                                      weights=weights).fit(X_train_OE, y_train)\n",
    "\n",
    "Voting_hard_weight.score(X_train_OE, y_train), Voting_hard_weight.score(X_test_OE, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6c12ce-be3b-48ff-8bf4-1000ffdae08f",
   "metadata": {},
   "source": [
    "不过加权后我们发现，相比普通的投票方法，上述加权过程似乎对结果融合结果并没有任何结果影响。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a43864-d47d-4618-924c-47f8ff7b2421",
   "metadata": {},
   "source": [
    "|Models|train_score|test_score|\n",
    "|:--:|:--:|:--:|\n",
    "|logistic_search|0.8123|0.7836|\n",
    "|tree_model|0.7991|0.7683|\n",
    "|RF_0|0.8483|0.7955|\n",
    "|Voting_hard|0.8345|0.7910|\n",
    "|Voting_soft|0.8258|0.7870|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d8c6e3-50d7-4714-bf0a-0e70d19f1857",
   "metadata": {},
   "source": [
    "&emsp;&emsp;造成该结果的可能性有两个，其一是或许我们不应该以训练集的准确率作为权重，而应该采用更加严谨、更能代表模型泛化能力的验证集的平均准确率作为权重；其二则是评分之间的差异过小，导致加权效果不明显，例如实际上上述3个模型的最终计算权重为："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "16354f2f-b25f-4c1e-8622-dcd9cd1b57f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1353969456014136, 0.1331881862930708, 0.14139214943834408)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight1 / weight_sum, weight2 / weight_sum, weight3 / weight_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc1742b-e2a7-4067-98db-1b50ccafb19c",
   "metadata": {},
   "source": [
    "能发现，差异其实是非常小的，要解决这个问题，就要想办法放大这种差异。这里我们首先尝试带入模型的验证集上的平均准确率进行加权融合："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6c646f0f-ea39-4b76-aacb-eeb6f17a8739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8104888764656977, 0.7949637696740346, 0.8104878013818411]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 设置三个评估器的权重\n",
    "weight1 = lr_val_score\n",
    "weight2 = tree_val_score\n",
    "weight3 = RF_val_score\n",
    "\n",
    "weights = [weight1, weight2, weight3]\n",
    "\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0a8b2c4a-a7d4-48e5-b17d-20655ef03672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8260128739113972, 0.787052810902896)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 软投票\n",
    "Voting_soft_weight = VotingClassifier(estimators=estimators, \n",
    "                                      voting='soft', \n",
    "                                      weights=weights).fit(X_train_OE, y_train)\n",
    "\n",
    "Voting_soft_weight.score(X_train_OE, y_train), Voting_soft_weight.score(X_test_OE, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0d555573-3e8e-4621-ace8-ece7a6f86fc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8345323741007195, 0.7910278250993753)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 硬投票\n",
    "Voting_hard_weight = VotingClassifier(estimators=estimators, \n",
    "                                      voting='hard', \n",
    "                                      weights=weights).fit(X_train_OE, y_train)\n",
    "\n",
    "Voting_hard_weight.score(X_train_OE, y_train), Voting_hard_weight.score(X_test_OE, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2506df8f-c7a8-442c-80a3-976baa10a344",
   "metadata": {},
   "source": [
    "发现仍然没有任何区别。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6c4f10-9874-4dd5-8bb0-2924a8109568",
   "metadata": {},
   "source": [
    "&emsp;&emsp;接下来我们进一步考虑放大不同模型之间的差异，具体如何放大，其实很多时候都是“启发式”的，例如我们可以简单根据模型评分进行排序，效果最差的模型权重为1、次优的模型权重为2、最好的模型权重为3，此时就相当于次优的模型权重是最差的模型的两倍、最优的模型的权重是最差模型的3倍。接下来我们考虑分配随机森林3的权重，分配逻辑回归2的权重，而给决策树分配1的权重，测试结果如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "98978471-8c09-4871-84ef-01d9675db60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置三个评估器的权重\n",
    "weight1 = 2\n",
    "weight2 = 1\n",
    "weight3 = 3\n",
    "\n",
    "weights = [weight1, weight2, weight3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "25b73eb7-0347-49b2-a1b2-836ee5fe384b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8292313517606967, 0.787052810902896)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 软投票\n",
    "Voting_soft_weight = VotingClassifier(estimators=estimators, \n",
    "                                      voting='soft', \n",
    "                                      weights=weights).fit(X_train_OE, y_train)\n",
    "\n",
    "Voting_soft_weight.score(X_train_OE, y_train), Voting_soft_weight.score(X_test_OE, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c0e2d17a-aeb8-45cf-b532-7bb5bfa21412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8386974630821659, 0.7921635434412265)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 硬投票\n",
    "Voting_hard_weight = VotingClassifier(estimators=estimators, \n",
    "                                      voting='hard', \n",
    "                                      weights=weights).fit(X_train_OE, y_train)\n",
    "\n",
    "Voting_hard_weight.score(X_train_OE, y_train), Voting_hard_weight.score(X_test_OE, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d537a16-f817-45b9-a97b-48b002b9c514",
   "metadata": {},
   "source": [
    "能够发现，加权硬投票效果有进一步提升。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389231b4-6e9f-4437-affb-bf10cfb622cc",
   "metadata": {},
   "source": [
    "&emsp;&emsp;当然，接下来我们就可以根据这样的一个放大不同模型权重差异的思路进行更进一步的尝试，总的来说，我们可以模型排名的倒序为基础分配权重，然后不断尝试不断修改，修改的方向有三个，分别是放大差异、缩小差异以及分配不同差异，示例如下："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf5350b-5c49-47c1-838b-c5da46d7529c",
   "metadata": {},
   "source": [
    "<center><img src=\"https://s2.loli.net/2022/05/20/qCPHEsKRbzSDUGA.png\" alt=\"image-20220520162248584\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bb0afc-c4ba-46b9-ab04-e818af27b1f1",
   "metadata": {},
   "source": [
    "&emsp;&emsp;总结一下，如果想快速分配一组权重，则可以考虑经验法进行权重设置，一个行之有效的经验方法是根据模型效果（最好是平均交叉验证的得分）倒序排序，并以排序结果为权重开始进行尝试，可以适当放大、缩小或者分配不规则差异的权重给到不同的评估器。很多时候经过几轮尝试，就能得到一个相对较好的结果。甚至由于经验法本身的不严谨性，能对冲很多过拟合的风险。其次需要注意的则是不同分类器之间权重的差异，原则上效果越好的分类器应该分配更大的权重，但有的时候有些性能接近的分类器也可以分配差异比较大的权重。例如当前示例中，逻辑回归和随机森林两个模型表现性能类似，并且显著好于决策树，但并不代表三个模型分配类似4、1、5权重就一定更好，也可以尝试分配1、2、5，也就是说不同分类器性能差异程度并不能作为权重差异程度的依据。总而言之，经验法确定权重还是需要多尝试，同时在尝试的过程中积累更多的经验。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3d1701-6570-457e-89fd-3d83cd0f0adb",
   "metadata": {},
   "source": [
    "> 实际上在此前的Kaggle公开课Top 1%方案介绍中，加权融合的权重（2、3、5）就是一组经验值，很明显这里是分配了不规则缩小差异的权重。<center><img src=\"https://s2.loli.net/2022/05/20/Kc8qYji7apUmDEX.png\" alt=\"image-20220520162932801\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82cb28e-a9e3-409e-ba22-0b41644ae81a",
   "metadata": {},
   "source": [
    "&emsp;&emsp;对于上述经验法分配权重的过程需要注意，在反复的权重设置尝试过程中，极有可能逐渐给到标签最好的评估器非常大的权重，此时融合效果会逐渐向表现最好的模型靠拢，例如假设我们按照2、1、10给三个分类器设置权重，则最终输出结果如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "fae4d093-1836-46ea-8eea-5d99bcda908e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置三个评估器的权重\n",
    "weight1 = 2\n",
    "weight2 = 1\n",
    "weight3 = 10\n",
    "\n",
    "weights = [weight1, weight2, weight3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e90f1837-cfbc-4c0a-9353-2d402cc63cb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8396440742143128, 0.7927314026121521)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 软投票\n",
    "Voting_soft_weight = VotingClassifier(estimators=estimators, \n",
    "                                      voting='soft', \n",
    "                                      weights=weights).fit(X_train_OE, y_train)\n",
    "\n",
    "Voting_soft_weight.score(X_train_OE, y_train), Voting_soft_weight.score(X_test_OE, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d2e6f7f2-a84f-439f-84d4-d947620e89e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8483528966300644, 0.7955706984667802)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 硬投票\n",
    "Voting_hard_weight = VotingClassifier(estimators=estimators, \n",
    "                                      voting='hard', \n",
    "                                      weights=weights).fit(X_train_OE, y_train)\n",
    "\n",
    "Voting_hard_weight.score(X_train_OE, y_train), Voting_hard_weight.score(X_test_OE, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea2844d-550e-44d2-9ae9-bb29ae30ed39",
   "metadata": {},
   "source": [
    "能够发现，此时硬投票法的结果实际上就是RF_0的结果，如果出现了该情况，则可以考虑第二个思路，与其RF_0占比越大越好，不如我们就以RF_0为核心，剩下两个模型为辅助，设置一个差异更大的权重比例。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88ea7d3-f006-4818-aaab-2a4727aef47f",
   "metadata": {},
   "source": [
    "#### 3.2 思路二：设置核心评估器与辅助评估器"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c871773a-feb4-44bb-a633-fce0f82dd221",
   "metadata": {},
   "source": [
    "&emsp;&emsp;如果说此前的权重设计是按照比例来设计和调整，即按照1：2：3进行权重设计和调整，那么接下来如果考虑以RF_0为核心评估器，剩下的评估器为辅助评估器，则可以按照指数关系设计评估器权重，即按照1：10：100进行权重设计和调整。基本实现过程如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e6642d32-d1dd-4cd2-9331-3f647165b08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置三个评估器的权重\n",
    "weight1 = 10\n",
    "weight2 = 1\n",
    "weight3 = 100\n",
    "\n",
    "weights = [weight1, weight2, weight3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2e35e9ce-4ec5-4b60-a85b-3025fd5cfd9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8460810299129118, 0.7961385576377058)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 软投票\n",
    "Voting_soft_weight = VotingClassifier(estimators=estimators, \n",
    "                                      voting='soft', \n",
    "                                      weights=weights).fit(X_train_OE, y_train)\n",
    "\n",
    "Voting_soft_weight.score(X_train_OE, y_train), Voting_soft_weight.score(X_test_OE, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "17c2a792-320f-4be7-9edf-18a21a79c06b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8483528966300644, 0.7955706984667802)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 硬投票\n",
    "Voting_hard_weight = VotingClassifier(estimators=estimators, \n",
    "                                      voting='hard', \n",
    "                                      weights=weights).fit(X_train_OE, y_train)\n",
    "\n",
    "Voting_hard_weight.score(X_train_OE, y_train), Voting_hard_weight.score(X_test_OE, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640a2e17-bd86-475c-ab1f-2ff02b3ffded",
   "metadata": {},
   "source": [
    "&emsp;&emsp;能够发现，在按照指数级差异设计权重时，软投票得到了一个甚至比随机森林单模型更好的结果，这也是截止目前我们在该数据集上获得的最好效果，据此也能够看出模型融合的真实威力。并且此时测试集准确率和训练集准确率表现出了同步变化趋势，对于加权软投票过程来说，该结果既是训练集上的最高得分，同时也是测试集上的最高得分，因此该策略也是能在正常的建模流程中被筛选出来的（否则如果测试集评分高而训练集评分低，我们是无法根据训练集的结果选择该策略的）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716d1988-9060-4170-87e4-781ff2d738f4",
   "metadata": {},
   "source": [
    "|Models|train_score|test_score|\n",
    "|:--:|:--:|:--:|\n",
    "|logistic_search|0.8123|0.7836|\n",
    "|tree_model|0.7991|0.7683|\n",
    "|RF_0|0.8483|0.7955|\n",
    "|Voting_hard|0.8345|0.7910|\n",
    "|Voting_soft|0.8258|0.7870|\n",
    "|Voting_soft_em|0.8460|0.7961|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0c2eae-770c-4b3d-ada3-3ab1af1401d0",
   "metadata": {},
   "source": [
    "&emsp;&emsp;在根据指数级差异设计权重时，大多数情况下加权硬投票都会失效，其主要原因也是因为当只有三个评估器参与投票、而其中某个评估器的权重比其他所有评估器权重之和还要大的时候，其他评估器的票数总和也抵不上核心评估器的一票有效，因此最后投票输出结果必然是核心评估器这一个评估器的预测结果，而如此一来，融合也是去了其意义，因此一般来说，指数级权重差异设计并不适用于硬投票的情况。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199e2b88-13fc-4d13-8273-d279da97fc30",
   "metadata": {},
   "source": [
    "&emsp;&emsp;而软投票则有所不同，有的时候当核心评估器对某些样本“摇摆不定”时，微弱的来自其他评估器的概率值加合就可能影响最终的结果，例如假设RF_0核心评估器判断某样本属于1的概率为0.48，而决策树对其的预测概率为0.9，逻辑回归对其的预测概率为0.8，则最终概率融合的结果为："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "dd9e739d-0820-4da5-b414-551e3c8a5ab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5126126126126126"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.48 * 100 + 0.9 * 1 + 0.8 * 10) / 111"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64ba775-ac8d-4f1b-856f-dd1384190346",
   "metadata": {},
   "source": [
    "最后就会输出一个和核心评估器不一样的预测结果。而由于这种情况只会出现在辅助评估器给出非常肯定的判断、并且核心评估器摇摆不定的时候有效。而事实证明，这确实也是一种非常有效的融合策略——核心评估器为主，核心评估器拿不定注意的时候参考辅助评估器的意见。但是需要注意的是，如果更进一步方法指数级的差异的话，哪怕是软投票，辅助评估器也将因为权重太小而失去对最终融合结果的影响，即最终融合结果将输出和核心评估器完全一致的结果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "722a41c3-fd86-4e29-85cd-8926f50a4798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8477849299507763, 0.7955706984667802)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 设置三个评估器的权重\n",
    "weight1 = 100\n",
    "weight2 = 1\n",
    "weight3 = 10000\n",
    "\n",
    "weights = [weight1, weight2, weight3]\n",
    "\n",
    "# 软投票\n",
    "Voting_soft_weight = VotingClassifier(estimators=estimators, \n",
    "                                      voting='soft', \n",
    "                                      weights=weights).fit(X_train_OE, y_train)\n",
    "\n",
    "Voting_soft_weight.score(X_train_OE, y_train), Voting_soft_weight.score(X_test_OE, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cfec37-40d4-4555-a7f2-45fdd876355b",
   "metadata": {},
   "source": [
    "- 进一步手动优化权重"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712c0074-6054-44e6-8da0-0e446d046f55",
   "metadata": {},
   "source": [
    "&emsp;&emsp;那既然简单的指数级的差异权重设计有效，那是否能够在此基础上进一步优化权重呢？比如是否9：1：101会比10：1：100更好呢？一般来说，我们可以以训练集上的融合得分为依据，简单尝试在原有权重基础上进行小幅度的修改，并手动测试修改效果，如果能找到训练集上得分更高的一组权重，则可以该权重，反之则保留原始权重。同学们可以自己手动小幅修改权重并测试效果，对于该数据集来说，10:1:100权重附近并没有训练集上的更优解，因此这里保留这一权重设置。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a7e8cf-d273-4bfc-83fc-39effbb85eb8",
   "metadata": {},
   "source": [
    "> 这里需要注意，为何只能进行小幅修改，并且手动测试效果，而不是利用优化器进行高精度的搜索，甚至是权重+阈值进行协同搜索，其实也是因为高精度的阈值搜索极容易导致过拟合，这里我们采用更加原始更加简单的手动调整权重策略，看似精度不足，实际上是为了对冲过拟合风险。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3cce61-9bba-405f-abf1-d610f6f3ae67",
   "metadata": {},
   "source": [
    "- 删除决策树模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8202ba03-afc8-4af3-92bd-942a79c6c0a6",
   "metadata": {},
   "source": [
    "&emsp;&emsp;根据上述实践我们发现，决策树模型权重占比非常小时，模型效果会更好，那么是不是说明决策树几乎没有对融合效果提升提供任何贡献，甚至是对最终融合结果有负面影响呢？这里我们可以简单测试删除决策树模型后、逻辑回归和随机森林按照1:10的权重融合后的结果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "c5ca9789-3b3a-4fb4-b0dd-6e2fc6758a51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8460810299129118, 0.7961385576377058)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 设置三个评估器的权重\n",
    "weight1 = 1\n",
    "weight2 = 0\n",
    "weight3 = 10\n",
    "\n",
    "weights = [weight1, weight2, weight3]\n",
    "\n",
    "# 软投票\n",
    "Voting_soft_weight = VotingClassifier(estimators=estimators, \n",
    "                                      voting='soft', \n",
    "                                      weights=weights).fit(X_train_OE, y_train)\n",
    "\n",
    "Voting_soft_weight.score(X_train_OE, y_train), Voting_soft_weight.score(X_test_OE, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234a6012-ffef-45ab-9fe0-1c7b4aa8f253",
   "metadata": {},
   "source": [
    "能够发现，剔除决策树模型并不会对结果有任何影响，这其实也从侧面说明决策树模型或许对当前的加权融合过程没有起到正面的作用。实际上，后面会详细说明，带入一个效果比较“脱节”的模型，将极大程度影响融合的效果和效率，也正因如此，训练出一组效果较好的模型是融合的前提。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010da759-8ad2-4bea-88ed-40d82bbaaa6c",
   "metadata": {},
   "source": [
    "## 四、权重的超参数搜索策略"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db44096-9759-4ee2-b73b-ef712a2b53a1",
   "metadata": {},
   "source": [
    "&emsp;&emsp;其实除了经验法外，很多时候，我们也能将权重视作超参数带入优化器进行搜索，也就是此前介绍过的——交叉验证+超参数搜索方法。没错，和阈值一样，加权融合中的权重也可以视作超参数，通过优化器搜索得到一组更好的结果。甚至我们可以同步搜索投票方式以及阈值，以期得到一组更好的结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65dfcc4-d584-4254-b533-da92722cab68",
   "metadata": {},
   "source": [
    "> 如果理论层面能给出最优解的计算流程，则影响结果的变量就是参数，反之则是超参数。这也是为何我们要先确定理论层面最有结论不可用之后再介绍超参数搜索方法的原因。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7141bb1-b321-4823-b0b5-851d25410dea",
   "metadata": {},
   "source": [
    "&emsp;&emsp;不过需要注意的是，伴随着搜索的参数数量越来越多（假设空间越来越大），简单的超参数搜索策略会遇到严重的过拟合问题，这是加权融合算法底层的问题，通过简单的交叉验证并不能有效的解决。我们可以简单进行测试，看下这个过拟合问题的具体表现，然后再考虑如何进行改进。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86073449-3c6a-44af-8b56-4aa58707efc0",
   "metadata": {},
   "source": [
    "### 1.权重搜索的过拟合问题"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8a99c7-7b4f-4ffc-b102-42a2d3d55cd2",
   "metadata": {},
   "source": [
    "&emsp;&emsp;这里我们可以创建一个和阈值移动类似的超参数搜索流程，即以投票法的交叉验证结果（的负数）作为目标函数，带入TPE搜索，得出一组最优的权重，需要注意的是，阈值和投票方法同样也可以作为超参数，和权重参数共同进行超参数搜索。由此创建超参数搜索空间如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "9d170582-b1e8-4f67-a06a-8896ae456804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义超参数空间\n",
    "params_space = {'voting':hp.choice(\"voting\", ['soft', 'hard']),\n",
    "                'thr': hp.uniform(\"thr\", 0.4, 0.6), \n",
    "                'weight1': hp.uniform(\"weight1\",0,1),\n",
    "                'weight2': hp.uniform(\"weight2\",0,1),\n",
    "                'weight3': hp.uniform(\"weight3\",0,1)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5711c18-b207-4897-b33c-fecc6b6a764e",
   "metadata": {},
   "source": [
    "这里需要注意，对于权重的超参数搜索空间，由于都是等比放缩（例如$\\frac{[2,3,5]}{2+3+5}$其实和$\\frac{[0.2,0.3,0.5]}{0.2+0.3+0.5}$等价），因此原则上是可以设置任意范围的，只要不同的参数设置相同范围即可，例如可以将三个参数的搜索空间都设置为0-1、0-10或者0-100等；此外由于voting参数是在两个字符串（相当于离散变量）中进行进行搜索，因此采用choice创建搜索空间。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ed1ba7-82c5-4972-b8df-7ddb64e7f750",
   "metadata": {},
   "source": [
    "&emsp;&emsp;然后定义目标函数，此时尽管参数较多，但只需对号入座带入评估器即可："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "8d7e1442-93c8-4fb1-b68a-cdddaab50ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义目标函数\n",
    "def hyperopt_objective_weight(params):\n",
    "    voting = params['voting']\n",
    "    thr = params['thr']\n",
    "    weight1 = params['weight1']\n",
    "    weight2 = params['weight2']\n",
    "    weight3 = params['weight3']\n",
    "    \n",
    "    weights = [weight1, weight2, weight3]\n",
    "    \n",
    "    # 创建带阈值的平均法评估器\n",
    "    VC_weight_search = VotingClassifier_threshold(estimators=estimators, \n",
    "                                                  weights=weights,\n",
    "                                                  voting=voting, \n",
    "                                                  thr=thr)\n",
    "\n",
    "    # 输出验证集上的平均得分\n",
    "    val_score = cross_val_score(VC_weight_search, \n",
    "                                X_train_OE, \n",
    "                                y_train, \n",
    "                                scoring='accuracy', \n",
    "                                n_jobs=15,\n",
    "                                cv=3).mean()\n",
    "    \n",
    "    return -val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bc430e-9835-4bca-8319-1b0961ab7a40",
   "metadata": {},
   "source": [
    "最后是定义优化函数:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "33e1d4ae-64ca-451a-9f39-cbe35a8824c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义优化函数\n",
    "def param_hyperopt_weight(max_evals):\n",
    "    params_best = fmin(fn = hyperopt_objective_weight,\n",
    "                       space = params_space,\n",
    "                       algo = tpe.suggest,\n",
    "                       max_evals = max_evals, \n",
    "                       rstate = np.random.default_rng(17))    \n",
    "    return params_best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fedbf3-abb3-4e98-89b1-2bb0fb9654e1",
   "metadata": {},
   "source": [
    "然后尝试执行搜索："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "eb1d7f4b-64a6-4117-b8d2-7b62df7081d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 3000/3000 [11:13<00:00,  4.45trial/s, best loss: -0.8114362319962831]\n"
     ]
    }
   ],
   "source": [
    "params_best = param_hyperopt_weight(3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "b8c5e5a4-a215-4135-98c4-3d0e0df04da1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'thr': 0.458551177777603,\n",
       " 'voting': 0,\n",
       " 'weight1': 0.9402201650890749,\n",
       " 'weight2': 0.0003628980064737191,\n",
       " 'weight3': 0.7767094520146229}"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d57eb1-ff0e-448c-9869-fd378abb506d",
   "metadata": {},
   "source": [
    "由此即搜索出了一组在验证集上表现最好的一组超参数，并且和经验法尝试的结果有点类似，给了第二个模型非常小的权重，二此时验证集的平均得分为0.8114，其实在验证集上的表现并不差。接下来测试改组参数在训练集和测试集上的表现，我们通过定义一个函数来快速计算训练集和测试上的准确率："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e2c111fa-48f7-4df3-9bbb-28fd35d26342",
   "metadata": {},
   "outputs": [],
   "source": [
    "def params_accuracy_score(params, remove_voting=False, remove_weight3=False):\n",
    "    \n",
    "    thr = params['thr']\n",
    "    weight1 = params['weight1']\n",
    "    weight2 = params['weight2']\n",
    "    \n",
    "    if remove_voting:\n",
    "        voting = 'soft'\n",
    "    else:\n",
    "        voting = ['soft', 'hard'][params['voting']]\n",
    "    \n",
    "    if remove_weight3:\n",
    "        weights = [weight1, 0, weight2]\n",
    "\n",
    "    else:\n",
    "        weight3 = params['weight3']\n",
    "        weights = [weight1, weight2, weight3]\n",
    "    \n",
    "    \n",
    "    VC = VotingClassifier_threshold(estimators, \n",
    "                                    weights=weights, \n",
    "                                    voting=voting, \n",
    "                                    thr=thr).fit(X_train_OE, y_train)\n",
    "    \n",
    "    acc_train = VC.score(X_train_OE, y_train)\n",
    "    acc_test = accuracy_score(VC.predict(X_test_OE), y_test)\n",
    "    print('train_accuracy: %0.8f' % acc_train)\n",
    "    print('test_accuracy: %0.8f' % acc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea158be-3616-43f4-a240-656da7e6dc98",
   "metadata": {},
   "source": [
    "尝试计算训练集和测试集上的准确率："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "f36c645a-9e72-4ab4-939d-256c1735769e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_accuracy: 0.83017796\n",
      "test_accuracy: 0.78875639\n"
     ]
    }
   ],
   "source": [
    "params_accuracy_score(params_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97779fff-6cb2-47f0-a792-c2997360c6c0",
   "metadata": {},
   "source": [
    "能够发现，当前融合结果在测试集上的表现非常一般，和验证集、训练集的准确率相差较大，存在较为严重的过拟合现象。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ac971d-14ee-4604-9148-dd46fdef4366",
   "metadata": {},
   "source": [
    "### 2.权重搜索的过拟合原因与改进方案"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bcc55f2-cfc3-4b47-99bc-f6b52c88160a",
   "metadata": {},
   "source": [
    "- 权重搜索过拟合问题原因"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96281323-cc0b-43d1-9a9c-7c37bca10c33",
   "metadata": {},
   "source": [
    "&emsp;&emsp;需要注意的是，这里其实是遇到了一个非常严重的问题，即验证集结果和测试集结果不一致的问题。这里我们可以把权重这一超参数的搜索过程类比于一个模型训练的过程，此前曾经讨论过，如果训练集和测试集结果不一致，则说明模型存在过拟合，此时需要引入验证集来模拟模型在测试集上的表现，从而调整训练过程，并借此提高模型泛化能力，这也是网格搜索超参数优化的基础。但是，现在遇到的问题是，模型在验证集上能得到一个不错的结果，但仍然无法在测试集上获得相类似的好的结果，这到底是什么原因呢？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce4b098-1b18-4fa9-a373-307d4630cc0f",
   "metadata": {},
   "source": [
    "&emsp;&emsp;首先同时也是最根本的问题，在于加权融合这个“模型”（或者说算法）本身的泛化能力。我们知道，任何通用有效的机器学习算法其实都是有一整套完整的计算流程和模型框架的，这个基本框架也是经过理论验证切实有效的，例如线性模型实际上是基于线性方程的框架进行的模型设计，决策树模型底层实际上是一个分层的决策流程，我们训练模型实际上训练的就是这个框架的参数，如线性方程的系数、决策树的分叉节点、决策树的深度等，而模型预测时也是依据这个框架来进行判别，例如带入数据到线性方程中算出预测结果，带入数据到决策树中进行判别等，这些模型的训练和预测都是通过这个算法框架来执行。而反观加权融合这个“模型”，我们只是希望三组数以一个最佳的权重加出一个最好的结果，尽管这个过程足够灵活，但其底层没有受到任何模型框架的约束。而正是因为这个底层框架的缺失，导致其泛化能力有限。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feaf105a-90e6-45c0-afbc-47fc457a4a5a",
   "metadata": {},
   "source": [
    "> 此外需要注意的是，关于模型融合方法的过拟合问题，不仅仅只存在于加权融合的过程，包括后续要介绍的Stacking等方法也都存在较为严重的过拟合问题。所以了解导致过拟合问题的根本原因以及相应的解决策略，是学习模型融合部分内容的重中之重。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c194aee8-8450-402f-a615-42fff81b6aa3",
   "metadata": {},
   "source": [
    "- 改进策略一：手动修改参数空间"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee29741-28b2-4720-8b8d-cd8d6a00db3e",
   "metadata": {},
   "source": [
    "&emsp;&emsp;那么要怎么改进这一问题，首先最简单高效的方法就是手动调整参数搜索空间，以此排除掉那些在验证集上表现较好但测试集上表现一般的备选参数组，以此来提升权重搜索的泛化能力。那要如何调整搜索空间呢？其实最高效的方法就是借助此前经验法得到的基本结论来调整搜索空间，此前根据经验法我们已经判断，三个模型的权重比例在10:1:100的时候融合结果能有较好的表现，并且在权重差异非常大的时候，软投票效果肯定好于硬投票，那么接下来我们就可以以此为依据，将不同权重设置不同区间来进行搜索，例如可以设置如下区间进行搜索，同时删除对投票方法的搜索："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "3b94356f-4cf7-4a62-8bdd-c1ac812509ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义超参数空间\n",
    "params_space = {'thr': hp.uniform(\"thr\", 0.4, 0.6), \n",
    "                'weight1': hp.uniform(\"weight1\",0.05,0.1),\n",
    "                'weight2': hp.uniform(\"weight2\",0,0.01),\n",
    "                'weight3': hp.uniform(\"weight3\",0.5,1)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fc0d46-5560-45ce-b7a4-0c2dc1a448da",
   "metadata": {},
   "source": [
    "当然，这个过程其实也就相当于是经验法挑选阈值+超参数搜索阈值结合的过程。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c77189-1dbf-4925-bcad-b78c79b3293c",
   "metadata": {},
   "source": [
    "> 甚至我们可以将决策树模型踢出融合过程，仅带入逻辑回归和随机森林进行融合，以此进一步搜索搜索空间，或许能达到更好的效果。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbb3953-edad-4122-a4fc-ff8f30fca217",
   "metadata": {},
   "source": [
    "- 改进策略二：强化信息隔离，提升验证集效力"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd19965-92ff-4bdc-8e7e-b8e16a07e6dc",
   "metadata": {},
   "source": [
    "&emsp;&emsp;那么第二种改进策略，则是在模型训练过程中彻底阻隔验证集的影响，以提升验证集的“验证”方面的效力。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d84c940-5bfa-4587-b62e-693f8a42920f",
   "metadata": {},
   "source": [
    "&emsp;&emsp;这点该怎么理解？首先，我们知道现在带入进行融合的这三个模型原始状态下是在全部训练集上训练的结果，包括模型的参数和超参数。尽管我们在调用cross_val_score函数进行交叉验证的时候，实际上是在训练集中再进行了（五折）划分，然后用不同数据训练了5个模型，但是需要注意的是，这个阶段训练的是模型的参数，而不是超参数，也就是说每个模型经过cross_val_score训练得到的5个模型，其实是拥有和原始模型相同的超参数，而这些超参数实际上是在全部数据集上训练得到，也就是说，cross_val_score训练得出的模型其实早已被泄露了验证集的信息，而泄露的途径实际上就是这些模型共同的超参数。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc5a262-b799-4b56-a18d-ba03f7300d08",
   "metadata": {},
   "source": [
    "<center><img src=\"https://s2.loli.net/2022/05/18/1UAlpgwt2mSbTQ5.png\" alt=\"image-20220518205529331\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a25949-49e9-4c5b-9597-a4eaf0771f0c",
   "metadata": {},
   "source": [
    "那么要如何改进这个问题，很简单，我们只需要手动划分训练集和验证集，然后单独在划分后的训练集上进行模型训练和超参数搜索即可，由此一来即可避免验证集信息泄露的问题，从而提高验证集结果的可信度，进而提升交叉验证结果的泛化能力。不过需要注意的是，这么做其实会降低每个单独模型的预测能力（训练超参数的数据量变少了），但整体来看能提升融合结果的泛化能力。并且，这不仅是加权融合过程的需要，也是下一小节将要介绍的Stacking方法的需要。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0367bd9e-8fa0-42c3-b0ce-91dcdddeb247",
   "metadata": {},
   "source": [
    "- 改进策略三：用模型代替搜索"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ed70a4-878e-46c7-9a4f-9edea0421d42",
   "metadata": {},
   "source": [
    "&emsp;&emsp;既然阈值搜索容易导致过拟合问题的根源在于没有模型框架，那么釜底抽薪之计当然就是考虑采用某个成熟的机器学习模型来代替这个搜索的过程。我们先来回顾下加权融合的整个过程，其实所谓的加权融合，其实就是根据单独模型的预测结果，通过加权求和以及一个分段函数输出结果，并用这个结果尽可能去拟合真实标签，不难发现，其实这个过程的本质就是用一组连续变量（各模型的预测结果）去拟合真实标签，其实也就是一个分类问题，完全可以由很多机器学习模型来完成。当然，如果是硬投票的加权融合过程，则是根据离散变量去拟合离散变量。而无论哪种情况，只要是这个预测过程采用机器学习模型，其本质就不再是加权融合了，而是一种名为Stacking的融合方法。这一小节我们重点介绍前两种改进策略，Stacking融合会在下一小节介绍。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5750525f-bfb2-41b7-8d2b-09ccad367613",
   "metadata": {},
   "source": [
    "<center><img src=\"https://s2.loli.net/2022/05/22/eGR4Cl3dsFDpAES.png\" alt=\"image-20220522174140320\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696cf929-a8bf-44d5-ae40-7d17e52427e4",
   "metadata": {},
   "source": [
    "> 尽管Stacking过程看似采用了机器学习模型代替了加权的过程，但该方法也有一定程度的过拟合问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fa4069-5717-4fd7-b46a-7375a845d531",
   "metadata": {},
   "source": [
    "### 3.通过裁剪搜索空间提高权重搜索的泛化能力"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57472bfd-27c8-467e-9cf2-3cde84260c3b",
   "metadata": {},
   "source": [
    "&emsp;&emsp;接下来我们首先测试第一种改进方案，即根据经验法得出的基本结论，对搜索空间进行差异化设置，即创建如下搜索空间并带入进行TPE搜索："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e817ab1c-6a0d-4e66-aeb2-b629f2e90196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义超参数空间\n",
    "params_space = {'thr': hp.uniform(\"thr\", 0.4, 0.6), \n",
    "                'weight1': hp.uniform(\"weight1\",0.05,0.1),\n",
    "                'weight2': hp.uniform(\"weight2\",0,0.01),\n",
    "                'weight3': hp.uniform(\"weight3\",0.5,1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cba75971-c89a-4840-a1c8-46a59384a334",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 定义目标函数\n",
    "def hyperopt_objective_weight(params):\n",
    "    thr = params['thr']\n",
    "    weight1 = params['weight1']\n",
    "    weight2 = params['weight2']\n",
    "    weight3 = params['weight3']\n",
    "    \n",
    "    weights = [weight1, weight2, weight3]\n",
    "    \n",
    "    # 创建带阈值的平均法评估器\n",
    "    VC_weight_search = VotingClassifier_threshold(estimators=estimators, \n",
    "                                                  weights=weights,\n",
    "                                                  voting='soft', \n",
    "                                                  thr=thr)\n",
    "\n",
    "    # 输出验证集上的平均得分\n",
    "    val_score = cross_val_score(VC_weight_search, \n",
    "                                X_train_OE, \n",
    "                                y_train, \n",
    "                                scoring='accuracy', \n",
    "                                n_jobs=15,\n",
    "                                cv=5).mean()\n",
    "    \n",
    "    return -val_score\n",
    "\n",
    "# 定义优化函数\n",
    "def param_hyperopt_weight(max_evals):\n",
    "    params_best = fmin(fn = hyperopt_objective_weight,\n",
    "                       space = params_space,\n",
    "                       algo = tpe.suggest,\n",
    "                       max_evals = max_evals, \n",
    "                       rstate = np.random.default_rng(22))    \n",
    "    return params_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5bb42e46-6ff8-455f-ab86-04b3a76cb7e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 500/500 [01:55<00:00,  4.33trial/s, best loss: -0.8102980490811615]\n"
     ]
    }
   ],
   "source": [
    "params_best = param_hyperopt_weight(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "5816c90b-b8f2-47e7-8319-f3f033294d4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8102980490811615"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.8102980490811615"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "a14bd2c3-6a79-4b56-abdc-9c6082255196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'thr': 0.5009273257651501,\n",
       " 'weight1': 0.05948568915156588,\n",
       " 'weight2': 0.003987464837297394,\n",
       " 'weight3': 0.9424491355599727}"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "a92f94a0-898c-4222-b92a-f4dd8225eb15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_accuracy: 0.84645967\n",
      "test_accuracy: 0.79670642\n"
     ]
    }
   ],
   "source": [
    "params_accuracy_score(params_best, remove_voting=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff64bdf2-298d-42c9-b193-8ed43d827b80",
   "metadata": {},
   "source": [
    "能够发现，模型搜索得到了一个比简单的10:1:100更好的结果。当然，该结果也是截止目前获得的最好的结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d0cc5d-a8ea-45cd-8bb0-85a111492d46",
   "metadata": {
    "tags": []
   },
   "source": [
    "|Models|train_score|test_score|\n",
    "|:--:|:--:|:--:|\n",
    "|logistic_search|0.8123|0.7836|\n",
    "|tree_model|0.7991|0.7683|\n",
    "|RF_0|0.8483|0.7955|\n",
    "|Voting_hard|0.8345|0.7910|\n",
    "|Voting_soft|0.8258|0.7870|\n",
    "|Voting_soft_em|0.8460|0.7961|\n",
    "|Voting_soft_ws|0.8464|0.7967|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
