{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78adfc97-41d3-49b3-acfc-ceaae681de0d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# <center> 【Kaggle】Telco Customer Churn 电信用户流失预测案例"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63ecdd2-8e1f-44bd-9b7b-7d8ad7a4afc5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a123dd-1381-45a6-abae-4215d606a5d4",
   "metadata": {},
   "source": [
    "## <font face=\"仿宋\">第四部分导读"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5e9afc-af04-49f4-938d-d91914fb1ec6",
   "metadata": {},
   "source": [
    "&emsp;&emsp;<font face=\"仿宋\">在案例的第二、三部分中，我们详细介绍了关于特征工程的各项技术，特征工程技术按照大类来分可以分为数据预处理、特征衍生、特征筛选三部分，其中特征预处理的目的是为了将数据集整理、清洗到可以建模的程度，具体技术包括缺失值处理、异常值处理、数据重编码等，是建模之前必须对数据进行的处理和操作；而特征衍生和特征筛选则更像是一类优化手段，能够帮助模型突破当前数据集建模的效果上界。并且我们在第二部分完整详细的介绍机器学习可解释性模型的训练、优化和解释方法，也就是逻辑回归和决策树模型。并且此前我们也一直以这两种算法为主，来进行各个部分的模型测试。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8afdcf-1840-462e-b07a-5e9dedf773b7",
   "metadata": {},
   "source": [
    "&emsp;&emsp;<font face=\"仿宋\">而第四部分，我们将开始介绍集成学习的训练和优化的实战技巧，尽管从可解释性角度来说，集成学习的可解释性并不如逻辑回归和决策树，但在大多数建模场景下，集成学习都将获得一个更好的预测结果，这也是目前效果优先的建模场景下最常使用的算法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c7d640-ab5b-44be-9222-a557ea1ceb17",
   "metadata": {},
   "source": [
    "&emsp;&emsp;<font face=\"仿宋\">总的来说，本部分内容只有一个目标，那就是借助各类优化方法，抵达每个主流集成学习的效果上界。换而言之，本部分我们将围绕单模优化策略展开详细的探讨，涉及到的具体集成学习包括随机森林、XGBoost、LightGBM、和CatBoost等目前最主流的集成学习算法，而具体的优化策略则包括超参数优化器的使用、特征衍生和筛选方法的使用、单模型自融合方法的使用，这些优化方法也是截至目前，提升单模效果最前沿、最有效、同时也是最复杂的方法。其中有很多较为艰深的理论，也有很多是经验之谈，但无论如何，我们希望能够围绕当前数据集，让每个集成学习算法优化到极限。值得注意的是，在这个过程中，我们会将此前介绍的特征衍生和特征筛选视作是一种模型优化方法，衍生和筛选的效果，一律以模型的最终结果来进行评定。而围绕集成学习进行海量特征衍生和筛选，也才是特征衍生和筛选技术能发挥巨大价值的主战场。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1e932c-eb91-4890-b072-026eafd21fd5",
   "metadata": {},
   "source": [
    "&emsp;&emsp;<font face=\"仿宋\">而在抵达了单模的极限后，我们就会进入到下一阶段，也就是模型融合阶段。需要知道的是，只有单模的效果到达了极限，进一步的多模型融合、甚至多层融合，才是有意义的，才是有效果的。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2020fe-301f-400c-841e-c2631e3d554a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f37d15-f038-4fd1-bbb2-56cf97c2329c",
   "metadata": {},
   "source": [
    "# <center>Part 4.集成算法的训练与优化技巧"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "1550dd26-3a55-437a-ab8e-9942dbb96d0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 基础数据科学运算库\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 可视化库\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 时间模块\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# sklearn库\n",
    "# 数据预处理\n",
    "from sklearn import preprocessing\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# 实用函数\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 常用评估器\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "# 网格搜索\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 自定义评估器支持模块\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, ClassifierMixin\n",
    "\n",
    "# 自定义模块\n",
    "from telcoFunc import *\n",
    "# 导入特征衍生模块\n",
    "import features_creation as fc\n",
    "from features_creation import *\n",
    "\n",
    "# re模块相关\n",
    "import inspect, re\n",
    "\n",
    "# 其他模块\n",
    "from tqdm import tqdm\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292c14d0-283a-45a4-9e04-92ecd57e2cdc",
   "metadata": {},
   "source": [
    "&emsp;&emsp;然后执行Part 1中的数据清洗相关工作："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "id": "f9d8884a-507a-43d7-ba2c-432b19613fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "tcc = pd.read_csv('WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
    "\n",
    "# 标注连续/离散字段\n",
    "# 离散字段\n",
    "category_cols = ['gender', 'SeniorCitizen', 'Partner', 'Dependents',\n",
    "                'PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', \n",
    "                'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling',\n",
    "                'PaymentMethod']\n",
    "\n",
    "# 连续字段\n",
    "numeric_cols = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
    " \n",
    "# 标签\n",
    "target = 'Churn'\n",
    "\n",
    "# ID列\n",
    "ID_col = 'customerID'\n",
    "\n",
    "# 验证是否划分能完全\n",
    "assert len(category_cols) + len(numeric_cols) + 2 == tcc.shape[1]\n",
    "\n",
    "# 连续字段转化\n",
    "tcc['TotalCharges']= tcc['TotalCharges'].apply(lambda x: x if x!= ' ' else np.nan).astype(float)\n",
    "tcc['MonthlyCharges'] = tcc['MonthlyCharges'].astype(float)\n",
    "\n",
    "# 缺失值填补\n",
    "tcc['TotalCharges'] = tcc['TotalCharges'].fillna(0)\n",
    "\n",
    "# 标签值手动转化 \n",
    "tcc['Churn'].replace(to_replace='Yes', value=1, inplace=True)\n",
    "tcc['Churn'].replace(to_replace='No',  value=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "a5686011-445d-42a5-bbb2-29a199573774",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = tcc.drop(columns=[ID_col, target]).copy()\n",
    "labels = tcc['Churn'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b3af7a-c6f4-4d06-8ddc-921094d96644",
   "metadata": {},
   "source": [
    "&emsp;&emsp;同时，创建自然编码后的数据集以及经过时序特征衍生的数据集："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "6767994c-5ed8-48b8-a83b-8b1a4d86e9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分训练集和测试集\n",
    "train, test = train_test_split(tcc, random_state=22)\n",
    "\n",
    "X_train = train.drop(columns=[ID_col, target]).copy()\n",
    "X_test = test.drop(columns=[ID_col, target]).copy()\n",
    "\n",
    "y_train = train['Churn'].copy()\n",
    "y_test = test['Churn'].copy()\n",
    "\n",
    "X_train_seq = pd.DataFrame()\n",
    "X_test_seq = pd.DataFrame()\n",
    "\n",
    "# 年份衍生\n",
    "X_train_seq['tenure_year'] = ((72 - X_train['tenure']) // 12) + 2014\n",
    "X_test_seq['tenure_year'] = ((72 - X_test['tenure']) // 12) + 2014\n",
    "\n",
    "# 月份衍生\n",
    "X_train_seq['tenure_month'] = (72 - X_train['tenure']) % 12 + 1\n",
    "X_test_seq['tenure_month'] = (72 - X_test['tenure']) % 12 + 1\n",
    "\n",
    "# 季度衍生\n",
    "X_train_seq['tenure_quarter'] = ((X_train_seq['tenure_month']-1) // 3) + 1\n",
    "X_test_seq['tenure_quarter'] = ((X_test_seq['tenure_month']-1) // 3) + 1\n",
    "\n",
    "# 独热编码\n",
    "enc = preprocessing.OneHotEncoder()\n",
    "enc.fit(X_train_seq)\n",
    "\n",
    "seq_new = list(X_train_seq.columns)\n",
    "\n",
    "# 创建带有列名称的独热编码之后的df\n",
    "X_train_seq = pd.DataFrame(enc.transform(X_train_seq).toarray(), \n",
    "                           columns = cate_colName(enc, seq_new, drop=None))\n",
    "\n",
    "X_test_seq = pd.DataFrame(enc.transform(X_test_seq).toarray(), \n",
    "                          columns = cate_colName(enc, seq_new, drop=None))\n",
    "\n",
    "# 调整index\n",
    "X_train_seq.index = X_train.index\n",
    "X_test_seq.index = X_test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "b82772b1-3517-425c-9bf8-d8fae64cd05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ord_enc = OrdinalEncoder()\n",
    "ord_enc.fit(X_train[category_cols])\n",
    "\n",
    "X_train_OE = pd.DataFrame(ord_enc.transform(X_train[category_cols]), columns=category_cols)\n",
    "X_train_OE.index = X_train.index\n",
    "X_train_OE = pd.concat([X_train_OE, X_train[numeric_cols]], axis=1)\n",
    "\n",
    "X_test_OE = pd.DataFrame(ord_enc.transform(X_test[category_cols]), columns=category_cols)\n",
    "X_test_OE.index = X_test.index\n",
    "X_test_OE = pd.concat([X_test_OE, X_test[numeric_cols]], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc45f1f-a9f3-4802-8ae6-f105889766e9",
   "metadata": {},
   "source": [
    "然后是模型融合部分所需的第三方库、准备的数据以及训练好的模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "fdceb7c0-21d4-4b06-948a-6d1dc652640e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 本节新增第三方库\n",
    "from joblib import dump, load\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from hyperopt import hp, fmin, tpe\n",
    "from numpy.random import RandomState\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "ce113e87-b4ff-44ac-9268-12e7b734d7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VotingClassifier_threshold(BaseEstimator, ClassifierMixin, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, estimators, voting='hard', weights=None, thr=0.5):\n",
    "        self.estimators = estimators\n",
    "        self.voting = voting\n",
    "        self.weights = weights\n",
    "        self.thr = thr\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        VC = VotingClassifier(estimators = self.estimators, \n",
    "                              voting = self.voting, \n",
    "                              weights = self.weights)\n",
    "        \n",
    "        VC.fit(X, y)\n",
    "        self.clf = VC\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    def predict_proba(self, X):\n",
    "        if self.voting == 'soft':\n",
    "            res_proba = self.clf.predict_proba(X)\n",
    "        else:\n",
    "            res_proba = None\n",
    "        return res_proba\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if self.voting == 'soft':\n",
    "            res = (self.clf.predict_proba(X)[:, 1] >= self.thr) * 1\n",
    "        else:\n",
    "            res = self.clf.predict(X)\n",
    "        return res\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        acc = accuracy_score(self.predict(X), y)\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "id": "913025c9-fb90-4688-96ad-1564591d4dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实例化KFold评估器\n",
    "kf = KFold(n_splits=5, random_state=12, shuffle=True)\n",
    "\n",
    "# 重置训练集和测试集的index\n",
    "X_train_OE = X_train_OE.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "\n",
    "train_part_index_l = []\n",
    "eval_index_l = []\n",
    "\n",
    "for train_part_index, eval_index in kf.split(X_train_OE, y_train):\n",
    "    train_part_index_l.append(train_part_index)\n",
    "    eval_index_l.append(eval_index)\n",
    "    \n",
    "# 训练集特征\n",
    "X_train1 = X_train_OE.loc[train_part_index_l[0]]\n",
    "X_train2 = X_train_OE.loc[train_part_index_l[1]]\n",
    "X_train3 = X_train_OE.loc[train_part_index_l[2]]\n",
    "X_train4 = X_train_OE.loc[train_part_index_l[3]]\n",
    "X_train5 = X_train_OE.loc[train_part_index_l[4]]\n",
    "\n",
    "# 验证集特征\n",
    "X_eval1 = X_train_OE.loc[eval_index_l[0]]\n",
    "X_eval2 = X_train_OE.loc[eval_index_l[1]]\n",
    "X_eval3 = X_train_OE.loc[eval_index_l[2]]\n",
    "X_eval4 = X_train_OE.loc[eval_index_l[3]]\n",
    "X_eval5 = X_train_OE.loc[eval_index_l[4]]\n",
    "\n",
    "# 训练集标签\n",
    "y_train1 = y_train.loc[train_part_index_l[0]]\n",
    "y_train2 = y_train.loc[train_part_index_l[1]]\n",
    "y_train3 = y_train.loc[train_part_index_l[2]]\n",
    "y_train4 = y_train.loc[train_part_index_l[3]]\n",
    "y_train5 = y_train.loc[train_part_index_l[4]]\n",
    "\n",
    "# 验证集标签\n",
    "y_eval1 = y_train.loc[eval_index_l[0]]\n",
    "y_eval2 = y_train.loc[eval_index_l[1]]\n",
    "y_eval3 = y_train.loc[eval_index_l[2]]\n",
    "y_eval4 = y_train.loc[eval_index_l[3]]\n",
    "y_eval5 = y_train.loc[eval_index_l[4]]\n",
    "\n",
    "train_set = [(X_train1, y_train1), \n",
    "             (X_train2, y_train2), \n",
    "             (X_train3, y_train3), \n",
    "             (X_train4, y_train4), \n",
    "             (X_train5, y_train5)]\n",
    "\n",
    "eval_set = [(X_eval1, y_eval1), \n",
    "            (X_eval2, y_eval2), \n",
    "            (X_eval3, y_eval3), \n",
    "            (X_eval4, y_eval4), \n",
    "            (X_eval5, y_eval5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "id": "9af21c3f-a3a4-4114-b4e0-613f2b43a298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 随机森林模型组\n",
    "grid_RF_1 = load('./models/grid_RF_1.joblib') \n",
    "grid_RF_2 = load('./models/grid_RF_2.joblib') \n",
    "grid_RF_3 = load('./models/grid_RF_3.joblib') \n",
    "grid_RF_4 = load('./models/grid_RF_4.joblib') \n",
    "grid_RF_5 = load('./models/grid_RF_5.joblib') \n",
    "\n",
    "RF_1 = grid_RF_1.best_estimator_\n",
    "RF_2 = grid_RF_2.best_estimator_\n",
    "RF_3 = grid_RF_3.best_estimator_\n",
    "RF_4 = grid_RF_4.best_estimator_\n",
    "RF_5 = grid_RF_5.best_estimator_\n",
    "\n",
    "RF_l = [RF_1, RF_2, RF_3, RF_4, RF_5]\n",
    "\n",
    "# 决策树模型组\n",
    "grid_tree_1 = load('./models/grid_tree_1.joblib')\n",
    "grid_tree_2 = load('./models/grid_tree_2.joblib')\n",
    "grid_tree_3 = load('./models/grid_tree_3.joblib')\n",
    "grid_tree_4 = load('./models/grid_tree_4.joblib')\n",
    "grid_tree_5 = load('./models/grid_tree_5.joblib')\n",
    "\n",
    "tree_1 = grid_tree_1.best_estimator_\n",
    "tree_2 = grid_tree_2.best_estimator_\n",
    "tree_3 = grid_tree_3.best_estimator_\n",
    "tree_4 = grid_tree_4.best_estimator_\n",
    "tree_5 = grid_tree_5.best_estimator_\n",
    "\n",
    "tree_l = [tree_1, tree_2, tree_3, tree_4, tree_5]\n",
    "\n",
    "# 逻辑回归模型组\n",
    "grid_lr_1 = load('./models/grid_lr_1.joblib')\n",
    "grid_lr_2 = load('./models/grid_lr_2.joblib')\n",
    "grid_lr_3 = load('./models/grid_lr_3.joblib')\n",
    "grid_lr_4 = load('./models/grid_lr_4.joblib')\n",
    "grid_lr_5 = load('./models/grid_lr_5.joblib')\n",
    "\n",
    "lr_1 = grid_lr_1.best_estimator_\n",
    "lr_2 = grid_lr_2.best_estimator_\n",
    "lr_3 = grid_lr_3.best_estimator_\n",
    "lr_4 = grid_lr_4.best_estimator_\n",
    "lr_5 = grid_lr_5.best_estimator_\n",
    "\n",
    "lr_l = [lr_1, lr_2, lr_3, lr_4, lr_5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "78e26c08-f8df-42b6-a0ed-7ee926290d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval1_predict_proba_RF = pd.Series(RF_l[0].predict_proba(X_eval1)[:, 1], index=X_eval1.index)\n",
    "eval2_predict_proba_RF = pd.Series(RF_l[1].predict_proba(X_eval2)[:, 1], index=X_eval2.index)\n",
    "eval3_predict_proba_RF = pd.Series(RF_l[2].predict_proba(X_eval3)[:, 1], index=X_eval3.index)\n",
    "eval4_predict_proba_RF = pd.Series(RF_l[3].predict_proba(X_eval4)[:, 1], index=X_eval4.index)\n",
    "eval5_predict_proba_RF = pd.Series(RF_l[4].predict_proba(X_eval5)[:, 1], index=X_eval5.index)\n",
    "\n",
    "eval_predict_proba_RF = pd.concat([eval1_predict_proba_RF, \n",
    "                                   eval2_predict_proba_RF, \n",
    "                                   eval3_predict_proba_RF, \n",
    "                                   eval4_predict_proba_RF, \n",
    "                                   eval5_predict_proba_RF]).sort_index()\n",
    "\n",
    "eval1_predict_proba_tree = pd.Series(tree_l[0].predict_proba(X_eval1)[:, 1], index=X_eval1.index)\n",
    "eval2_predict_proba_tree = pd.Series(tree_l[1].predict_proba(X_eval2)[:, 1], index=X_eval2.index)\n",
    "eval3_predict_proba_tree = pd.Series(tree_l[2].predict_proba(X_eval3)[:, 1], index=X_eval3.index)\n",
    "eval4_predict_proba_tree = pd.Series(tree_l[3].predict_proba(X_eval4)[:, 1], index=X_eval4.index)\n",
    "eval5_predict_proba_tree = pd.Series(tree_l[4].predict_proba(X_eval5)[:, 1], index=X_eval5.index)\n",
    "\n",
    "eval_predict_proba_tree = pd.concat([eval1_predict_proba_tree, \n",
    "                                     eval2_predict_proba_tree, \n",
    "                                     eval3_predict_proba_tree, \n",
    "                                     eval4_predict_proba_tree, \n",
    "                                     eval5_predict_proba_tree]).sort_index()\n",
    "\n",
    "eval1_predict_proba_lr = pd.Series(lr_l[0].predict_proba(X_eval1)[:, 1], index=X_eval1.index)\n",
    "eval2_predict_proba_lr = pd.Series(lr_l[1].predict_proba(X_eval2)[:, 1], index=X_eval2.index)\n",
    "eval3_predict_proba_lr = pd.Series(lr_l[2].predict_proba(X_eval3)[:, 1], index=X_eval3.index)\n",
    "eval4_predict_proba_lr = pd.Series(lr_l[3].predict_proba(X_eval4)[:, 1], index=X_eval4.index)\n",
    "eval5_predict_proba_lr = pd.Series(lr_l[4].predict_proba(X_eval5)[:, 1], index=X_eval5.index)\n",
    "\n",
    "eval_predict_proba_lr = pd.concat([eval1_predict_proba_lr, \n",
    "                                   eval2_predict_proba_lr, \n",
    "                                   eval3_predict_proba_lr, \n",
    "                                   eval4_predict_proba_lr, \n",
    "                                   eval5_predict_proba_lr]).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "65fa97b2-8080-4196-bfd8-1321f5dd202b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict_proba_RF = []\n",
    "\n",
    "for i in range(5):\n",
    "    test_predict_proba_RF.append(RF_l[i].predict_proba(X_test_OE)[:, 1])\n",
    "\n",
    "test_predict_proba_RF = np.array(test_predict_proba_RF)\n",
    "test_predict_proba_RF = test_predict_proba_RF.mean(0)\n",
    "\n",
    "test_predict_proba_tree = []\n",
    "\n",
    "for i in range(5):\n",
    "    test_predict_proba_tree.append(tree_l[i].predict_proba(X_test_OE)[:, 1])\n",
    "\n",
    "test_predict_proba_tree = np.array(test_predict_proba_tree)\n",
    "test_predict_proba_tree = test_predict_proba_tree.mean(0)\n",
    "\n",
    "test_predict_proba_lr = []\n",
    "\n",
    "for i in range(5):\n",
    "    test_predict_proba_lr.append(lr_l[i].predict_proba(X_test_OE)[:, 1])\n",
    "\n",
    "test_predict_proba_lr = np.array(test_predict_proba_lr)\n",
    "test_predict_proba_lr = test_predict_proba_lr.mean(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388dea54-5578-491f-a5eb-a2389f5eb250",
   "metadata": {},
   "source": [
    "## <center>Ch.3 模型融合基础方法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e49e7b8-d051-418d-9295-1d3e6a73cdea",
   "metadata": {},
   "source": [
    "- 如何获得更好的融合结果"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd551cbb-7341-4144-94f9-2ee1d35e3931",
   "metadata": {},
   "source": [
    "&emsp;&emsp;不同于模型训练和超参数优化，想要在模型融合过程中获得更好的结果，则必须进行更广泛的尝试，需要多种不同方法的实践、以及实践经验的积累。而在实际学习的过程中，则需要注意前言技术方法的掌握，以及工程化工具的储备。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dda17cb-bb65-48c6-8a74-3154f2090e46",
   "metadata": {},
   "source": [
    "- Stacking融合优化策略综述"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c3213d-24d0-4976-a8c1-14f665fe3ecd",
   "metadata": {},
   "source": [
    "&emsp;&emsp;通过上一小节的学习，我们不难发现，Stacking模型融合和投票法&均值法类似，原理不难，但要获得一个稳定的优化效果却并没有那么简单。并且相比投票法&均值法，Stacking过程采用模型来学习一级评估器的输出结果和标签之间的关系，过拟合的倾向会更加明显。当然，关于Stacking容易过拟合的另一个理解的角度是：由于第一层学习器就已经提取了和标签更有关联度的特征，因此元学习器的学习难度偏弱，元学习器更容易过拟合。      \n",
    "&emsp;&emsp;此外，在上一小节我们分别尝试了手动Stacking和调用sklearn库实现Stacking融合，从本节开始，我们将重点介绍Stacking模型融合的优化策略。上一小节中我们围绕Stacking最核心的三个方向已经分别进行了尝试，分别是：\n",
    "- 其一是一、二级学习器优化，包括一级学习器训练方法优化与元学习器优化。这是最基础同时也是最核心的优化策略，其核心目的在于平衡Stacking融合的学习效果与过拟合倾向之间的关系；     \n",
    "- 其二则是多层Stacking，通过叠加更多层来提高Stacking的学习效果，当然在大多数情况下解决单层Stacking融合的过拟合问题已属实不易，要用好多层Stacking则更是难上加难；      \n",
    "- 其三则是特征增强。所谓特征增强，指的是一级学习器和元学习器带入不同的特征（或衍生特征的）组合，来提高模型多样性，并最终提升Stacking融合效果。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093ddc73-17db-47e9-b248-bdc2aeb0be4b",
   "metadata": {},
   "source": [
    "> 这里需要注意，我们所谓的特征增强更多是实践过程中对某一类方法总结的名称，这类方法在学术上还有另一种叫法：输入属性扰动。属于Stacking多样性增强的一类方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f510fd0b-f899-405f-b233-42ccc48c56b4",
   "metadata": {},
   "source": [
    "> 其实，就这三个优化方向来说，元学习器优化是每个Stacking过程都必须要进行的基础优化策略，而多层Stacking实际应用场景中出现的不多，但偶尔对于某些复杂数据集会有奇效，而真正能够大幅提升Stacking融合效果的方法其实是特征增强。我们知道，投票法&均值法在进行模型融合时，发挥效果的方式类似于Bagging，会更适用于“合而不同”的一组评估器的融合，即只要不同模型输出结果不同，就有可能融合得到一个更好的结果。但Stacking完全不同，根据Stacking的基本原理，该过程其实更适用于一组能够有效学习不同特征的一级评估器的融合。而如何能让一级学习器来各有所偏重的学习不同特征？特征增强肯定是最佳选择。例如我们完全可以给不同模型分配不同特征的衍生特征，从而让不同模型的学习重点各有不同，进而提升Stacking最终效果。此外，在元学习器中添加一些一级学习器中没有充分学习的衍生特征（例如特征重要性偏低的特征），也是能提升Stacking效果的。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f95e59-bcab-402d-9896-885f19a70fcf",
   "metadata": {},
   "source": [
    "&emsp;&emsp;接下来，我们就这三个优化方向、同时结合Stacking融合发挥作用的根本方式来进行更进一步的探讨。本小节将重点探讨Stacking过程中一级学习器的交叉训练策略、元学习器选择以及元学习器优化相关内容。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274811ee-3ad1-4fa2-b3d2-fb034f2d7a89",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 八、Stacking一级学习器交叉训练策略"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c119310d-b83b-4869-898b-bf4434ad3494",
   "metadata": {},
   "source": [
    "&emsp;&emsp;我们知道，Stacking强大的学习能力以及显著的过拟合问题，都源于其分层学习的架构特点（这点和神经网络类似）。如何克服过拟合问题、提升Stacking泛化能力，首先就必须要从各层学习器的训练和优化过程入手进行调整。           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74579a1-f90e-42be-a102-a293b113c5a6",
   "metadata": {},
   "source": [
    "### 1.一级学习器的三种不同的交叉训练策略"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89444bb2-9d3d-4999-be0e-bc7dbb6d8d2f",
   "metadata": {},
   "source": [
    "&emsp;&emsp;首先是一级学习器的训练过程。上一小节提到，作为提升模型融合泛化能力的重要手段，交叉训练已经承了Stacking一级学习器训练过程的“标配”，而在执行一级学习器交叉训练的过程，其实又可以分为三种不同的交叉训练的方式：    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b1a24f-73bd-46b0-a611-30103ab20d81",
   "metadata": {},
   "source": [
    "- 方法一：直接带入原始参数评估器进行交叉训练，即每一组模型内部都共用一组模型原始超参数。由于没有进行超参数优化，因此该种方式能够非常快速的训练一组模型，并可以借助sklearn中Stacking评估器来快速执行，该过程可以通过如下方式实现："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "id": "441f626a-9d1e-4c80-8bab-918e1c5335f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8761832639151836, 0.7853492333901193)"
      ]
     },
     "execution_count": 513,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 实例化一级评估器（默认超参数）\n",
    "logistic = LogisticRegression()\n",
    "tree = DecisionTreeClassifier()\n",
    "RF = RandomForestClassifier()\n",
    "\n",
    "# 实例化Stacking评估器\n",
    "estimators = [('lr', logistic), ('tree', tree), ('rf', RF)]\n",
    "clf = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
    "\n",
    "# 在训练集上训练\n",
    "clf.fit(X_train_OE, y_train)\n",
    "\n",
    "# 输出训练集和测试集评分\n",
    "clf.score(X_train_OE, y_train), clf.score(X_test_OE, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1f7ba4-a891-4cae-ab03-1dc419a9d494",
   "metadata": {},
   "source": [
    "不过需要注意的是，该方式尽管足够简洁，但由于一级学习器没有进行超参数优化，因此最终Stacking的结果表现出了较为明显的过拟合倾向。除非是希望快速验证某些建模过程，否则一般不建议采用该种方式进行一级学习器的训练。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5071e76-c09e-4628-b16f-9cb42b53bdde",
   "metadata": {},
   "source": [
    "- 方法二：先在全部训练集上训练一级学习器，并进行超参数优化。在确定每个一级学习器的超参数取值后，再进行交叉训练，交叉训练过程只训练每个一级学习器的参数而非超参数。尽管此时每一组模型内部超参数仍然是相同取值，但由于这组超参数毕竟是训练集上训练得到，因此方案二的Stacking结果的泛化能力要强于方案一，具体实现过程如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "97682b9c-0cec-4300-909f-d64ba228844e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8273381294964028, 0.787052810902896)"
      ]
     },
     "execution_count": 514,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 实例化一级评估器（默认超参数）\n",
    "logistic_search = load('./models/logistic_search.joblib') \n",
    "tree_model = load('./models/tree_model.joblib') \n",
    "RF_0 = load('./models/RF_0.joblib') \n",
    "\n",
    "# 实例化Stacking评估器\n",
    "estimators = [('lr', logistic_search.best_estimator_), ('tree', tree_model), ('rf', RF_0)]\n",
    "clf = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
    "\n",
    "# 在训练集上训练\n",
    "clf.fit(X_train_OE, y_train)\n",
    "\n",
    "# 输出训练集和测试集评分\n",
    "clf.score(X_train_OE, y_train), clf.score(X_test_OE, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e484c3c3-8337-44af-a6ec-d07d61382606",
   "metadata": {},
   "source": [
    "这里三个一级学习器的超参数其实就是在全部训练集上搜索得到的一组最优结果。根据最终Stacking评分能够看出，过拟合倾向得到了明显抑制，但融合结果并没有显著提升。实际上，在大多数情况下，第二种训练策略是能够一定程度抑制Stacking过拟合倾向，同时测试集上结果（即泛化能力）也会略好于方案一。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4990c84c-b3ca-4304-9ce6-f172d404aa52",
   "metadata": {},
   "source": [
    "|train strategy|train_score|test_score|\n",
    "|:--:|:--:|:--:|\n",
    "|组内共用默认超参数|0.88337|0.7898|\n",
    "|组内共用优化后的超参数|0.82733|0.7870|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b1b619-16ca-4999-819e-3bbb4669b006",
   "metadata": {},
   "source": [
    "> 大家可以思考，为何过拟合被抑制但测试集评分却略有下降。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599d00c8-fefa-4d94-8f5a-ad687a779af2",
   "metadata": {},
   "source": [
    "- 方法三：：在交叉训练过程中，每个模型的每个组内训练过程都单独进行超参数搜索，正如Part 4.3.4中进行操作，然后再进行Stacking融合。该策略交叉训练过程会耗费大量的时间，并且于需要先确定几折然后再进行一级学习器的超参数搜索和优化，因此会使得我们一般无法再根据融合结果灵活调整Stacking的CV超参数（调整一次就需要重新训练各组模型、重新进行超参数优化，成本巨大）。并且，由于sklearn较高的封装程度，使得我们无法简单调用sklearn中的评估器来完成该过程，整个过程都需要手动编写代码实现。但是，由于这种策略能够显著提升交叉训练过程中每个模型的泛化能力（更严格的信息隔离）和多样性（超参数多样性），因此在大多数情况下都是能显著提升最终融合结果的。例如我们借助Part 4.3.4中交叉训练结果，在不改变元学习器的情况下，能够得到Stacking融合结果如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "94f8f98a-24fc-46f5-8054-ccd953f156fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.044787\n",
       "1       0.572187\n",
       "2       0.161815\n",
       "3       0.250871\n",
       "4       0.122533\n",
       "          ...   \n",
       "5277    0.082653\n",
       "5278    0.346562\n",
       "5279    0.551481\n",
       "5280    0.049011\n",
       "5281    0.002783\n",
       "Length: 5282, dtype: float64"
      ]
     },
     "execution_count": 515,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 随机森林模型组OOF数据集\n",
    "eval_predict_proba_RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "id": "3c85fc6f-a8a8-4de5-aa57-2e415aa156e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr_oof</th>\n",
       "      <th>tree_oof</th>\n",
       "      <th>RF_oof</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.011289</td>\n",
       "      <td>0.037669</td>\n",
       "      <td>0.044787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.542331</td>\n",
       "      <td>0.787986</td>\n",
       "      <td>0.572187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.154121</td>\n",
       "      <td>0.222819</td>\n",
       "      <td>0.161815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.273393</td>\n",
       "      <td>0.259434</td>\n",
       "      <td>0.250871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.158399</td>\n",
       "      <td>0.107345</td>\n",
       "      <td>0.122533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5277</th>\n",
       "      <td>0.083575</td>\n",
       "      <td>0.062959</td>\n",
       "      <td>0.082653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5278</th>\n",
       "      <td>0.365228</td>\n",
       "      <td>0.222819</td>\n",
       "      <td>0.346562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5279</th>\n",
       "      <td>0.674365</td>\n",
       "      <td>0.438538</td>\n",
       "      <td>0.551481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5280</th>\n",
       "      <td>0.050536</td>\n",
       "      <td>0.066419</td>\n",
       "      <td>0.049011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5281</th>\n",
       "      <td>0.005250</td>\n",
       "      <td>0.026367</td>\n",
       "      <td>0.002783</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5282 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        lr_oof  tree_oof    RF_oof\n",
       "0     0.011289  0.037669  0.044787\n",
       "1     0.542331  0.787986  0.572187\n",
       "2     0.154121  0.222819  0.161815\n",
       "3     0.273393  0.259434  0.250871\n",
       "4     0.158399  0.107345  0.122533\n",
       "...        ...       ...       ...\n",
       "5277  0.083575  0.062959  0.082653\n",
       "5278  0.365228  0.222819  0.346562\n",
       "5279  0.674365  0.438538  0.551481\n",
       "5280  0.050536  0.066419  0.049011\n",
       "5281  0.005250  0.026367  0.002783\n",
       "\n",
       "[5282 rows x 3 columns]"
      ]
     },
     "execution_count": 516,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stack_oof = pd.DataFrame({'lr_oof': eval_predict_proba_lr, \n",
    "                                'tree_oof': eval_predict_proba_tree, \n",
    "                                'RF_oof': eval_predict_proba_RF})\n",
    "\n",
    "train_stack_oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "id": "60cd9ed0-525e-40e7-a37e-15a5be504655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04647312, 0.15890043, 0.04647312, ..., 0.15890043, 0.43740054,\n",
       "       0.1303992 ])"
      ]
     },
     "execution_count": 517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predict_proba_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "id": "db57e2ac-3289-45ea-927f-79b9fb0091dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr_test</th>\n",
       "      <th>tree_test</th>\n",
       "      <th>RF_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.045946</td>\n",
       "      <td>0.046473</td>\n",
       "      <td>0.029220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.233711</td>\n",
       "      <td>0.158900</td>\n",
       "      <td>0.311980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.005192</td>\n",
       "      <td>0.046473</td>\n",
       "      <td>0.016244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.035878</td>\n",
       "      <td>0.046473</td>\n",
       "      <td>0.025769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.056142</td>\n",
       "      <td>0.051573</td>\n",
       "      <td>0.035476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1756</th>\n",
       "      <td>0.169545</td>\n",
       "      <td>0.212513</td>\n",
       "      <td>0.193367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1757</th>\n",
       "      <td>0.040112</td>\n",
       "      <td>0.046473</td>\n",
       "      <td>0.048821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1758</th>\n",
       "      <td>0.125325</td>\n",
       "      <td>0.158900</td>\n",
       "      <td>0.145346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1759</th>\n",
       "      <td>0.501991</td>\n",
       "      <td>0.437401</td>\n",
       "      <td>0.530686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1760</th>\n",
       "      <td>0.062787</td>\n",
       "      <td>0.130399</td>\n",
       "      <td>0.106832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1761 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       lr_test  tree_test   RF_test\n",
       "0     0.045946   0.046473  0.029220\n",
       "1     0.233711   0.158900  0.311980\n",
       "2     0.005192   0.046473  0.016244\n",
       "3     0.035878   0.046473  0.025769\n",
       "4     0.056142   0.051573  0.035476\n",
       "...        ...        ...       ...\n",
       "1756  0.169545   0.212513  0.193367\n",
       "1757  0.040112   0.046473  0.048821\n",
       "1758  0.125325   0.158900  0.145346\n",
       "1759  0.501991   0.437401  0.530686\n",
       "1760  0.062787   0.130399  0.106832\n",
       "\n",
       "[1761 rows x 3 columns]"
      ]
     },
     "execution_count": 518,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_stack = pd.DataFrame({'lr_test': test_predict_proba_lr, \n",
    "                           'tree_test': test_predict_proba_tree, \n",
    "                           'RF_test': test_predict_proba_RF})\n",
    "\n",
    "test_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "id": "f7470e29-eb73-4160-aa22-cad70b8bb70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_final = LogisticRegression().fit(train_stack_oof, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "id": "68fc9a1a-b6f6-4526-84f7-5969c1b08b89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8178720181749337, 0.7955706984667802)"
      ]
     },
     "execution_count": 520,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_final.score(train_stack_oof, y_train), lr_final.score(test_stack, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3c678a-1044-4df9-95e1-685203e94277",
   "metadata": {},
   "source": [
    "能够看出，此时Stacking融合结果，不仅过拟合倾向得到了有效抑制，最终结果的泛化能力也得到了显著提升。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68959f4-ee65-4d3c-aea6-ed07449d1213",
   "metadata": {},
   "source": [
    "|train strategy|train_score|test_score|\n",
    "|:--:|:--:|:--:|\n",
    "|组内共用默认超参数|0.88337|0.7898|\n",
    "|组内共用优化后的超参数|0.82733|0.7870|\n",
    "|组内单独进行超参数优化|0.81787|0.7955|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06806278-e1ca-4164-913d-baa52c2b9ab4",
   "metadata": {},
   "source": [
    "&emsp;&emsp;尽管从效果上来说，第三种训练策略优势明显（多数情况下能够有千分位上的效果提升），但在具体实践过程中选取哪种训练策略，还需要根据具体实践情况来决定。当然，在大多数情况下我们主要是围绕第二、三种策略来进行选择，一般来说除非为了快速验证某些结论，否则不会采用第一种方法。      \n",
    "&emsp;&emsp;而就第二、三种方法的选择来说，如果时间允许，并且追求效果上的极致，建议考虑第三种训练策略，而如果时间有限，第二种训练策略也不失为一种能够保证效果的方案，并且大多数的建模情况下，我们都是要围绕单模进行超参数优化的，因此方案二的实践成本是很低的。实际上，在多数情况下我们看到的Stacking的交叉训练，其实都是采用的方案二，而很多方案二的训练结果也是比较可观的。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c841a0-7cf0-4cc7-85a8-d37520868091",
   "metadata": {},
   "source": [
    "> 之前的Kaggle案例公开课的Stacking融合过程就是采用的方案二。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9048d4-52c5-4387-8d63-6555b38cb6ed",
   "metadata": {},
   "source": [
    "&emsp;&emsp;对于方案二，其实还有一种变种策略，能实现类似方案二的效果：即带入网格搜索评估器而非模型评估器，则可以在交叉训练过程中每次训练都在既定的超参数空间中搜索得到一个最佳超参数组。尽管面对更加复杂的集成算法，我们没法最开始设置一个非常大的超参数搜索空间（否则会导致一次计算的时间过长），但哪怕是一个小范围内的搜索结果，也能够一定程度提升模型效果。这一点我们稍后会进行尝试。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9163d3b-9104-4768-8a01-90a84de4c858",
   "metadata": {},
   "source": [
    "&emsp;&emsp;此外，方案三的实现方法其实也并非一定像Part 4.3.4中那样，需要一个个模型单独来进行超参数优化。在下一小节，我们将借助级联优化的思路，来尝试构建一种更加自动化的流程来高效率的实现方案三。总的来说，课上会同时使用两种方案来进行Stacking融合，并从运行效率和融合结果等多个角度来进行分析和对比，同时完整提供两种方案的实现代码，方便同学们在实践过程中自行选择。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf29413-fee2-420a-b43d-940ee9890703",
   "metadata": {},
   "source": [
    "### 2.交叉训练的函数封装"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55772aaf-e6d3-438a-8f02-f146d14a3512",
   "metadata": {},
   "source": [
    "&emsp;&emsp;尽管sklearn的Stacking评估器调用过程足够简洁，但由于其较高的封装程度，很多时候并不利于我们来进行后续更加灵活的优化操作，因此在绝大多数情况下，我们都是手动进行一级评估器的交叉训练。此处我们先将手动交叉训练的相关过程封装为一个函数，方便后续调用："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "id": "2a8d5682-9f97-4243-bdb5-b439ede7d06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cross(X_train, y_train, X_test, estimators, n_splits=5, random_state=12):\n",
    "    \"\"\"\n",
    "    Stacking融合过程一级学习器交叉训练函数\n",
    "    \n",
    "    :param X_train: 训练集特征\n",
    "    :param y_train: 训练集标签\n",
    "    :param X_test: 测试集特征\n",
    "    :param estimators: 一级学习器，由(名称,评估器)组成的列表\n",
    "    :param n_splits: 交叉训练折数\n",
    "    :param random_state: 随机数种子\n",
    "    \n",
    "    :return：交叉训练后创建oof训练数据和测试集平均预测结果\n",
    "    \"\"\"\n",
    "    # 重置数据集的index，若数据集index是顺序排列，则此步骤可省略\n",
    "    X = X_train.reset_index(drop=True)\n",
    "    y = y_train.reset_index(drop=True)\n",
    "    \n",
    "    # 实例化重复交叉验证评估器\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    # 创建一级评估器输出的训练集预测结果和测试集预测结果数据集\n",
    "    # 数据集当前数值暂用零值填充\n",
    "    m = X.shape[0]\n",
    "    n = len(estimators)\n",
    "    m_test = X_test.shape[0]\n",
    "    \n",
    "    columns = []\n",
    "    for estimator in estimators:\n",
    "        columns.append(estimator[0] + '_oof')\n",
    "    \n",
    "    train_oof = pd.DataFrame(np.zeros((m, n)), columns=columns)\n",
    "    \n",
    "    columns = []\n",
    "    for estimator in estimators:\n",
    "        columns.append(estimator[0] + '_predict')\n",
    "    \n",
    "    test_predict = pd.DataFrame(np.zeros((m_test, n)), columns=columns)\n",
    "\n",
    "    # 执行交叉训练\n",
    "    for estimator in estimators:\n",
    "        model = estimator[1]\n",
    "        oof_colName = estimator[0] + '_oof'\n",
    "        predict_colName = estimator[0] + '_predict'\n",
    "        \n",
    "        for train_part_index, eval_index in kf.split(X, y):\n",
    "            # 在训练集上训练\n",
    "            X_train_part = X.loc[train_part_index]\n",
    "            y_train_part = y.loc[train_part_index]\n",
    "            model.fit(X_train_part, y_train_part)\n",
    "            # 在验证集上进行验证\n",
    "            X_eval_part = X.loc[eval_index]\n",
    "            # 将验证集上预测结果拼接入oof数据集\n",
    "            train_oof[oof_colName].loc[eval_index] = model.predict_proba(X_eval_part)[:, 1]\n",
    "            # 将测试集上预测结果填入predict数据集\n",
    "            test_predict[predict_colName] += model.predict_proba(X_test)[:, 1] / n_splits\n",
    "        \n",
    "    return train_oof, test_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085d173b-5104-4de0-8311-feaab9fc4eef",
   "metadata": {},
   "source": [
    "&emsp;&emsp;接下来测试函数性能："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "id": "a9c6da73-2715-4f63-9cc6-9e2266e53da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_search = load('./models/logistic_search.joblib') \n",
    "tree_model = load('./models/tree_model.joblib') \n",
    "RF_0 = load('./models/RF_0.joblib') \n",
    "\n",
    "estimators = [('lr', logistic_search.best_estimator_), ('tree', tree_model), ('rf', RF_0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "id": "f6558074-ddf0-4bf6-aa4b-2ec40079822f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_oof, test_predict = train_cross(X_train_OE, y_train, X_test_OE, estimators=estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "id": "9ff08447-f582-4615-a01a-5878d72a641e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr_oof</th>\n",
       "      <th>tree_oof</th>\n",
       "      <th>rf_oof</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.010385</td>\n",
       "      <td>0.065380</td>\n",
       "      <td>0.064009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.553209</td>\n",
       "      <td>0.787986</td>\n",
       "      <td>0.623811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.146526</td>\n",
       "      <td>0.222819</td>\n",
       "      <td>0.186379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.291518</td>\n",
       "      <td>0.234201</td>\n",
       "      <td>0.243126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.156131</td>\n",
       "      <td>0.211248</td>\n",
       "      <td>0.158017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5277</th>\n",
       "      <td>0.064633</td>\n",
       "      <td>0.062959</td>\n",
       "      <td>0.096975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5278</th>\n",
       "      <td>0.351549</td>\n",
       "      <td>0.222819</td>\n",
       "      <td>0.257227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5279</th>\n",
       "      <td>0.682007</td>\n",
       "      <td>0.503722</td>\n",
       "      <td>0.478084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5280</th>\n",
       "      <td>0.054905</td>\n",
       "      <td>0.066419</td>\n",
       "      <td>0.058595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5281</th>\n",
       "      <td>0.006476</td>\n",
       "      <td>0.026367</td>\n",
       "      <td>0.006766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5282 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        lr_oof  tree_oof    rf_oof\n",
       "0     0.010385  0.065380  0.064009\n",
       "1     0.553209  0.787986  0.623811\n",
       "2     0.146526  0.222819  0.186379\n",
       "3     0.291518  0.234201  0.243126\n",
       "4     0.156131  0.211248  0.158017\n",
       "...        ...       ...       ...\n",
       "5277  0.064633  0.062959  0.096975\n",
       "5278  0.351549  0.222819  0.257227\n",
       "5279  0.682007  0.503722  0.478084\n",
       "5280  0.054905  0.066419  0.058595\n",
       "5281  0.006476  0.026367  0.006766\n",
       "\n",
       "[5282 rows x 3 columns]"
      ]
     },
     "execution_count": 524,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "id": "d0c9b10f-913a-4c15-ab0f-ab57efd70a4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr_predict</th>\n",
       "      <th>tree_predict</th>\n",
       "      <th>rf_predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.035692</td>\n",
       "      <td>0.052015</td>\n",
       "      <td>0.023194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.231090</td>\n",
       "      <td>0.091196</td>\n",
       "      <td>0.307647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.006166</td>\n",
       "      <td>0.052015</td>\n",
       "      <td>0.006359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.029141</td>\n",
       "      <td>0.052015</td>\n",
       "      <td>0.012658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.065028</td>\n",
       "      <td>0.069881</td>\n",
       "      <td>0.049331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1756</th>\n",
       "      <td>0.178666</td>\n",
       "      <td>0.223305</td>\n",
       "      <td>0.192447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1757</th>\n",
       "      <td>0.030765</td>\n",
       "      <td>0.052015</td>\n",
       "      <td>0.066831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1758</th>\n",
       "      <td>0.136318</td>\n",
       "      <td>0.091196</td>\n",
       "      <td>0.160348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1759</th>\n",
       "      <td>0.500557</td>\n",
       "      <td>0.484657</td>\n",
       "      <td>0.591940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1760</th>\n",
       "      <td>0.066240</td>\n",
       "      <td>0.091196</td>\n",
       "      <td>0.093765</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1761 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      lr_predict  tree_predict  rf_predict\n",
       "0       0.035692      0.052015    0.023194\n",
       "1       0.231090      0.091196    0.307647\n",
       "2       0.006166      0.052015    0.006359\n",
       "3       0.029141      0.052015    0.012658\n",
       "4       0.065028      0.069881    0.049331\n",
       "...          ...           ...         ...\n",
       "1756    0.178666      0.223305    0.192447\n",
       "1757    0.030765      0.052015    0.066831\n",
       "1758    0.136318      0.091196    0.160348\n",
       "1759    0.500557      0.484657    0.591940\n",
       "1760    0.066240      0.091196    0.093765\n",
       "\n",
       "[1761 rows x 3 columns]"
      ]
     },
     "execution_count": 525,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0491e1e2-7317-4717-b765-3d68892b616a",
   "metadata": {},
   "source": [
    "通过该函数，我们能够快速获得一级评估器交叉训练得到的oof训练数据集，以及测试集上的平均预测结果。有了该结果，我们就能进一步对元学习器进行训练："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "id": "3573542d-ced1-4768-946f-5d1d4b93a4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression().fit(train_oof, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "id": "0be09895-3a36-4de0-987a-0f829af1c0d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.811056418023476, 0.7893242475865985)"
      ]
     },
     "execution_count": 527,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(train_oof, y_train), clf.score(test_predict, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbfd6e5-34d9-429e-b826-ecff69839a1b",
   "metadata": {},
   "source": [
    "## 九、元学习器的模型选择与超参数优化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321c581e-9355-45c9-98ee-171bde4c4958",
   "metadata": {},
   "source": [
    "&emsp;&emsp;当然，就整个Stacking过程模型训练优化的讨论来说，相比一级学习器的训练和优化，更关键、影响更大的，其实是元学习器的选择与优化。根据上一小节的探索，我们已经发现，Stacking元学习器的训练过程极容易过拟合，究其原因，其实是oof训练数据学习难度较低导致。因此，元学习器的模型选择并不是越复杂越好，在上一小节中，我们得出了以下基本结论："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba08754-7215-439b-abc5-722ccdc0849f",
   "metadata": {},
   "source": [
    "- 简单模型要比复杂模型效果更好：例如逻辑回归、决策树等模型作为元学习器，就会比随机森林等更加复杂的模型建模效果更好；"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9296dcfe-1c0e-4efb-a0cc-51efab2d4981",
   "metadata": {},
   "source": [
    "- 手动限制模型过拟合往往能得到一个更好的结果：例如将逻辑回归模型中正则化项设置为l1正则化、或者限制决策树模型的结构复杂度，往往能够获得一个更好的建模结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e94d2bf-3fef-48e3-a4cf-2e4327f93a1c",
   "metadata": {},
   "source": [
    "接下来，我们以此为基础，进一步讨论关于元学习器的选择和超参数优化策略。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32552ff6-4cf0-497e-bdc2-75dfa840bf71",
   "metadata": {},
   "source": [
    "### 1.元学习器模型选择"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269b73a4-d95f-429d-8a3e-9bd51aa36b88",
   "metadata": {},
   "source": [
    "&emsp;&emsp;关于元学习的模型选择，上一小节我们曾借助Stacking评估器快速验证了逻辑回归作为分类模型效果的优越性，接下来我们快速进行一组更加严谨的实验：通过带入更大范围的模型来验证最佳元学习器的模型选择，同时对其进行超参数优化，试探其效果上限。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b98239-58be-4e42-be3e-c7243c4e3317",
   "metadata": {},
   "source": [
    "- 多组模型的元学习器效果测试"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138e783c-db26-48c3-9502-0846c7d2bf4d",
   "metadata": {},
   "source": [
    "&emsp;&emsp;这里我们首先带入全部常用分类模型进行元学习器的模型训练，并测试最终学习效果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "id": "cde9a3ce-a6b8-4e45-8abd-dffbdd238f65",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The results of LR-final:\n",
      "Train-Accuracy: 0.811056, Test-Accuracy: 0.789324\n",
      "The results of tree-final:\n",
      "Train-Accuracy: 0.999432, Test-Accuracy: 0.716070\n",
      "The results of KNN-final:\n",
      "Train-Accuracy: 0.850625, Test-Accuracy: 0.755821\n",
      "The results of SVM-final:\n",
      "Train-Accuracy: 0.810867, Test-Accuracy: 0.787621\n",
      "The results of GaussianNB-final:\n",
      "Train-Accuracy: 0.797993, Test-Accuracy: 0.781942\n",
      "The results of Bagging-final:\n",
      "Train-Accuracy: 0.980689, Test-Accuracy: 0.764338\n",
      "The results of RandomForest-final:\n",
      "Train-Accuracy: 0.999432, Test-Accuracy: 0.767178\n",
      "The results of AdaBoost-final:\n",
      "Train-Accuracy: 0.812382, Test-Accuracy: 0.791028\n",
      "The results of GBDT-final:\n",
      "Train-Accuracy: 0.827149, Test-Accuracy: 0.787621\n",
      "[00:43:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "The results of XGB-final:\n",
      "Train-Accuracy: 0.903256, Test-Accuracy: 0.771721\n"
     ]
    }
   ],
   "source": [
    "# 逻辑回归\n",
    "lr = LogisticRegression().fit(train_oof, y_train)\n",
    "print('The results of LR-final:')\n",
    "print('Train-Accuracy: %f, Test-Accuracy: %f' % (lr.score(train_oof, y_train), lr.score(test_predict, y_test)))\n",
    "\n",
    "# 决策树\n",
    "tree = DecisionTreeClassifier().fit(train_oof, y_train)\n",
    "print('The results of tree-final:')\n",
    "print('Train-Accuracy: %f, Test-Accuracy: %f' % (tree.score(train_oof, y_train), tree.score(test_predict, y_test)))\n",
    "\n",
    "# KNN最近邻分类器\n",
    "from sklearn import neighbors\n",
    "KNN = neighbors.KNeighborsClassifier().fit(train_oof, y_train)\n",
    "print('The results of KNN-final:')\n",
    "print('Train-Accuracy: %f, Test-Accuracy: %f' % (KNN.score(train_oof, y_train), KNN.score(test_predict, y_test)))\n",
    "\n",
    "# SVM支持向量机\n",
    "from sklearn import svm\n",
    "SVM = svm.SVC().fit(train_oof, y_train)\n",
    "print('The results of SVM-final:')\n",
    "print('Train-Accuracy: %f, Test-Accuracy: %f' % (SVM.score(train_oof, y_train), SVM.score(test_predict, y_test)))\n",
    "\n",
    "# 朴素贝叶斯/高斯贝叶斯\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB().fit(train_oof, y_train)\n",
    "print('The results of GaussianNB-final:')\n",
    "print('Train-Accuracy: %f, Test-Accuracy: %f' % (gnb.score(train_oof, y_train), gnb.score(test_predict, y_test)))\n",
    "\n",
    "# Bagging\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "bagging = BaggingClassifier().fit(train_oof, y_train)\n",
    "print('The results of Bagging-final:')\n",
    "print('Train-Accuracy: %f, Test-Accuracy: %f' % (bagging.score(train_oof, y_train), bagging.score(test_predict, y_test)))\n",
    "\n",
    "# 随机森林\n",
    "RFC = RandomForestClassifier().fit(train_oof, y_train)\n",
    "print('The results of RandomForest-final:')\n",
    "print('Train-Accuracy: %f, Test-Accuracy: %f' % (RFC.score(train_oof, y_train), RFC.score(test_predict, y_test)))\n",
    "\n",
    "# AdaBoost\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ABC = AdaBoostClassifier().fit(train_oof, y_train)\n",
    "print('The results of AdaBoost-final:')\n",
    "print('Train-Accuracy: %f, Test-Accuracy: %f' % (ABC.score(train_oof, y_train), ABC.score(test_predict, y_test)))\n",
    "\n",
    "# GBDT\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "GBC = GradientBoostingClassifier().fit(train_oof, y_train)\n",
    "print('The results of GBDT-final:')\n",
    "print('Train-Accuracy: %f, Test-Accuracy: %f' % (GBC.score(train_oof, y_train), GBC.score(test_predict, y_test)))\n",
    "\n",
    "# XGB\n",
    "from xgboost import XGBClassifier\n",
    "XGB = XGBClassifier().fit(train_oof, y_train)\n",
    "print('The results of XGB-final:')\n",
    "print('Train-Accuracy: %f, Test-Accuracy: %f' % (XGB.score(train_oof, y_train), XGB.score(test_predict, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e842aba2-2eb1-4a09-a647-8a7ba2273960",
   "metadata": {},
   "source": [
    "能够发现，除了KNN存在欠拟合的情况，其模型都存在不同程度过拟合，而就目前这组模型来说，逻辑回归和AdaBoost表现较好。当然，KNN的欠拟合问题可以通过增加最近邻个数来进行验证："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "id": "09ef87ca-17a0-43a6-bcd9-24319032238b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.827906096175691, 0.7705848949460534)"
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN = neighbors.KNeighborsClassifier(n_neighbors=9).fit(train_oof, y_train)\n",
    "KNN.score(train_oof, y_train), KNN.score(test_predict, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61286e5-4a34-4e45-a349-226b1d5c1fb2",
   "metadata": {},
   "source": [
    "而对于逻辑回归和AdaBoost来说，逻辑回归模型表现较好的原因是本身oof数据集学习难度就不大，外加模型自带抗过拟合的正则化项，因此最后能得到一个还不错的训练结果；而对于AdaBoost而言，则是因为在默认参数情况下，AdaBoost是以最大深度为1的决策树模型为基础模型进行迭代，外加oof数据集的不同特征其实都和标签保持着非常高的关联度，种种原因，该会使得AdaBoost也天然具备一定的抗过拟合特性，从而使得最终获得了一个还不错的建模效果。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd39c39-72f7-4b67-813f-1f6abad58b10",
   "metadata": {},
   "source": [
    "&emsp;&emsp;需要注意的是，在元学习器的选择和优化的过程中，早些年的实践，人们往往倾向于“无脑”选择逻辑回归（回归问题选择贝叶斯回归），而近些年，随着实践应用程度的加深，以及越来越多的特征增强的手段出现，以初级Bagging和Boosting结合逻辑回归（或决策树模型）作为基础学习器的元学习器训练策略也逐渐展露头角。这类方法，也将是我们接下来介绍的关于元学习器优化策略的核心。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76f80b3-c137-4b2c-aa2c-1cb8be9fafd4",
   "metadata": {},
   "source": [
    "&emsp;&emsp;当然，原始参数的建模结果可能并不能完全说明问题，接下来我们进一步围绕这些模型，挑选具有代表性的模型进行超参数优化，并观察最终训练成果。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fc1410-3a67-4318-8e87-789e8575e773",
   "metadata": {},
   "source": [
    "### 2.元学习器的超参数优化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cf5e78-631e-4bdc-a01e-73975d2d6111",
   "metadata": {},
   "source": [
    "&emsp;&emsp;接下来我们挑选具备代表性的逻辑回归、决策树、Bagging、AdaBoost和随机森林五个模型来进行元学习器的超参数优化。由于本节我们采用的是手动训练一级学习器的方法，因此可以直接在一级学习器输出的oof数据集上完成元学习器的超参数优化，而不用像上一小节那样根据每个模型不同的超参数，对Stacking元学习器进行修改。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d9fe8b-5a78-4049-a9d8-d143def642cd",
   "metadata": {},
   "source": [
    "&emsp;&emsp;首先是逻辑回归模型，超参数优化过程如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "id": "ef2c9277-8474-4f7a-a4cf-8b74782b9b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置超参数空间\n",
    "logistic_param = [\n",
    "    {'thr': np.arange(0.1, 1, 0.1).tolist(), 'penalty': ['l1'], 'C': np.arange(0.1, 1.1, 0.1).tolist(), 'solver': ['saga']}, \n",
    "    {'thr': np.arange(0.1, 1, 0.1).tolist(), 'penalty': ['l2'], 'C': np.arange(0.1, 1.1, 0.1).tolist(), 'solver': ['lbfgs', 'newton-cg', 'sag', 'saga']}, \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "id": "766f394a-3200-4224-b647-4f1478c27af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实例化相关评估器\n",
    "logistic_final = logit_threshold(max_iter=int(1e6))\n",
    "    \n",
    "# 执行网格搜索\n",
    "lfg = GridSearchCV(estimator = logistic_final,\n",
    "                   param_grid = logistic_param,\n",
    "                   scoring='accuracy',\n",
    "                   n_jobs = 15).fit(train_oof, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "id": "0a28e16f-49cd-4b41-853b-a533e91ed242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.811434591898168"
      ]
     },
     "execution_count": 532,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lfg.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "id": "04483931-3c20-4dcb-b597-341c6b9fac8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0, 'penalty': 'l1', 'solver': 'saga', 'thr': 0.5}"
      ]
     },
     "execution_count": 533,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lfg.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "id": "82fb029c-b4fa-46da-827c-ca1c98138847",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8120030291556228, 0.7898921067575241)"
      ]
     },
     "execution_count": 534,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lfg.score(train_oof, y_train), lfg.score(test_predict, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b26e9c-0293-4482-af30-706ae934ed82",
   "metadata": {},
   "source": [
    "超参数搜索优化后对比结果如下："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa597f8-0ad8-4636-bedf-69e9af6d6623",
   "metadata": {},
   "source": [
    "|得分|训练集|测试集|\n",
    "|:--:|:--:|:--:|\n",
    "|优化前|0.8110|0.7893|\n",
    "|优化后|0.8120|0.7898|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb86651e-68a2-42f8-9d97-1ddc42832d07",
   "metadata": {},
   "source": [
    "能够发现，超参数搜索得到了一个更严格控制结构风险的参数组合（l1）正则化项，并且测试集上准确率略有提升。这也说明超参数优化在逻辑回归模型上确实能发挥作用。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a600b1-9156-4672-ade2-d1b4c50ba820",
   "metadata": {},
   "source": [
    "&emsp;&emsp;接下来是决策树模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "id": "e806e8c7-e61c-4a85-b3db-8683d287c0b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=DecisionTreeClassifier(), n_jobs=12,\n",
       "             param_grid={'max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,\n",
       "                                       14, 15],\n",
       "                         'max_leaf_nodes': [6, 7, 8, 9, 10, 11, 12, 13, 14, 15,\n",
       "                                            16, 17, 18, 19, 20, 21, 22, 23, 24,\n",
       "                                            25, 26, 27, 28, 29],\n",
       "                         'min_samples_leaf': [1, 2, 3],\n",
       "                         'min_samples_split': [1, 2, 3, 4]})"
      ]
     },
     "execution_count": 535,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 实例化决策树评估器\n",
    "tree_final = DecisionTreeClassifier()\n",
    "\n",
    "tree_param = {'max_depth': np.arange(2, 16, 1).tolist(), \n",
    "              'min_samples_split': np.arange(1, 5, 1).tolist(), \n",
    "              'min_samples_leaf': np.arange(1, 4, 1).tolist(), \n",
    "              'max_leaf_nodes':np.arange(6, 30, 1).tolist()}\n",
    "\n",
    "# 实例化网格搜索评估器\n",
    "tfg = GridSearchCV(estimator = tree_final,\n",
    "                   param_grid = tree_param,\n",
    "                   n_jobs = 12)\n",
    "\n",
    "tfg.fit(train_oof, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "id": "01cd6df4-d537-4c98-a731-0ff762edb485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 3,\n",
       " 'max_leaf_nodes': 7,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2}"
      ]
     },
     "execution_count": 536,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfg.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "id": "fc1d7e47-0c63-4069-94e4-7c905e05a70e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8072704337605"
      ]
     },
     "execution_count": 537,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfg.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "id": "21f2f38d-b59a-458e-9dfd-2158aa2f1168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8087845513063233, 0.7830777967064169)"
      ]
     },
     "execution_count": 538,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfg.score(train_oof, y_train), tfg.score(test_predict, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df54081-4b86-45e7-837b-b6ced29bb5d4",
   "metadata": {},
   "source": [
    "|得分|训练集|测试集|\n",
    "|:--:|:--:|:--:|\n",
    "|优化前|0.9994|0.7177|\n",
    "|优化后|0.8087|0.7830|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2432b72f-86ae-4bac-8823-88f1c31508d5",
   "metadata": {},
   "source": [
    "能够发现，超参数优化也同样能提升决策树模型作为元学习器的预测效果并抑制过拟合。不过并未“反超”逻辑回归模型效果。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c920e6-381e-486d-9453-eeaa0128c4d0",
   "metadata": {},
   "source": [
    "&emsp;&emsp;接下来是Bagging和AdaBoost，作为较为基础的集成算法，这里我们不仅需要对其进行超参数优化，而且也要尝试在更换不同基础评估器的情况下最终建模效果。首先是Bagging，在不修改baseEstimator的情况下搜索结果如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "id": "df27da14-cd78-4713-845f-78872d53e856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.832921981811523\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# 设置超参数空间\n",
    "parameter_space = {\n",
    "    \"n_estimators\": range(10, 21), \n",
    "    \"max_samples\": np.arange(0.1, 1.1, 0.1).tolist()}\n",
    "\n",
    "# 实例化模型与评估器\n",
    "bagging_final = BaggingClassifier(DecisionTreeClassifier())\n",
    "BG = GridSearchCV(bagging_final, parameter_space, n_jobs=15)\n",
    "\n",
    "# 模型训练\n",
    "BG.fit(train_oof, y_train)\n",
    "\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "bec080ac-1d59-4eb4-bbe8-56063823f734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_samples': 0.1, 'n_estimators': 18}"
      ]
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BG.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "id": "ab2f92ce-81f2-4247-870b-31a905331845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8057567156904906"
      ]
     },
     "execution_count": 541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BG.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "id": "34e68087-9d81-4bba-a184-4599cfca64b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8322605073835668, 0.7751277683134583)"
      ]
     },
     "execution_count": 542,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BG.score(train_oof, y_train), BG.score(test_predict, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbcff8b-9dd3-420e-acce-bcc40fc2c4ae",
   "metadata": {},
   "source": [
    "|得分|训练集|测试集|\n",
    "|:--:|:--:|:--:|\n",
    "|优化前|0.9795|0.7683|\n",
    "|优化后|0.8243|0.7722|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ad83f1-ffb0-4af1-808a-d2837250b4c3",
   "metadata": {},
   "source": [
    "能够发现，相比原始Bagging，效果还是有所提升的。当然，根据AdaBoost起作用的原因分析，我们能够看到基础学习器本身的特性其实是会影响到集成算法的预测结果的（尤其是Bagging和AdaBoost这类较为基础的集成学习算法），因此我们尝试将基础评估器改为超参数优化后的决策树（上述过程是带入了原始超参数的决策树作为base estimator）、原始参数下的逻辑回归、以及超参数优化后的逻辑回归模型进行效果测试："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "id": "02b2bba6-fef7-4502-a4f8-1d77bd2b94c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.613081932067871\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# 设置超参数空间\n",
    "parameter_space = {\n",
    "    \"n_estimators\": range(10, 21), \n",
    "    \"max_samples\": np.arange(0.1, 1.1, 0.1).tolist()}\n",
    "\n",
    "# 实例化模型与评估器\n",
    "bagging_final = BaggingClassifier(DecisionTreeClassifier(max_depth=3,\n",
    "                                                         max_leaf_nodes=7,\n",
    "                                                         min_samples_leaf=1,\n",
    "                                                         min_samples_split=2))\n",
    "BG = GridSearchCV(bagging_final, parameter_space, n_jobs=15)\n",
    "\n",
    "# 模型训练\n",
    "BG.fit(train_oof, y_train)\n",
    "\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "id": "81ee290e-7b8a-449a-bec3-571608c993f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_samples': 0.7000000000000001, 'n_estimators': 17}"
      ]
     },
     "execution_count": 544,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BG.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "id": "f6393510-61c7-4631-8d85-d85dcf63513e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.812381382414495"
      ]
     },
     "execution_count": 545,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BG.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "id": "6f446943-e07f-48bf-9a6a-bee98f6dcad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8146535403256342, 0.7881885292447472)"
      ]
     },
     "execution_count": 546,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BG.score(train_oof, y_train), BG.score(test_predict, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82d5156-fb5d-4f83-8cba-1514993c56b8",
   "metadata": {},
   "source": [
    "能够发现，带入超参数优化后的决策树模型后，Bagging作为元学习器的效果有了更进一步的提升："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de2f770-ab1a-46ca-b3f1-c19caa5b48d9",
   "metadata": {},
   "source": [
    "|基础评估器|训练集|测试集|\n",
    "|:--:|:--:|:--:|\n",
    "|未优化的决策树|0.8243|0.7722|\n",
    "|优化后的决策树|0.8120|0.7881|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8a4850-a0e5-4a0a-99ee-f9e40c47944d",
   "metadata": {},
   "source": [
    "然后带入原始超参数的逻辑回归模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "id": "83bc522d-c3c2-4db5-8319-f8840c5ace82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.365494966506958\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# 设置超参数空间\n",
    "parameter_space = {\n",
    "    \"n_estimators\": range(10, 21), \n",
    "    \"max_samples\": np.arange(0.1, 1.1, 0.1).tolist(),\n",
    "    'max_features':np.arange(0.1, 1.1, 0.1).tolist()}\n",
    "\n",
    "# 实例化模型与评估器\n",
    "bagging_final = BaggingClassifier(LogisticRegression())\n",
    "BG = GridSearchCV(bagging_final, parameter_space, n_jobs=15)\n",
    "\n",
    "# 模型训练\n",
    "BG.fit(train_oof, y_train)\n",
    "\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "id": "b0844dee-d348-4e00-86de-e841981930b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 0.9, 'max_samples': 0.9, 'n_estimators': 11}"
      ]
     },
     "execution_count": 548,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BG.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "id": "c490b0d1-1bac-4dd6-a7e7-c8689df61271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8129495642326768"
      ]
     },
     "execution_count": 549,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BG.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "id": "c227e6dc-b7f0-4486-bdd7-b6e833966a84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8102991291177585, 0.7836456558773425)"
      ]
     },
     "execution_count": 550,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BG.score(train_oof, y_train), BG.score(test_predict, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b18919a-2766-431f-8e38-307fd711134d",
   "metadata": {},
   "source": [
    "能够发现，该结果价于单独逻辑回归模型作为元学习器的效果，但由于原始Bagging模型效果："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5425cfe7-5676-4668-98a7-96a2eb331057",
   "metadata": {},
   "source": [
    "|基础评估器|训练集|测试集|\n",
    "|:--:|:--:|:--:|\n",
    "|未优化的决策树|0.8243|0.7722|\n",
    "|优化后的决策树|0.8120|0.7915|\n",
    "|未优化的逻辑回归|0.8102|0.7864|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750612ac-7084-4ec3-80dd-23f1df924ced",
   "metadata": {},
   "source": [
    "接下来带入超参数优化后的逻辑回归模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "id": "2a051a22-db63-4a26-a9f3-dc9ccff2c986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.1256947517395\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# 设置超参数空间\n",
    "parameter_space = {\n",
    "    \"n_estimators\": range(10, 21), \n",
    "    \"max_samples\": np.arange(0.1, 1.1, 0.1).tolist(),\n",
    "    'max_features':np.arange(0.1, 1.1, 0.1).tolist()}\n",
    "\n",
    "# 实例化模型与评估器\n",
    "bagging_final = BaggingClassifier(LogisticRegression(penalty='l1',\n",
    "                                                     solver='saga'))\n",
    "BG = GridSearchCV(bagging_final, parameter_space, n_jobs=15)\n",
    "\n",
    "# 模型训练\n",
    "BG.fit(train_oof, y_train)\n",
    "\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "id": "13ec2f64-97c1-4593-bae6-351ef18d41a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 0.9, 'max_samples': 0.6, 'n_estimators': 19}"
      ]
     },
     "execution_count": 552,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BG.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "id": "04673b97-e31d-4bd2-b08a-9b83d4aeec46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8137062440870387"
      ]
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BG.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "id": "44fb501b-3cd2-4565-b2c2-36fe7b523524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8121923513820523, 0.7887563884156729)"
      ]
     },
     "execution_count": 554,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BG.score(train_oof, y_train), BG.score(test_predict, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacaab35-29ef-434a-a700-39949e7d7b8a",
   "metadata": {},
   "source": [
    "能够发现，效果有更进一步的提升："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa16a5c-b3b9-46c3-9233-05c9f09fe4b0",
   "metadata": {},
   "source": [
    "|基础评估器|训练集|测试集|\n",
    "|:--:|:--:|:--:|\n",
    "|未优化的决策树|0.8243|0.7722|\n",
    "|优化后的决策树|0.8120|0.7915|\n",
    "|未优化的逻辑回归|0.8102|0.7864|\n",
    "|优化后的逻辑回归|0.8106|0.7881|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebeed61d-62e8-417e-b68a-e67af14e7cf0",
   "metadata": {},
   "source": [
    "据此我们能够得出两个基本结论，其一，对基础评估器进行超参数优化，尤其是对其进行一定程度过拟合限制，是能够提升Bagging最终效果的；其二，在部分情况下，Bagging搭配超参数优化的基础评估器，有可能得到比单独基础评估器作为元学习器更好的结果。而这两种方法：简单模型的超参数优化、以及将优化后的简单模型进行Bagging集成并进一步进行超参数搜索，都是我们在Stacking过程中非常值得进行尝试的策略。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a57f183-4888-43d4-99c7-12408620c84d",
   "metadata": {},
   "source": [
    "> 切记模型融合开篇介绍的观点，要保证模型融合的效果，则不仅需要否采用复杂前沿的方法，更需要广泛的尝试可能潜在的有价值的方案，更多的尝试往往才是保障最终融合效果的根本方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100852ae-86a3-476e-ae1c-1bf08d53d430",
   "metadata": {},
   "source": [
    "&emsp;&emsp;最后是AdaBoost，相比之下由于Boosting特殊的流程，并不能像Bagging一样随意修改基础学习器（Boosting类算法降低基础学习器的学习能力，将很大程度影响最终模型训练结果），因此作为元学习器，可以提升的空间较为有限，在大多数情况下，我们只能对其进行超参数优化："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "id": "7115ee97-7827-4b08-83c4-a40fc24b5331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.56694054603577\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# 设置超参数空间\n",
    "parameter_space = {\n",
    "    \"n_estimators\": range(10, 101), \n",
    "    \"learning_rate\": np.arange(0.01, 0.55, 0.05).tolist(),\n",
    "    'algorithm':['SAMME.R', 'SAMME']}\n",
    "\n",
    "# 实例化模型与评估器\n",
    "AB_final = AdaBoostClassifier()\n",
    "abg = GridSearchCV(AB_final, parameter_space, n_jobs=15)\n",
    "\n",
    "# 模型训练\n",
    "abg.fit(train_oof, y_train)\n",
    "\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "id": "7558d285-5d87-44f3-bbf8-bd06a6efdb81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm': 'SAMME.R', 'learning_rate': 0.11, 'n_estimators': 33}"
      ]
     },
     "execution_count": 556,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abg.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "id": "ea775ccb-218f-401a-956d-d001de7e567f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8114350624763347, 0.787052810902896)"
      ]
     },
     "execution_count": 557,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abg.score(train_oof, y_train), abg.score(test_predict, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede2a580-60af-4977-a177-cfc0ab022308",
   "metadata": {},
   "source": [
    "能够看出结果其实并没有提升。而如果我们将基础模型换为逻辑回归模型，模型结果也不会有好转："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "id": "5c48daf0-2154-4dc2-bed3-3c4323f8fcc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.944231748580933\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# 设置超参数空间\n",
    "parameter_space = {\n",
    "    \"n_estimators\": range(10, 51), \n",
    "    \"learning_rate\": np.arange(0.01, 0.51, 0.05).tolist(),\n",
    "    'algorithm':['SAMME.R', 'SAMME']}\n",
    "\n",
    "# 实例化模型与评估器\n",
    "AB_final = AdaBoostClassifier(LogisticRegression())\n",
    "abg = GridSearchCV(AB_final, parameter_space, n_jobs=15)\n",
    "\n",
    "# 模型训练\n",
    "abg.fit(train_oof, y_train)\n",
    "\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "id": "7b240d79-4a20-447d-b90b-3aaf8ac1f7c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm': 'SAMME', 'learning_rate': 0.26, 'n_estimators': 29}"
      ]
     },
     "execution_count": 559,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abg.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "id": "b5d356ea-796d-44e5-a6f4-36164a26746a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8076486179477471, 0.7864849517319704)"
      ]
     },
     "execution_count": 560,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abg.score(train_oof, y_train), abg.score(test_predict, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736265aa-19ba-48ee-b45a-d0c21591b66e",
   "metadata": {},
   "source": [
    "而如果我们希望通过提升基础模型的抗过拟合特性（即提升基础模型的结构风险惩罚力度），则Boosting类算法则因为缺乏学习能力而无法得到有效建模结果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "id": "fa691579-2fe3-4ca0-9018-faf4913eb4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.684714317321777\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# 设置超参数空间\n",
    "parameter_space = {\n",
    "    \"n_estimators\": range(1, 31), \n",
    "    \"learning_rate\": np.arange(0.01, 0.51, 0.05).tolist(),\n",
    "    'algorithm':['SAMME.R', 'SAMME']}\n",
    "\n",
    "# 实例化模型与评估器\n",
    "AB_final = AdaBoostClassifier(LogisticRegression(penalty='l1',\n",
    "                                                     solver='saga'))\n",
    "abg = GridSearchCV(AB_final, parameter_space, n_jobs=15)\n",
    "\n",
    "# 模型训练\n",
    "abg.fit(train_oof, y_train)\n",
    "\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "id": "96a97f79-b6c7-41ac-89b7-c560c72063f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm': 'SAMME.R', 'learning_rate': 0.01, 'n_estimators': 1}"
      ]
     },
     "execution_count": 569,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abg.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "id": "54009b2b-d328-43c9-bae3-df63f8584168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7385460053010223, 0.7228847245883021)"
      ]
     },
     "execution_count": 570,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abg.score(train_oof, y_train), abg.score(test_predict, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285b76db-b745-41ea-a084-93ea46aa31d6",
   "metadata": {},
   "source": [
    "&emsp;&emsp;其实不仅仅是AdaBoost，很多更加复杂的集成学习算法经过超参数优化后也并不会有非常显著的效果提升。以随机森林为例，当我们对其进行超参数优化后，并不会获得一个比逻辑回归或者逻辑回归Bagging的更好的结果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "id": "744ffb59-825f-4c46-acb0-12ff951fbb68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.03087377548218\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# 设置超参数空间\n",
    "parameter_space = {\n",
    "    \"min_samples_leaf\": range(2, 6), \n",
    "    \"min_samples_split\": range(1, 6),\n",
    "    \"max_depth\": range(5, 8),\n",
    "    \"max_leaf_nodes\": [None] + list(range(20, 25)), \n",
    "    \"n_estimators\": range(6, 11), \n",
    "    \"max_samples\":[None, 0.54, 0.55, 0.56]}\n",
    "\n",
    "# 实例化模型与评估器\n",
    "RF_final = RandomForestClassifier(random_state=12)\n",
    "rfg = GridSearchCV(RF_final, parameter_space, n_jobs=15)\n",
    "\n",
    "# 模型训练\n",
    "rfg.fit(train_oof, y_train)\n",
    "\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "id": "f5b847a7-52a4-4896-88e8-18ab2b0969dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 6,\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': 0.55,\n",
       " 'min_samples_leaf': 3,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 8}"
      ]
     },
     "execution_count": 565,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfg.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "id": "42768a17-a648-4e16-9cc7-94f38861386a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8188186293070806, 0.7853492333901193)"
      ]
     },
     "execution_count": 566,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfg.score(train_oof, y_train), rfg.score(test_predict, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4237b3b-5cb6-46fb-acbb-938ca09f4e1d",
   "metadata": {},
   "source": [
    "当然，除了随机森林，其他复杂的集成算法其实也会出现类似情况。同学们感兴趣的话可以课后自行尝试。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e720bd-95d9-42dd-9990-3fd0d6d25dd8",
   "metadata": {},
   "source": [
    "&emsp;&emsp;经过上述一系列尝试，我们能获得以下结论："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e1288f-b000-4289-9249-3c0938bbc551",
   "metadata": {},
   "source": [
    "- 元学习器的超参数优化是能够提升元学习器的泛化能力的，在大多数情况下我们应该尽可能的对其进行超参数优化；"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53a3682-af2f-4118-8072-b7e9b6f72465",
   "metadata": {},
   "source": [
    "- 除了元学习器应该尽可能选择抗过拟合较高的简单模型外，有效的元学习器（经过超参数优化后的元学习器）+Bagging有时也能一定的提升元学习器学习能力；"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712dfbb7-733f-47f2-a4d9-9316c4030b9c",
   "metadata": {},
   "source": [
    "需要注意的是，这些基本结论不仅适用于当前数据集，同时也是大多数实践经验总结出来的结果。甚至，由于本案例数据集的特殊性，很多在大多数情况下有显著提升效果的方法（例如使用超参数优化后的逻辑回归作为基础评估器来进行Bagging），在当前数据集上并没有明显的显现其作用。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48d9294-e4ab-43cc-aa1e-1f62eb22891e",
   "metadata": {},
   "source": [
    "### 3.元学习器的训练策略"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a24e6d2-03d8-4782-a50a-919b1640a486",
   "metadata": {},
   "source": [
    "&emsp;&emsp;在得到了上述一系列结论后，Stacking过程中元学习器的训练策略就非常清晰了。总的来说可以分为两个阶段："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde26a82-44fd-462b-b648-8b55c3f262ab",
   "metadata": {},
   "source": [
    "- 选取逻辑回归、决策树等模型作为元学习器的备选模型，对其进行训练和超参数优化；"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04867e48-6906-4ff9-81bb-1ebb14806db9",
   "metadata": {},
   "source": [
    "- 以超参数优化后的逻辑回归模型或决策树模型等模型作为基础模型进行Bagging过程，并对Bagging评估器进行超参数优化；"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1792078-b686-436f-98fd-64c41f2e28ff",
   "metadata": {},
   "source": [
    "最终，在两个阶段训练得到的若干模型中挑选最好的元学习器输出最终预测结果，当然如果是在竞赛中，也可以多次提交不同元学习器的预测结果，来获得一个当前元学习器中最高的排名。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee1693d-5003-413c-9c77-cf23fee5d785",
   "metadata": {},
   "source": [
    "> 如果是回归问题，则基础分类器则更多考虑贝叶斯回归、Lasso和岭回归，第二阶段的Bagging过程类似。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb250bc-aa51-45d6-81ef-5257347f28f8",
   "metadata": {},
   "source": [
    "&emsp;&emsp;不过需要注意的是，其实在单独的基础分类器作为元学习器和Bagging作为元学习器二者之间，还存在一种中间状态，即有些情况下我们并不会直接对基础分类器进行Bagging，而是借助sklearn中交叉验证过程，对其进行多次训练（一般是进行5-10次训练），然后取其平均预测结果作为最终预测结果，以实现类似Bagging但弱于Bagging的过程。该过程也被称为元学习器的交叉训练，只不过元学习器的交叉训练的目标并不是为了得到OOF数据集，而是借助交叉训练实现类似Boostrap的过程，来提升元学习器的泛化能力。具体执行流程如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "id": "d93cff33-0889-4497-aa49-0cfda8663700",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "id": "d48cb5a5-2d41-4a1a-a7fa-7cf30c74ca88",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = np.zeros(test_predict.shape[0])\n",
    "\n",
    "folds = RepeatedKFold(n_splits=5, n_repeats=2)\n",
    "\n",
    "for trn_idx, val_idx in folds.split(train_oof, y_train):\n",
    "    lr = LogisticRegression(penalty='l1',solver='saga')\n",
    "    lr.fit(train_oof.loc[trn_idx], y_train.loc[trn_idx])\n",
    "    res += lr.predict_proba(test_predict)[:, 1] / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "id": "eeffc857-941e-409c-8068-b17e0d7bb860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7898921067575241"
      ]
     },
     "execution_count": 598,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score((res >= 0.5) * 1, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "id": "82c6e6c2-41c0-4125-ab31-61b4f7db7ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = np.zeros(test_predict.shape[0])\n",
    "\n",
    "folds = RepeatedKFold(n_splits=5, n_repeats=2)\n",
    "\n",
    "for trn_idx, val_idx in folds.split(train_oof, y_train):\n",
    "    tree = DecisionTreeClassifier(max_depth=3,\n",
    "                                  max_leaf_nodes=7,\n",
    "                                  min_samples_leaf=1,\n",
    "                                  min_samples_split=2)\n",
    "    tree.fit(train_oof.loc[trn_idx], y_train.loc[trn_idx])\n",
    "    res += tree.predict_proba(test_predict)[:, 1] / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "id": "676dac1c-e4eb-477a-95c2-f4f5e5a60de1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7887563884156729"
      ]
     },
     "execution_count": 600,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score((res >= 0.5) * 1, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8c71df-f155-4279-994b-74f408e806cb",
   "metadata": {},
   "source": [
    "其中RepeatedKFold就是简单的重复kFold过程："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "id": "6f9e0491-b51f-4135-af21-7523024d6c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "id": "9833aaed-3a46-4074-aa0f-0fe21851b623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 其中n_repeats用于控制重复的次数\n",
    "folds = RepeatedKFold(n_splits=5, n_repeats=2, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "id": "6f620e47-2910-4f64-8d82-702404c3a11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_idx_l = []\n",
    "\n",
    "for trn_idx, val_idx in folds.split(train_oof, y_train):\n",
    "    trn_idx_l.append(trn_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "id": "b7d6b228-a2d7-4f0b-bb13-374edd4e916f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([   1,    2,    5, ..., 5279, 5280, 5281]),\n",
       " array([   0,    1,    2, ..., 5279, 5280, 5281]),\n",
       " array([   0,    1,    2, ..., 5279, 5280, 5281]),\n",
       " array([   0,    1,    3, ..., 5275, 5277, 5281]),\n",
       " array([   0,    2,    3, ..., 5278, 5279, 5280]),\n",
       " array([   0,    1,    2, ..., 5278, 5280, 5281]),\n",
       " array([   0,    1,    2, ..., 5278, 5279, 5281]),\n",
       " array([   0,    3,    5, ..., 5279, 5280, 5281]),\n",
       " array([   0,    1,    2, ..., 5279, 5280, 5281]),\n",
       " array([   1,    2,    3, ..., 5277, 5279, 5280])]"
      ]
     },
     "execution_count": 604,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_idx_l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53886e04-66d2-4dc6-b5c8-f7f2b810a954",
   "metadata": {},
   "source": [
    "这里需要注意，尽管是重复执行kFold，但划分的随机过程却不是重复的，这里能够看到，在两轮进行五折划分时，每轮的第一次划分结果都不相同："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "id": "5707e7f2-ae00-459c-a35d-caf6f3ff959f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   1,    2,    5, ..., 5279, 5280, 5281])"
      ]
     },
     "execution_count": 605,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_idx_l[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "id": "a772b1d7-b49e-46b3-ad02-2d57d50a1609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    1,    2, ..., 5278, 5280, 5281])"
      ]
     },
     "execution_count": 606,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_idx_l[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd0b3dd-0496-48d7-bdcb-58c7f2fc6e98",
   "metadata": {},
   "source": [
    "而当我们设置n_repeats=1时，其实就是简单的进行五折数据集划分，效果相当于KFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "id": "23bb9658-6a85-4cd7-a120-e5d337083973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   1    2    5 ... 5279 5280 5281]\n",
      "[   0    1    2 ... 5279 5280 5281]\n",
      "[   0    1    2 ... 5279 5280 5281]\n",
      "[   0    1    3 ... 5275 5277 5281]\n",
      "[   0    2    3 ... 5278 5279 5280]\n"
     ]
    }
   ],
   "source": [
    "folds = RepeatedKFold(n_splits=5, n_repeats=1, random_state=12)\n",
    "for trn_idx, val_idx in folds.split(X_train_OE):\n",
    "    print(trn_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "id": "d7e320b7-23c7-40a7-b173-863b3410c2e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   1    2    5 ... 5279 5280 5281]\n",
      "[   0    1    2 ... 5279 5280 5281]\n",
      "[   0    1    2 ... 5279 5280 5281]\n",
      "[   0    1    3 ... 5275 5277 5281]\n",
      "[   0    2    3 ... 5278 5279 5280]\n"
     ]
    }
   ],
   "source": [
    "folds = KFold(n_splits=5, random_state=12, shuffle=True)\n",
    "for trn_idx, val_idx in folds.split(X_train_OE):\n",
    "    print(trn_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0c39d4-1fc4-43da-b26e-85b972cd742e",
   "metadata": {},
   "source": [
    "&emsp;&emsp;当然，有的时候我们也可以考虑在多轮计算的时候直接带入网格搜索评估器而不是确定超参数的模型评估器，以提升每次训练的模型效果。当然，在某些情况下是能够提升最终效果的："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "id": "0e0803b3-d0f2-4784-a309-02f185958221",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7887563884156729"
      ]
     },
     "execution_count": 614,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = np.zeros(test_predict.shape[0])\n",
    "\n",
    "folds = RepeatedKFold(n_splits=5, n_repeats=2, random_state=12)\n",
    "\n",
    "for trn_idx, val_idx in folds.split(train_oof, y_train):\n",
    "    lfg = GridSearchCV(estimator = logit_threshold(max_iter=int(1e6)),\n",
    "                       param_grid = logistic_param,\n",
    "                       scoring='accuracy',\n",
    "                       n_jobs = 15)\n",
    "    lfg.fit(train_oof.loc[trn_idx], y_train.loc[trn_idx])\n",
    "    res += lfg.predict_proba(test_predict)[:, 1] / 10\n",
    "    \n",
    "accuracy_score((res >= 0.5) * 1, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "id": "e057c33f-9de1-45df-92ee-8fc1c36c4225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7876206700738216\n"
     ]
    }
   ],
   "source": [
    "res = np.zeros(test_predict.shape[0])\n",
    "\n",
    "folds = RepeatedKFold(n_splits=5, n_repeats=2, random_state=12)\n",
    "\n",
    "for trn_idx, val_idx in folds.split(train_oof, y_train):\n",
    "    tfg = GridSearchCV(estimator = DecisionTreeClassifier(),\n",
    "                       param_grid = tree_param,\n",
    "                       n_jobs = 12)\n",
    "    tfg.fit(train_oof.loc[trn_idx], y_train.loc[trn_idx])\n",
    "    res += tfg.predict_proba(test_predict)[:, 1] / 10\n",
    "\n",
    "print(accuracy_score((res >= 0.5) * 1, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd48e84-74f9-4331-a2b9-b2d4882f57b7",
   "metadata": {},
   "source": [
    "至此，我们就完整介绍了关于元学习器训练流程。这里需要注意，元学习器单次训练成本较低，可以多次尝试不同方法，并从中挑选最优结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c53fb8-3aab-41d1-a08f-2c6318bd7ca8",
   "metadata": {},
   "source": [
    "### 4.元学习器的训练实战"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f543c99-68c0-4af5-a302-e672e242a6cb",
   "metadata": {},
   "source": [
    "&emsp;&emsp;最后，让我们在严格信息隔离的交叉训练的oof数据集上，按照我们之前的流程来进行元学习器的完整训练过程，并尝试能否获得一个更好的测试集预测结果。此前最好的结果是Part 4.3.4中获得0.7972。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ffe887-8d99-4403-a481-d50e41323324",
   "metadata": {},
   "source": [
    "- Step 1.元学习器的单模优化训练"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfb5d02-1c60-4309-933f-7240318142ca",
   "metadata": {},
   "source": [
    "&emsp;&emsp;首先是逻辑回归和决策树单模训练与超参数优化过程："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "id": "a5ecd946-8eb5-4fff-a5f8-4d4e51f0eb2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8186293070806513, 0.7967064168086314)"
      ]
     },
     "execution_count": 618,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 设置超参数空间\n",
    "logistic_param = [\n",
    "    {'thr': np.arange(0.1, 1, 0.1).tolist(), 'penalty': ['l1'], 'C': np.arange(0.1, 1.1, 0.1).tolist(), 'solver': ['saga']}, \n",
    "    {'thr': np.arange(0.1, 1, 0.1).tolist(), 'penalty': ['l2'], 'C': np.arange(0.1, 1.1, 0.1).tolist(), 'solver': ['lbfgs', 'newton-cg', 'sag', 'saga']}, \n",
    "]\n",
    "\n",
    "# 实例化相关评估器\n",
    "logistic_final = logit_threshold(max_iter=int(1e6))\n",
    "    \n",
    "# 执行网格搜索\n",
    "lfg = GridSearchCV(estimator = logistic_final,\n",
    "                   param_grid = logistic_param,\n",
    "                   scoring='accuracy',\n",
    "                   n_jobs = 15).fit(train_stack_oof, y_train)\n",
    "\n",
    "lfg.score(train_stack_oof, y_train), lfg.score(test_stack, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "id": "fcdb4ba5-f363-42a2-b82a-a652a088e80b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.30000000000000004, 'penalty': 'l1', 'solver': 'saga', 'thr': 0.5}"
      ]
     },
     "execution_count": 621,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lfg.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286a13a0-faf9-4102-99a6-91b571e4fcc0",
   "metadata": {},
   "source": [
    "&emsp;&emsp;接下来是决策树模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "id": "2b0fe4cf-13cc-4ed4-9001-bc0d082a45ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8188186293070806, 0.7904599659284497)"
      ]
     },
     "execution_count": 619,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 实例化决策树评估器\n",
    "tree_final = DecisionTreeClassifier()\n",
    "\n",
    "tree_param = {'max_depth': np.arange(2, 16, 1).tolist(), \n",
    "              'min_samples_split': np.arange(1, 5, 1).tolist(), \n",
    "              'min_samples_leaf': np.arange(1, 4, 1).tolist(), \n",
    "              'max_leaf_nodes':np.arange(6, 30, 1).tolist()}\n",
    "\n",
    "# 实例化网格搜索评估器\n",
    "tfg = GridSearchCV(estimator = tree_final,\n",
    "                   param_grid = tree_param,\n",
    "                   n_jobs = 12).fit(train_stack_oof, y_train)\n",
    "\n",
    "tfg.score(train_stack_oof, y_train), tfg.score(test_stack, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "id": "454fbba3-bee4-45ce-872f-80fa3d6d84f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 3,\n",
       " 'max_leaf_nodes': 7,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2}"
      ]
     },
     "execution_count": 620,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfg.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca51e0e-67b0-474e-a74f-c0e8c6bd7aa6",
   "metadata": {},
   "source": [
    "单模元学习器训练结果如下："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63aea8b-e730-460a-a2cb-e4c8cac7c7de",
   "metadata": {},
   "source": [
    "|得分|训练集|测试集|\n",
    "|:--:|:--:|:--:|\n",
    "|LR单模|0.8186|0.7967|\n",
    "|Tree单模|0.8188|0.7904|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1557c91b-5f62-4408-8438-f504a2f5eb16",
   "metadata": {},
   "source": [
    "其中，LR单模的结果已超过融合前单独模型的最好成绩0.7955。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1a4912-9090-42f6-9a8d-ce4fd3a36c3e",
   "metadata": {},
   "source": [
    "- Step 2.单模的交叉训练过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "id": "70bf3d64-b882-483d-b344-5450d4ef045b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7978421351504826\n"
     ]
    }
   ],
   "source": [
    "# 逻辑回归交叉训练\n",
    "res = np.zeros(test_predict.shape[0])\n",
    "\n",
    "folds = RepeatedKFold(n_splits=5, n_repeats=2, random_state=12)\n",
    "\n",
    "for trn_idx, val_idx in folds.split(train_stack_oof, y_train):\n",
    "    lfg = GridSearchCV(estimator = logit_threshold(max_iter=int(1e6)),\n",
    "                       param_grid = logistic_param,\n",
    "                       scoring='accuracy',\n",
    "                       n_jobs = 15)\n",
    "    lfg.fit(train_stack_oof.loc[trn_idx], y_train.loc[trn_idx])\n",
    "    res += lfg.predict_proba(test_stack)[:, 1] / 10\n",
    "    \n",
    "print(accuracy_score((res >= 0.5) * 1, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "id": "6136df02-e445-4faa-9372-1961cfd61f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7904599659284497\n"
     ]
    }
   ],
   "source": [
    "# 决策树交叉训练过程\n",
    "res = np.zeros(test_predict.shape[0])\n",
    "\n",
    "folds = RepeatedKFold(n_splits=5, n_repeats=2, random_state=12)\n",
    "\n",
    "for trn_idx, val_idx in folds.split(train_stack_oof, y_train):\n",
    "    tfg = GridSearchCV(estimator = DecisionTreeClassifier(),\n",
    "                       param_grid = tree_param,\n",
    "                       n_jobs = 12)\n",
    "    tfg.fit(train_stack_oof.loc[trn_idx], y_train.loc[trn_idx])\n",
    "    res += tfg.predict_proba(test_stack)[:, 1] / 10\n",
    "\n",
    "print(accuracy_score((res >= 0.5) * 1, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11f0ccc-5153-4434-a7a1-5249df75ee4a",
   "metadata": {},
   "source": [
    "|得分|训练集|测试集|\n",
    "|:--:|:--:|:--:|\n",
    "|LR单模|0.8186|0.7967|\n",
    "|Tree单模|0.8188|0.7904|\n",
    "|LR交叉训练|-|0.7978|\n",
    "|Tree交叉训练|-|0.7904|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1187b0-cc00-4c80-9885-beefd1fc4159",
   "metadata": {},
   "source": [
    "能够发现，逻辑回归的交叉训练结果已超过此前的最好成绩0.7972。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b280fa3-2f04-4a89-a918-19e23216046d",
   "metadata": {},
   "source": [
    "- Step 3.优化后模型的Bagging过程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c434bf38-d0b9-4c59-b3be-118844e4bd5e",
   "metadata": {},
   "source": [
    "&emsp;&emsp;最后，尝试带入经过超参数优化的基础评估器到Bagging中来进行训练："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "id": "aa0a0ac6-e6ca-42cd-8aa6-2a575a55071b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8186293070806513, 0.7967064168086314)"
      ]
     },
     "execution_count": 624,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# 设置超参数空间\n",
    "parameter_space = {\n",
    "    \"n_estimators\": range(10, 21), \n",
    "    \"max_samples\": np.arange(0.1, 1.1, 0.1).tolist(),\n",
    "    'max_features':np.arange(0.1, 1.1, 0.1).tolist()}\n",
    "\n",
    "# 实例化模型与评估器\n",
    "bagging_final = BaggingClassifier(LogisticRegression(C=0.3, \n",
    "                                                     penalty='l1',\n",
    "                                                     solver='saga'))\n",
    "BG = GridSearchCV(bagging_final, parameter_space, n_jobs=15).fit(train_stack_oof, y_train)\n",
    "\n",
    "BG.score(train_stack_oof, y_train), BG.score(test_stack, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "id": "a9ff5d48-c75e-42ce-9b25-c39e03413a02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8203332071185158, 0.8001135718341851)"
      ]
     },
     "execution_count": 622,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 设置超参数空间\n",
    "parameter_space = {\n",
    "    \"n_estimators\": range(10, 21), \n",
    "    \"max_samples\": np.arange(0.1, 1.1, 0.1).tolist()}\n",
    "\n",
    "# 实例化模型与评估器\n",
    "bagging_final = BaggingClassifier(DecisionTreeClassifier(max_depth=3,\n",
    "                                                         max_leaf_nodes=7,\n",
    "                                                         min_samples_leaf=1,\n",
    "                                                         min_samples_split=2))\n",
    "BG = GridSearchCV(bagging_final, parameter_space, n_jobs=15).fit(train_stack_oof, y_train)\n",
    "\n",
    "BG.score(train_stack_oof, y_train), BG.score(test_stack, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2ecf70-3c9c-4c3c-8c92-f3fa156f90b9",
   "metadata": {},
   "source": [
    "能够发现效果有了更进一步的提升，最终决策树模型的Bagging过程得分超过了此前的最高得分，准确率首次突破了80%大关。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc328fd4-8074-4680-a477-b9f65ef15ebd",
   "metadata": {},
   "source": [
    "|得分|训练集|测试集|\n",
    "|:--:|:--:|:--:|\n",
    "|LR单模|0.8186|0.7967|\n",
    "|Tree单模|0.8188|0.7904|\n",
    "|LR交叉训练|-|0.7978|\n",
    "|Tree交叉训练|-|0.7904|\n",
    "|LR+Bagging|0.8186|0.7967|\n",
    "|Tree+Bagging|0.8203|0.8001|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137d7fa2-980e-4abf-909b-b5f9ec5357f1",
   "metadata": {},
   "source": [
    "至此，我们就完整介绍了Stacking模型融合过程中一级学习器和元学习器的训练及优化流程。在大多数情况下，这些都是我们在执行模型融合过程中有效且通用的流程，在大型竞赛中，若能顺利执行到这一步，基本可以达到复赛得分。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
