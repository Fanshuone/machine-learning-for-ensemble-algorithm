{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac9e9a81-3c77-42e4-a450-ae59ce12ffbb",
   "metadata": {
    "tags": []
   },
   "source": [
    "# <center> 【Kaggle】Telco Customer Churn 电信用户流失预测案例"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745fbeac-32c0-4d40-926d-ff5067fb5b0d",
   "metadata": {},
   "source": [
    "## <font face=\"仿宋\">第四部分导读"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86dd5c81-efad-4a29-b862-22b378b7922c",
   "metadata": {},
   "source": [
    "&emsp;&emsp;<font face=\"仿宋\">在案例的第二、三部分中，我们详细介绍了关于特征工程的各项技术，特征工程技术按照大类来分可以分为数据预处理、特征衍生、特征筛选三部分，其中特征预处理的目的是为了将数据集整理、清洗到可以建模的程度，具体技术包括缺失值处理、异常值处理、数据重编码等，是建模之前必须对数据进行的处理和操作；而特征衍生和特征筛选则更像是一类优化手段，能够帮助模型突破当前数据集建模的效果上界。并且我们在第二部分完整详细的介绍机器学习可解释性模型的训练、优化和解释方法，也就是逻辑回归和决策树模型。并且此前我们也一直以这两种算法为主，来进行各个部分的模型测试。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93799ce2-f541-4ef8-b6b2-c4660373351d",
   "metadata": {},
   "source": [
    "&emsp;&emsp;<font face=\"仿宋\">而第四部分，我们将开始介绍集成学习的训练和优化的实战技巧，尽管从可解释性角度来说，集成学习的可解释性并不如逻辑回归和决策树，但在大多数建模场景下，集成学习都将获得一个更好的预测结果，这也是目前效果优先的建模场景下最常使用的算法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89189e38-f1c1-47ba-a88f-4d4b785ef73e",
   "metadata": {},
   "source": [
    "&emsp;&emsp;<font face=\"仿宋\">总的来说，本部分内容只有一个目标，那就是借助各类优化方法，抵达每个主流集成学习的效果上界。换而言之，本部分我们将围绕单模优化策略展开详细的探讨，涉及到的具体集成学习包括随机森林、XGBoost、LightGBM、和CatBoost等目前最主流的集成学习算法，而具体的优化策略则包括超参数优化器的使用、特征衍生和筛选方法的使用、单模型自融合方法的使用，这些优化方法也是截至目前，提升单模效果最前沿、最有效、同时也是最复杂的方法。其中有很多较为艰深的理论，也有很多是经验之谈，但无论如何，我们希望能够围绕当前数据集，让每个集成学习算法优化到极限。值得注意的是，在这个过程中，我们会将此前介绍的特征衍生和特征筛选视作是一种模型优化方法，衍生和筛选的效果，一律以模型的最终结果来进行评定。而围绕集成学习进行海量特征衍生和筛选，也才是特征衍生和筛选技术能发挥巨大价值的主战场。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8d8815-f6b0-4aa5-b356-6a71c6de82c5",
   "metadata": {},
   "source": [
    "&emsp;&emsp;<font face=\"仿宋\">而在抵达了单模的极限后，我们就会进入到下一阶段，也就是模型融合阶段。需要知道的是，只有单模的效果到达了极限，进一步的多模型融合、甚至多层融合，才是有意义的，才是有效果的。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f893eac7-bc60-417a-99fd-26766341071e",
   "metadata": {},
   "source": [
    "# <center>Part 4.集成算法的训练与优化技巧"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ee4f357-1488-4443-bc32-2a668589295f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 基础数据科学运算库\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 可视化库\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 时间模块\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# sklearn库\n",
    "# 数据预处理\n",
    "from sklearn import preprocessing\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# 实用函数\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 常用评估器\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 网格搜索\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 自定义评估器支持模块\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# 自定义模块\n",
    "from telcoFunc import *\n",
    "# 导入特征衍生模块\n",
    "import features_creation as fc\n",
    "from features_creation import *\n",
    "\n",
    "# re模块相关\n",
    "import inspect, re\n",
    "\n",
    "# 其他模块\n",
    "from tqdm import tqdm\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59333941-9106-4de6-a138-9173c39698c7",
   "metadata": {},
   "source": [
    "&emsp;&emsp;然后执行Part 1中的数据清洗相关工作："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0d57cb6-1c5b-4062-a7a3-ac73efe57dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "tcc = pd.read_csv('WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
    "\n",
    "# 标注连续/离散字段\n",
    "# 离散字段\n",
    "category_cols = ['gender', 'SeniorCitizen', 'Partner', 'Dependents',\n",
    "                'PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', \n",
    "                'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling',\n",
    "                'PaymentMethod']\n",
    "\n",
    "# 连续字段\n",
    "numeric_cols = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
    " \n",
    "# 标签\n",
    "target = 'Churn'\n",
    "\n",
    "# ID列\n",
    "ID_col = 'customerID'\n",
    "\n",
    "# 验证是否划分能完全\n",
    "assert len(category_cols) + len(numeric_cols) + 2 == tcc.shape[1]\n",
    "\n",
    "# 连续字段转化\n",
    "tcc['TotalCharges']= tcc['TotalCharges'].apply(lambda x: x if x!= ' ' else np.nan).astype(float)\n",
    "tcc['MonthlyCharges'] = tcc['MonthlyCharges'].astype(float)\n",
    "\n",
    "# 缺失值填补\n",
    "tcc['TotalCharges'] = tcc['TotalCharges'].fillna(0)\n",
    "\n",
    "# 标签值手动转化 \n",
    "tcc['Churn'].replace(to_replace='Yes', value=1, inplace=True)\n",
    "tcc['Churn'].replace(to_replace='No',  value=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e2a2d40-e14a-4d08-9955-d19bcde87669",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = tcc.drop(columns=[ID_col, target]).copy()\n",
    "labels = tcc['Churn'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d5dbe3-f67a-49f9-9242-ad8e74f7b099",
   "metadata": {},
   "source": [
    "&emsp;&emsp;同时，创建自然编码后的数据集以及经过时序特征衍生的数据集："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb0443f8-2882-429f-9302-bec5a1595b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分训练集和测试集\n",
    "train, test = train_test_split(tcc, random_state=22)\n",
    "\n",
    "X_train = train.drop(columns=[ID_col, target]).copy()\n",
    "X_test = test.drop(columns=[ID_col, target]).copy()\n",
    "\n",
    "y_train = train['Churn'].copy()\n",
    "y_test = test['Churn'].copy()\n",
    "\n",
    "X_train_seq = pd.DataFrame()\n",
    "X_test_seq = pd.DataFrame()\n",
    "\n",
    "# 年份衍生\n",
    "X_train_seq['tenure_year'] = ((72 - X_train['tenure']) // 12) + 2014\n",
    "X_test_seq['tenure_year'] = ((72 - X_test['tenure']) // 12) + 2014\n",
    "\n",
    "# 月份衍生\n",
    "X_train_seq['tenure_month'] = (72 - X_train['tenure']) % 12 + 1\n",
    "X_test_seq['tenure_month'] = (72 - X_test['tenure']) % 12 + 1\n",
    "\n",
    "# 季度衍生\n",
    "X_train_seq['tenure_quarter'] = ((X_train_seq['tenure_month']-1) // 3) + 1\n",
    "X_test_seq['tenure_quarter'] = ((X_test_seq['tenure_month']-1) // 3) + 1\n",
    "\n",
    "# 独热编码\n",
    "enc = preprocessing.OneHotEncoder()\n",
    "enc.fit(X_train_seq)\n",
    "\n",
    "seq_new = list(X_train_seq.columns)\n",
    "\n",
    "# 创建带有列名称的独热编码之后的df\n",
    "X_train_seq = pd.DataFrame(enc.transform(X_train_seq).toarray(), \n",
    "                           columns = cate_colName(enc, seq_new, drop=None))\n",
    "\n",
    "X_test_seq = pd.DataFrame(enc.transform(X_test_seq).toarray(), \n",
    "                          columns = cate_colName(enc, seq_new, drop=None))\n",
    "\n",
    "# 调整index\n",
    "X_train_seq.index = X_train.index\n",
    "X_test_seq.index = X_test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d25e78c-3007-471a-94b3-de8b00a9ca3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ord_enc = OrdinalEncoder()\n",
    "ord_enc.fit(X_train[category_cols])\n",
    "\n",
    "X_train_OE = pd.DataFrame(ord_enc.transform(X_train[category_cols]), columns=category_cols)\n",
    "X_train_OE.index = X_train.index\n",
    "X_train_OE = pd.concat([X_train_OE, X_train[numeric_cols]], axis=1)\n",
    "\n",
    "X_test_OE = pd.DataFrame(ord_enc.transform(X_test[category_cols]), columns=category_cols)\n",
    "X_test_OE.index = X_test.index\n",
    "X_test_OE = pd.concat([X_test_OE, X_test[numeric_cols]], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd866bc-4b69-4b15-a061-b537f589f12b",
   "metadata": {},
   "source": [
    "## <center>Ch.2 基于网格搜索的超参数优化实战"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4593e781-1d24-4ac1-9737-4f61b832d825",
   "metadata": {},
   "source": [
    "&emsp;&emsp;在完成了特征衍生与初步筛选后，接下来就将进入到模型训练与优化的阶段了，正如此前所说，对特征的更精确的筛选其本质也可以看成是一种优化方法。不过需要注意的是，一般在特征初筛结束后，我们都将围绕当前筛选出来的特征尝试进行模型训练，若模型能够有效的挖掘出当前特征池的全部信息，且计算量在可以承受的范围内，则无需进一步进行特征精筛；但如果模型无法有效挖掘当前海量特征的全部信息，甚至是出现了加入新特征的模型效果反而不如只带入原始特征的模型的情况，则需要考虑进一步围绕特征进行更加精确的搜索，以提高模型效果。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c654e5-98fe-455f-904a-3b28eb67ac15",
   "metadata": {},
   "source": [
    "&emsp;&emsp;而要如何才能测试模型能否“消化”当前海量特征池的全部信息呢？很明显，只靠此前介绍的可解释型模型（逻辑回归和决策树模型）肯定是远远不够的，这里我们将采用可解释型更弱、但更能从海量特征池中提取有效信息的集成学习进行建模。并且也将采用模型融合的策略，以进一步提升模型效果和从海量特征中提取有效信息的能力。集成学习+模型融合，这也是效果优先的机器学习建模必然会采用的策略。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7183d168-e6ad-4b78-8f54-3cd9459f18ab",
   "metadata": {},
   "source": [
    "&emsp;&emsp;本节我们先聚焦如何训练并优化好一个集成学习算法，再考虑带入衍生特征后模型的优化方法。这里需要注意，少量特征和海量特征在优化策略方面也会有较大的差别，我们将逐步深入进行介绍。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21786659-8027-482f-8e10-5cc42968b46a",
   "metadata": {},
   "source": [
    "- 随机森林+网格搜索策略"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3271b9-21be-46a3-916e-f91a29b40228",
   "metadata": {},
   "source": [
    "&emsp;&emsp;不过不同于逻辑回归和决策树模型，集成学习的超参数设置与优化会更加复杂。一般来说不同优化器会适用于不同集成算法的超参数空间。关于集成学习的基本原理、超参数解释以及各类不同优化器的基本原理，在此前的课程中都有详细介绍，本节作为实战阶段的内容，将更加注重介绍优化器的实战使用技巧。本节我们将首先介绍一个最基础、但同时也是效果非常好的一套集成学习建模+优化策略，即随机森林模型+网格搜索优化器。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e29ef8-3362-40ae-9d68-c166617f2ebd",
   "metadata": {},
   "source": [
    "&emsp;&emsp;随机森林作为Bagging算法中的集大成者，一直以来都是建模效果最好、适用面最广的集成学习之一，哪怕是在XGBoost、LightGBM和CatBoost这些后起之秀面前，RF也毫不逊色，在很多情况下，RF也是值得甚至是必须尝试的模型。同时，在多模型融合、甚至是多层多模型融合当道的今天，学会针对第一梯队的全部集成学习算法进行训练和调优，就成了所有算法工作人员的必修课。因此本节我们将先从RF开始，介绍集成学习超参数搜索与优化技巧。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17358596-e662-4de1-a79e-08b47f7b17bd",
   "metadata": {},
   "source": [
    "- 网格搜索优化器"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b6c489-d208-46b3-8a00-5f0194115c2c",
   "metadata": {},
   "source": [
    "&emsp;&emsp;而具体到要使用哪种优化器对随机森林进行超参数调优，一般来说肯定是首选网格搜索。其一是因为随机森林的超参数几乎全部都是离散变量，网格搜索完全能够胜任；其二则是这套策略从建模到调优，都可以借助sklearn来完成，无需额外的数据格式转化，同时模型评估器和超参数评估器接口一致，调用起来也会非常方便。当然，对于网格搜索评估器来说，不仅可以应用于随机森林，同时也可以其他很多集成学习的优化，甚至在当下，不同优化器匹配不同集成学习，都成了模型融合提升效果的一种手段。总而言之，数量使用网格搜索进行超参数优化，也是算法工作人员的必修课。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7317ab6f-4703-4765-89a8-a4f7b36c5afc",
   "metadata": {},
   "source": [
    "- sklearn中网格搜索评估器"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab62ccda-dd09-472f-9024-e455f6939547",
   "metadata": {},
   "source": [
    "&emsp;&emsp;目前来说sklearn中超参数优化器有四种，分别是GridSearchCV（网格搜索）、RandomizedSearchCV（随机网格搜索）、HalvingSearchCV（对半网格搜索）和HalvingRandomizedSearchCV（对半随机网格搜索）。其中网格搜索是通过枚举搜索出一组最优超参数，枚举的精度最高但效率最低，也就是网格搜索其实是精度最高的搜索算法，但往往伴随着巨大的计算量；而加入了随机网格搜索，则是随机选取了原始参数空间的子空间，然后在这个子空间内进行枚举，尽管还是枚举，但由于参数空间的缩小，计算量也会随之减少，并且伴随着这个参数子空间不断扩大（可人工修改参数），随机网格搜索的计算量和精度都将逼近网格搜索，简而言之随机网格搜索是一种牺牲精度换效率的搜索方式；相比随机网格搜索，对半网格搜索采用了类似锦标赛的筛选机制进行多轮的参数搜索，每一轮输入原始数据一部分数据进行模型训练，并且剔除一半的备选超参数。由于每一轮都只输入了一部分数据，因此不同备选超参数组的评估可能存在一定的误差，但由于每一轮都只剔除一半的超参数组而不是直接选出最优的超参数组，因此也拥有一定的容错性。不难发现，这个过程也像极了RFE过程——每一轮用一个精度不是最高的模型剔除一个最不重要的特征，即保证了执行效率、同时又保证了执行精度。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46dc7070-239b-4f16-a36d-ed29f0a91443",
   "metadata": {},
   "source": [
    "&emsp;&emsp;如果从一个宏观视角来看，随机网格搜索是通过减少备选参数组来减少计算量，而对半网格搜索则是减少带入的数据量，来减少计算量。二者其实都能一定程度提升超参数的搜索效率，但也存在损失精度的风险。当然，如果还想更进一步提高搜索效率，则可以考虑对半搜索和随机搜索的组合——对半随机网格搜索，这种搜索策略实际上就是对半搜索的思路+随机网格搜索的超参数空间，即在一个超参数子空间内进行多轮筛选，每一轮剔除一半的备选超参数组。这种方法的搜索效率是最高的，但同时精度也相对较差。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb002a45-4cf9-4e9a-8f51-b29903bd698e",
   "metadata": {},
   "source": [
    "&emsp;&emsp;因此，到底选择哪种优化器，实际上还是一个效率和效果平衡的问题。一般来说，首先方案肯定是采用网格搜索进行超参数优化，但不建议设置太大的超参数搜索空间，而是配合人工经验每次设置一个相对较小的参数空间，然后逐步调整、甚至是分参数分批进行搜索，以提高整个搜索效率；而只有当单独一组超参数的训练都非常耗时时，才会考虑使用其他两种超参数搜索方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfc117a-927c-421e-807e-50880b194913",
   "metadata": {},
   "source": [
    "> 若要深究随机网格搜索和对半网格搜索哪个误差更大，则要看情况而定。简单来说，如果超参数空间内，最优超参数组附近存在多个且效果和最优超参数组相近的次优超参数组，则随机网格搜索效果会更好，因为在随机抽样时很有可能抽中次优超参数组；但如果最优超参数组的效果比次优超参数组效果好很多，则对半网格搜索效果会更好，因为此时最优超参数组因为效果拔群，所以哪怕是少量样本，也会更容易脱颖而出。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcbec30-a0c6-419a-bc33-5f286ae3a15f",
   "metadata": {},
   "source": [
    "&emsp;&emsp;本节我们就将围绕当前数据集来进行网格搜索评估器的实战演练，并通过这个过程快速获取参数设置与超参数搜索的经验，如何用好网格搜索评估器进行参数调优，也是所有模型训练进阶的必修课。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bfa97d-6d67-4755-a741-42f61485c36a",
   "metadata": {},
   "source": [
    "- 原始数据不调参"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d97822-7a73-4959-9167-4763bd0381f1",
   "metadata": {},
   "source": [
    "&emsp;&emsp;在进行超参数搜索调参之前，我们先简单测试不进行调优时的模型训练结果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "45ff8455-f44e-43db-a4c8-819cb923b96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58fe9203-5d5c-4134-b594-205a032deb7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12277936935424805\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "RF = RandomForestClassifier(n_jobs=15, random_state=12).fit(X_train_OE, y_train)\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "614da143-8887-4fb4-8fe1-501a1293f55a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9977281332828474, 0.7756956274843839)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF.score(X_train_OE, y_train), RF.score(X_test_OE, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b88effe0-36db-4f6c-9e7f-3251a6c52cab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF.n_estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa3a7e6-6d6e-430e-81e4-d7484ed3d61f",
   "metadata": {},
   "source": [
    "能够发现，在不进行超参数优化时，模型存在明显的过拟合倾向，当然这也是很多集成算法在应对简单数据集时会表现出的一般状况。同时单独模型在小量样本下训练速度较快，在构建100棵树的情况下仅用时0.12s。当然，我们也可以进一步查看当前模型对特征的利用率："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eeb280c0-ac6c-497d-83a1-87dd0e261b97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02812245, 0.01974651, 0.02421983, 0.01963431, 0.00603235,\n",
       "       0.0223819 , 0.02811445, 0.05395741, 0.02698412, 0.02560977,\n",
       "       0.04127569, 0.01718816, 0.01773947, 0.07040168, 0.02639826,\n",
       "       0.05104428, 0.15185081, 0.17836349, 0.19093506])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "00be55d5-edb6-40ca-95db-5052fd2dbac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(RF.feature_importances_ == 0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ec0b27-50e9-4c0f-ab9c-1bce63911843",
   "metadata": {},
   "source": [
    "能够看到，此时并不存在特征重要性为0的特征，即模型在训练过程中用到了全部19个特征，模型利用率比单独树模型更高。当然我们也可以从模型的其他参数观察模型的特征利用效率，在不调参的情况下，随机森林的max_features（每棵树分配到的最多特征）为auto，即特征总数开二次方，即4-5个特征，而总共建了100棵树，每棵树又没有剪枝，自然在极大概率情况下每个特征都会被用到："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "97e3a8ca-d166-439d-9188-67d8f06e122a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'auto'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF.max_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3e66a15f-7f0c-486d-9199-8c20e212cad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.358898943540674"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(19)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c337e037-d56a-46fe-bb62-675091b15c6d",
   "metadata": {},
   "source": [
    "> 注意这几个参数，后面将围绕这几个参数来估计模型调参时的运行时间及模型对特征的利用效率。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276c3da9-794c-49f6-86af-45361c247645",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 一、网格搜索调参实战技巧"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c2ff3f-824a-4f96-aa67-6326be55f5ad",
   "metadata": {},
   "source": [
    "&emsp;&emsp;接下来我们尝试进行网格搜索调参，并在这个过程中介绍网格搜索调参的实战技巧。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e580edb6-c7c9-4eae-9d1c-f8ef2569243f",
   "metadata": {},
   "source": [
    "### 1.确定调优参数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93d2d7b-bec6-480d-9e6b-579413664a90",
   "metadata": {},
   "source": [
    "&emsp;&emsp;首先肯定是要先确定调哪些参数，也就是需要确定模型的参数空间的维度。随机森林参数众多，但不是每个参数都对模型结果有影响，并且有些参数彼此之间是存在关联关系的，调整其中一个或者几个即可，带入太多无关参数会使得参数空间过大、极大程度影响搜索效率。这里回顾随机森林参数如下："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c35374-270d-4723-ac04-b726cffdfb42",
   "metadata": {},
   "source": [
    "|Name|Description|   \n",
    "|:--:|:--:| \n",
    "|n_estimators|决策树模型个数|\n",
    "|criterion|规则评估指标或损失函数，默认基尼系数，可选信息熵| \n",
    "|splitter|树模型生长方式，默认以损失函数取值减少最快方式生长，可选随机根据某条件进行划分|\n",
    "|max_depth|树的最大生长深度，类似max_iter，即总共迭代几次| \n",
    "|min_samples_split|内部节点再划分所需最小样本数| \n",
    "|min_samples_leaf|叶节点包含最少样本数| \n",
    "|min_weight_fraction_leaf|叶节点所需最小权重和| \n",
    "|max_features|在进行切分时候最多带入多少个特征进行划分规则挑选|\n",
    "|random_state|随机数种子| \n",
    "|max_leaf_nodes|叶节点最大个数| \n",
    "|min_impurity_decrease|数据集再划分至少需要降低的损失值| \n",
    "|bootstrap|是否进行自助抽样|\n",
    "|oob_score|是否输出袋外数据的测试结果|\n",
    "|min_impurity_split|数据集再划分所需最低不纯度，将在0.25版本中移除| \n",
    "|class_weight|各类样本权重| \n",
    "|ccp_alpha|决策树限制剪枝参数，相当于风险项系数|\n",
    "|max_samples|进行自助抽样时每棵树分到的样本量|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "57989d0f-5009-4cf0-9b78-40133a91a0f5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m\n",
       "\u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mcriterion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gini'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmin_samples_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmin_samples_leaf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmin_weight_fraction_leaf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmax_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'auto'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmax_leaf_nodes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmin_impurity_decrease\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mbootstrap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0moob_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mwarm_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mccp_alpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmax_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m     \n",
       "A random forest classifier.\n",
       "\n",
       "A random forest is a meta estimator that fits a number of decision tree\n",
       "classifiers on various sub-samples of the dataset and uses averaging to\n",
       "improve the predictive accuracy and control over-fitting.\n",
       "The sub-sample size is controlled with the `max_samples` parameter if\n",
       "`bootstrap=True` (default), otherwise the whole dataset is used to build\n",
       "each tree.\n",
       "\n",
       "Read more in the :ref:`User Guide <forest>`.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "n_estimators : int, default=100\n",
       "    The number of trees in the forest.\n",
       "\n",
       "    .. versionchanged:: 0.22\n",
       "       The default value of ``n_estimators`` changed from 10 to 100\n",
       "       in 0.22.\n",
       "\n",
       "criterion : {\"gini\", \"entropy\"}, default=\"gini\"\n",
       "    The function to measure the quality of a split. Supported criteria are\n",
       "    \"gini\" for the Gini impurity and \"entropy\" for the information gain.\n",
       "    Note: this parameter is tree-specific.\n",
       "\n",
       "max_depth : int, default=None\n",
       "    The maximum depth of the tree. If None, then nodes are expanded until\n",
       "    all leaves are pure or until all leaves contain less than\n",
       "    min_samples_split samples.\n",
       "\n",
       "min_samples_split : int or float, default=2\n",
       "    The minimum number of samples required to split an internal node:\n",
       "\n",
       "    - If int, then consider `min_samples_split` as the minimum number.\n",
       "    - If float, then `min_samples_split` is a fraction and\n",
       "      `ceil(min_samples_split * n_samples)` are the minimum\n",
       "      number of samples for each split.\n",
       "\n",
       "    .. versionchanged:: 0.18\n",
       "       Added float values for fractions.\n",
       "\n",
       "min_samples_leaf : int or float, default=1\n",
       "    The minimum number of samples required to be at a leaf node.\n",
       "    A split point at any depth will only be considered if it leaves at\n",
       "    least ``min_samples_leaf`` training samples in each of the left and\n",
       "    right branches.  This may have the effect of smoothing the model,\n",
       "    especially in regression.\n",
       "\n",
       "    - If int, then consider `min_samples_leaf` as the minimum number.\n",
       "    - If float, then `min_samples_leaf` is a fraction and\n",
       "      `ceil(min_samples_leaf * n_samples)` are the minimum\n",
       "      number of samples for each node.\n",
       "\n",
       "    .. versionchanged:: 0.18\n",
       "       Added float values for fractions.\n",
       "\n",
       "min_weight_fraction_leaf : float, default=0.0\n",
       "    The minimum weighted fraction of the sum total of weights (of all\n",
       "    the input samples) required to be at a leaf node. Samples have\n",
       "    equal weight when sample_weight is not provided.\n",
       "\n",
       "max_features : {\"auto\", \"sqrt\", \"log2\"}, int or float, default=\"auto\"\n",
       "    The number of features to consider when looking for the best split:\n",
       "\n",
       "    - If int, then consider `max_features` features at each split.\n",
       "    - If float, then `max_features` is a fraction and\n",
       "      `round(max_features * n_features)` features are considered at each\n",
       "      split.\n",
       "    - If \"auto\", then `max_features=sqrt(n_features)`.\n",
       "    - If \"sqrt\", then `max_features=sqrt(n_features)` (same as \"auto\").\n",
       "    - If \"log2\", then `max_features=log2(n_features)`.\n",
       "    - If None, then `max_features=n_features`.\n",
       "\n",
       "    Note: the search for a split does not stop until at least one\n",
       "    valid partition of the node samples is found, even if it requires to\n",
       "    effectively inspect more than ``max_features`` features.\n",
       "\n",
       "max_leaf_nodes : int, default=None\n",
       "    Grow trees with ``max_leaf_nodes`` in best-first fashion.\n",
       "    Best nodes are defined as relative reduction in impurity.\n",
       "    If None then unlimited number of leaf nodes.\n",
       "\n",
       "min_impurity_decrease : float, default=0.0\n",
       "    A node will be split if this split induces a decrease of the impurity\n",
       "    greater than or equal to this value.\n",
       "\n",
       "    The weighted impurity decrease equation is the following::\n",
       "\n",
       "        N_t / N * (impurity - N_t_R / N_t * right_impurity\n",
       "                            - N_t_L / N_t * left_impurity)\n",
       "\n",
       "    where ``N`` is the total number of samples, ``N_t`` is the number of\n",
       "    samples at the current node, ``N_t_L`` is the number of samples in the\n",
       "    left child, and ``N_t_R`` is the number of samples in the right child.\n",
       "\n",
       "    ``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,\n",
       "    if ``sample_weight`` is passed.\n",
       "\n",
       "    .. versionadded:: 0.19\n",
       "\n",
       "bootstrap : bool, default=True\n",
       "    Whether bootstrap samples are used when building trees. If False, the\n",
       "    whole dataset is used to build each tree.\n",
       "\n",
       "oob_score : bool, default=False\n",
       "    Whether to use out-of-bag samples to estimate the generalization score.\n",
       "    Only available if bootstrap=True.\n",
       "\n",
       "n_jobs : int, default=None\n",
       "    The number of jobs to run in parallel. :meth:`fit`, :meth:`predict`,\n",
       "    :meth:`decision_path` and :meth:`apply` are all parallelized over the\n",
       "    trees. ``None`` means 1 unless in a :obj:`joblib.parallel_backend`\n",
       "    context. ``-1`` means using all processors. See :term:`Glossary\n",
       "    <n_jobs>` for more details.\n",
       "\n",
       "random_state : int, RandomState instance or None, default=None\n",
       "    Controls both the randomness of the bootstrapping of the samples used\n",
       "    when building trees (if ``bootstrap=True``) and the sampling of the\n",
       "    features to consider when looking for the best split at each node\n",
       "    (if ``max_features < n_features``).\n",
       "    See :term:`Glossary <random_state>` for details.\n",
       "\n",
       "verbose : int, default=0\n",
       "    Controls the verbosity when fitting and predicting.\n",
       "\n",
       "warm_start : bool, default=False\n",
       "    When set to ``True``, reuse the solution of the previous call to fit\n",
       "    and add more estimators to the ensemble, otherwise, just fit a whole\n",
       "    new forest. See :term:`the Glossary <warm_start>`.\n",
       "\n",
       "class_weight : {\"balanced\", \"balanced_subsample\"}, dict or list of dicts,             default=None\n",
       "    Weights associated with classes in the form ``{class_label: weight}``.\n",
       "    If not given, all classes are supposed to have weight one. For\n",
       "    multi-output problems, a list of dicts can be provided in the same\n",
       "    order as the columns of y.\n",
       "\n",
       "    Note that for multioutput (including multilabel) weights should be\n",
       "    defined for each class of every column in its own dict. For example,\n",
       "    for four-class multilabel classification weights should be\n",
       "    [{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of\n",
       "    [{1:1}, {2:5}, {3:1}, {4:1}].\n",
       "\n",
       "    The \"balanced\" mode uses the values of y to automatically adjust\n",
       "    weights inversely proportional to class frequencies in the input data\n",
       "    as ``n_samples / (n_classes * np.bincount(y))``\n",
       "\n",
       "    The \"balanced_subsample\" mode is the same as \"balanced\" except that\n",
       "    weights are computed based on the bootstrap sample for every tree\n",
       "    grown.\n",
       "\n",
       "    For multi-output, the weights of each column of y will be multiplied.\n",
       "\n",
       "    Note that these weights will be multiplied with sample_weight (passed\n",
       "    through the fit method) if sample_weight is specified.\n",
       "\n",
       "ccp_alpha : non-negative float, default=0.0\n",
       "    Complexity parameter used for Minimal Cost-Complexity Pruning. The\n",
       "    subtree with the largest cost complexity that is smaller than\n",
       "    ``ccp_alpha`` will be chosen. By default, no pruning is performed. See\n",
       "    :ref:`minimal_cost_complexity_pruning` for details.\n",
       "\n",
       "    .. versionadded:: 0.22\n",
       "\n",
       "max_samples : int or float, default=None\n",
       "    If bootstrap is True, the number of samples to draw from X\n",
       "    to train each base estimator.\n",
       "\n",
       "    - If None (default), then draw `X.shape[0]` samples.\n",
       "    - If int, then draw `max_samples` samples.\n",
       "    - If float, then draw `max_samples * X.shape[0]` samples. Thus,\n",
       "      `max_samples` should be in the interval `(0.0, 1.0]`.\n",
       "\n",
       "    .. versionadded:: 0.22\n",
       "\n",
       "Attributes\n",
       "----------\n",
       "base_estimator_ : DecisionTreeClassifier\n",
       "    The child estimator template used to create the collection of fitted\n",
       "    sub-estimators.\n",
       "\n",
       "estimators_ : list of DecisionTreeClassifier\n",
       "    The collection of fitted sub-estimators.\n",
       "\n",
       "classes_ : ndarray of shape (n_classes,) or a list of such arrays\n",
       "    The classes labels (single output problem), or a list of arrays of\n",
       "    class labels (multi-output problem).\n",
       "\n",
       "n_classes_ : int or list\n",
       "    The number of classes (single output problem), or a list containing the\n",
       "    number of classes for each output (multi-output problem).\n",
       "\n",
       "n_features_ : int\n",
       "    The number of features when ``fit`` is performed.\n",
       "\n",
       "    .. deprecated:: 1.0\n",
       "        Attribute `n_features_` was deprecated in version 1.0 and will be\n",
       "        removed in 1.2. Use `n_features_in_` instead.\n",
       "\n",
       "n_features_in_ : int\n",
       "    Number of features seen during :term:`fit`.\n",
       "\n",
       "    .. versionadded:: 0.24\n",
       "\n",
       "feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
       "    Names of features seen during :term:`fit`. Defined only when `X`\n",
       "    has feature names that are all strings.\n",
       "\n",
       "    .. versionadded:: 1.0\n",
       "\n",
       "n_outputs_ : int\n",
       "    The number of outputs when ``fit`` is performed.\n",
       "\n",
       "feature_importances_ : ndarray of shape (n_features,)\n",
       "    The impurity-based feature importances.\n",
       "    The higher, the more important the feature.\n",
       "    The importance of a feature is computed as the (normalized)\n",
       "    total reduction of the criterion brought by that feature.  It is also\n",
       "    known as the Gini importance.\n",
       "\n",
       "    Warning: impurity-based feature importances can be misleading for\n",
       "    high cardinality features (many unique values). See\n",
       "    :func:`sklearn.inspection.permutation_importance` as an alternative.\n",
       "\n",
       "oob_score_ : float\n",
       "    Score of the training dataset obtained using an out-of-bag estimate.\n",
       "    This attribute exists only when ``oob_score`` is True.\n",
       "\n",
       "oob_decision_function_ : ndarray of shape (n_samples, n_classes) or             (n_samples, n_classes, n_outputs)\n",
       "    Decision function computed with out-of-bag estimate on the training\n",
       "    set. If n_estimators is small it might be possible that a data point\n",
       "    was never left out during the bootstrap. In this case,\n",
       "    `oob_decision_function_` might contain NaN. This attribute exists\n",
       "    only when ``oob_score`` is True.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "sklearn.tree.DecisionTreeClassifier : A decision tree classifier.\n",
       "sklearn.ensemble.ExtraTreesClassifier : Ensemble of extremely randomized\n",
       "    tree classifiers.\n",
       "\n",
       "Notes\n",
       "-----\n",
       "The default values for the parameters controlling the size of the trees\n",
       "(e.g. ``max_depth``, ``min_samples_leaf``, etc.) lead to fully grown and\n",
       "unpruned trees which can potentially be very large on some data sets. To\n",
       "reduce memory consumption, the complexity and size of the trees should be\n",
       "controlled by setting those parameter values.\n",
       "\n",
       "The features are always randomly permuted at each split. Therefore,\n",
       "the best found split may vary, even with the same training data,\n",
       "``max_features=n_features`` and ``bootstrap=False``, if the improvement\n",
       "of the criterion is identical for several splits enumerated during the\n",
       "search of the best split. To obtain a deterministic behaviour during\n",
       "fitting, ``random_state`` has to be fixed.\n",
       "\n",
       "References\n",
       "----------\n",
       ".. [1] L. Breiman, \"Random Forests\", Machine Learning, 45(1), 5-32, 2001.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> from sklearn.ensemble import RandomForestClassifier\n",
       ">>> from sklearn.datasets import make_classification\n",
       ">>> X, y = make_classification(n_samples=1000, n_features=4,\n",
       "...                            n_informative=2, n_redundant=0,\n",
       "...                            random_state=0, shuffle=False)\n",
       ">>> clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
       ">>> clf.fit(X, y)\n",
       "RandomForestClassifier(...)\n",
       ">>> print(clf.predict([[0, 0, 0, 0]]))\n",
       "[1]\n",
       "\u001b[1;31mFile:\u001b[0m           d:\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\n",
       "\u001b[1;31mType:\u001b[0m           ABCMeta\n",
       "\u001b[1;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "RandomForestClassifier?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98ff05d-a02f-4c31-9c1f-d94e9495ec75",
   "metadata": {},
   "source": [
    "&emsp;&emsp;随机森林的参数整体可以分为两个大类，其一是单独一颗树的剪枝参数，包括splitter、max_depth、min_samples_split、min_samples_leaf、min_weight_fraction_leaf、max_leaf_nodes、min_impurity_decrease、ccp_alpha等，从树模型的理论上来看，这些参数统一可以由ccp_alpha一个参数代替，但随机森林是由多棵树构成，我们无法单独针对每棵树设置一个ccp_alpha，并且由于sklearn的决策树计算流程和CART树的原理存在一定差异，因此ccp_alpha参数实际剪枝效果并不明显。在单独决策树的剪枝参数中，核心参数有以下四个，分别是min_samples_leaf、min_samples_split、max_leaf_nodes和max_depth，这四个参数的组合效果基本就能够完全决定单独一个决策树的剪枝结果，若有余力，可考虑围绕剩余参数进行搜索。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00983e5-e5da-4876-9fbf-aaf80dd203e0",
   "metadata": {},
   "source": [
    "> 决策树的其他参数优化效果并不显著，另一个原因也是因为其他参数都是连续型变量，而网格搜索对连续型变量的最优值搜索效果并不好，而且通过枚举的方法搜索连续变量也将耗费非常大的计算量。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de91c76-9d6a-4f9e-a099-754248de979b",
   "metadata": {},
   "source": [
    "&emsp;&emsp;而第二类参数则是随机森林的集成类参数，包括n_estimators、bootstrap、max_features、max_samples、oob_score等，对于随机森林来说，自助抽抽样是提升Bagging效果的重要手段，因此bootstrap需要设置为True，并且max_samples需要参与搜索，而由于网格搜索中并不会用到oob_score，因此该参数可以设置为False。而在其他参数中，n_estimators和max_features两个参数也是影响模型效果的重要参数，需要进行搜索。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb83b413-10d2-4680-abc2-03051853c350",
   "metadata": {},
   "source": [
    "> 此外需要注意的是，如果样本偏态非常明显，并且最终模型是以Recall或者F1-Score作为评估指标，则可以考虑带入class_weight进行搜索。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a6cffc-026f-4234-9002-4402ac524c2b",
   "metadata": {},
   "source": [
    "> 另外，关于随机数种子random_state，一般来说对于大样本而言，影响并不明显，而如果是小样本，则会有一定程度影响。Telco数据集是相对较小的数据集，但并不建议对random_state进行搜索，其一是random_state其实是一个无限的搜索空间、并且没有任何取值规律可言，最重要的一点，在下一小节我们将介绍关于模型“自融合”的方法，通过该方法输出的模型融合结果，也将极大程度减少random_state对最终预测结果的影响。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e8a186-fc86-494d-a704-87a811a4b266",
   "metadata": {},
   "source": [
    "&emsp;&emsp;总结一下，针对当前数据集，我们需要围绕就min_samples_leaf、min_samples_split、max_leaf_nodes、max_depth、max_samples、n_estimators、max_features七个参数进行搜索调优。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1144729-54ef-472e-9488-9643c2684bfc",
   "metadata": {},
   "source": [
    "### 2.设计参数空间时面临的“舍罕王赏麦”问题"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e330b805-e9f0-4fb1-9853-eade01425b78",
   "metadata": {},
   "source": [
    "&emsp;&emsp;<font face=\"仿宋\">“传说国际象棋的发明者是古印度的西萨·班·达依尔。那时的国王是舍罕，世人称为舍罕王。国王想奖励他便问宰相需要得到什么赏赐。宰相开口说道：“请您在棋盘的第一个格子上放1粒麦子，第二个格子上放2粒，第三个格子上放4粒，第四个格子放8粒...即每一个次序在后的格子上放的麦粒必须是前一个格子麦粒数的倍数，直到最后一个格子即第64格放满为止，这样我就十分满足了。”国王哈哈大笑，慷慨地答应了宰相的这个谦卑的请求。这位聪明的宰相到底要求的是多少麦粒呢？”      --《舍罕王赏麦》"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75ca5f3-9fe7-4dac-b642-f5fdd53f5c78",
   "metadata": {},
   "source": [
    "> <font face=\"仿宋\">按照这个指数级增长的结果，宰相的要求实际上是$2^{64}-1$粒大米，相当于当时全世界在2000年内所产小麦的总和。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfde509-58e5-41e6-9228-0a9219de03ec",
   "metadata": {},
   "source": [
    "&emsp;&emsp;在确定了要调优哪些参数后，接下来就需要确定每个参数的搜索空间了，这一步也是直接关系到参数搜索效率的关键步骤。首先我们需要对参数搜索需要耗费的时间有基本的判断，才好进行进一步搜索策略的制定，否则极容易出现“仿佛永远等不到搜索停止”的情况出现。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80937f39-b3ef-4f3c-8ac1-7199c96d5838",
   "metadata": {},
   "source": [
    "&emsp;&emsp;首先需要明确的是，参数空间内总备选参数组合的数量为各参数取值之积，且随着参数空间内每个参数取值增加而呈现指数级上升，且随着参数空间内参数维度增加（增加新的超参数）呈指数级上升，且二者呈现叠加效应。例如现有参数空间如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9c801c8c-c48d-4c6d-b68c-50c6cd1b4f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 参数空间有4个备选参数组合\n",
    "parameter_space0 = {\"min_samples_leaf\": range(1, 3),\n",
    "                    \"min_samples_split\": range(1, 3)\n",
    "                   }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ba113c-4d19-482c-ad06-9cc6bc5d8d89",
   "metadata": {},
   "source": [
    "则备选的参数组合有$2*2=4$个。而此时如果调整\"min_samples_leaf\": range(1, 4)，则备选参数组合就变成了$2*3=6$个，也就是说,\"min_samples_leaf\"参数搜索范围增加1，造成的搜索次数增加了两次，而非一次。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cb2415b2-8d11-47d4-8236-dc0733ee4b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 参数空间有6个备选参数组合\n",
    "parameter_space1 = {\"min_samples_leaf\": range(1, 4),\n",
    "                    \"min_samples_split\": range(1, 3)\n",
    "                   }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98876ce3-8ab0-467e-9a0e-be535fd96f46",
   "metadata": {},
   "source": [
    "并且，如果我们新增一个超参数维度\"max_depth\": range(1, 4)，则目前总共的备选参数组合就达到了$2*3*3=18$个，也就是说,增加\"min_samples_split\"3个数值，造成的搜索次数增加了18-6=12次，而非3次："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cf268eb-9d7f-4023-8bbb-d5e3f8cc4c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 参数空间有18个备选参数组合\n",
    "parameter_space2 = {\"min_samples_leaf\": range(1, 4),\n",
    "                    \"min_samples_split\": range(1, 3), \n",
    "                    \"max_depth\": range(1, 4)\n",
    "                   }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bc955a-2df4-4acb-adb3-58fbd0acdc90",
   "metadata": {},
   "source": [
    "&emsp;&emsp;当然，这种指数级的变化在少量数据情况下可能无法看出“真正的威力”，但如果参数稍微多些或计算过程稍微复杂些，例如假设parameter_space1搜索任务耗时5分钟，而在只增加了一个参数及3个不同取值的情况下，parameter_space2就将耗费15分钟。而如果更复杂些，不是5\\*3=15分钟，而是15\\*3=45分钟呢，甚至是1小时\\*3=3小时呢，参数空间的略微扩大就可能造成搜索时间的指数级增加。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d669f4ae-55e5-463a-b604-ce5daed7a94d",
   "metadata": {},
   "source": [
    "> 此外，在进行网格搜索时，每一次建模背后还存在5折交叉验证，也就是需要训练5次模型，而每一次随机森林的建模，都伴随着几十个甚至是上百个决策树模型训练，背后的计算量可想而知。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08acf90-d2c2-4355-b29b-09ead2f70989",
   "metadata": {},
   "source": [
    "&emsp;&emsp;介于此，在参数空间设计时就会有这样一个核心问题，那就是参数空间设置小了不确定最优参数是否在这个空间内，参数空间设置大了又不确定何时能算完。这也就是所谓的参数空间设计时面临的“舍罕王赏麦”问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de77be5-fac9-4b86-bd79-f9934121650d",
   "metadata": {},
   "source": [
    "> <font face=\"仿宋\">舍罕王赏麦后续：国王哪有这么多麦子呢？他的一句慷慨之言，成了他欠宰相西萨·班·达依尔的一笔永远也无法还清的债。正当国王一筹莫展之际，王太子的数学老师知道了这件事，他笑着对国王说：“陛下，这个问题很简单啊，就像1+1=2一样容易，您怎么会被它难倒？”国王大怒：“难道你要我把全世界所有的小麦都给他？”年轻的教师说：“没有必要啊，陛下，其实，您只要让宰相大人到粮仓去，自己数出那些麦子就可以了，假如宰相大人一秒钟数一粒，数完所有的麦子所需要的时间，大约是5800亿年，就算宰相大人日夜不停地数，数到他魂归极乐，也只是数出那些麦粒中极小的一部分，这样的话，就不是陛下无法支付赏赐，而是宰相大人自己没有能力取走赏赐。”国王恍然大悟，当下就召来宰相，将教师的方法告诉了他。西萨·班·达依尔沉思片刻后笑道：“陛下啊，您的智慧超过了我，那些赏赐，我也只好不要了！”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b46b7ef-045d-4166-8ec7-a02c95030ea6",
   "metadata": {},
   "source": [
    "### 3.超参数搜索的“凸函数”假设"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a79f94-7b24-4182-8d43-95efac7cd6bc",
   "metadata": {},
   "source": [
    "&emsp;&emsp;如何解决这个问题，最好的解决方案是“小步迭代、快速调整”。在介绍这种方案之前，要先介绍在超参数调优时大家都会默认的一个假设，那就是超参数的取值和模型效果往往呈现严格“凸函数”的特性，例如假设参数\"min_samples_leaf\"在取值为5时模型效果最好，那么在参数取值为1、2、3、4时，模型效果是依次递增的，而如果参数取值为6、7、8，则模型效果是依次递减的，因此如果我们设计的该参数的搜索空间是\"min_samples_leaf\": range(6, 9)，参数在6、7、8之间取值，则最优结果将会是min_samples_leaf=6，即预设的参数空间的下届，此时我们就需要进一步的移动参数空间，例如改为\"min_samples_leaf\": range(5, 8)，即让参数在5、6、7之间取值，很明显，最终输出的挑选结果将会是min_samples_leaf=5，但此时仍然是搜索空间的下届，因此我们还需要进一步移动搜索空间，即移动至\"min_samples_leaf\": range(4, 7)，即让参数在4、5、6之间取值，此时输出的最优结果将会是min_samples_leaf=5，此时就无需再移动超参数空间了，因为此时的参数空间已经包括了“凸函数”的最小值点，再往左边移动没有任何意义，这个过程如下图所示："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038437dd-0375-42b4-803d-933b3de2455e",
   "metadata": {},
   "source": [
    "<center><img src=\"https://s2.loli.net/2022/05/01/R5gubzxKyrVeWcd.png\" alt=\"image-20220501213631356\" style=\"zoom:50%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd77ff0d-a0ca-4dfb-acf2-4fb93087d596",
   "metadata": {},
   "source": [
    "对于单个参数来说，如果呈现出搜索空间包含了最优值点（或者最优值点不在搜索空间的边界上）时，则判断已经找到了最优超参数。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb102063-7a61-413f-a16f-8a56709648c8",
   "metadata": {},
   "source": [
    "> 如果超参数的取值不仅是数值，而是数值和其他类型对象混合的情况，则其他类型对象需要单独作为一个备选项参与搜索。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7367462-8e3b-40bd-9855-e42c04e6f39d",
   "metadata": {},
   "source": [
    "&emsp;&emsp;对于单个变量是如此，对于多个变量来说也是如此，若最终超参数搜索结果呈以下状态，则说明我们已经找到了一组最优超参数组："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cc1c1e-5870-4273-8a4f-a4f09badb7b5",
   "metadata": {},
   "source": [
    "<center><img src=\"https://s2.loli.net/2022/05/01/vWeEnyfFau6soO8.png\" alt=\"image-20220501214514625\" style=\"zoom:50%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51715ecd-8a44-4fc5-8f8f-c5f79c8565d1",
   "metadata": {},
   "source": [
    "> 当然，这种“凸函数假设”其实并没有充份严谨的理论依据，更多的是人们长期实践总结出来的结论。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529202eb-157e-4f29-af34-19753fb21f33",
   "metadata": {},
   "source": [
    "### 4.小步前进，快速调整"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f79abc-d4dd-4e17-9712-2e801a1c7140",
   "metadata": {},
   "source": [
    "&emsp;&emsp;接下来我们来看如何通过“小步迭代快速调整”的方法来进行超参数的搜索。在这个策略里，我们每次需要设置一个相对较小的参数搜索空间，然后快速执行一次超参数搜索，并根据超参数搜索结果来调整参数空间，并进行更进一步的超参数搜索，如此往复，直到参数空间内包含了全部参数的最优解为止。就像此前举例的那样，我们不会给\"min_samples_leaf\"一次设置一个非常大的参数搜索范围（如[1,9]），而是每次设置一个更小的搜索范围，通过不断调整这个范围来定位最优解。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70df1e4-2c47-4aaf-81c7-f19cc2395e27",
   "metadata": {},
   "source": [
    "&emsp;&emsp;既然要反复执行搜索任务，就必然需要一定程度控制单次搜索任务所需要的时间。当然，单次搜索的时间会和CPU、数据量、参数空间大小有关，但一般来说，对于小样本，单次搜索任务最好控制在5-30min内，而对于海量样本，最好也控制在30min-2H内，特殊情况可以适当放宽单次搜索任务的时间。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d3b431-2031-4ea5-a102-de488c70340e",
   "metadata": {},
   "source": [
    "&emsp;&emsp;不过无论单次搜索任务耗时或长或短，我们都需要首先有个大概的预判，即本次搜索需要多久，方便我们确定“下次回来看结果”的时间。这里我们以Telco原始数据集为例，来简单测试单次搜索任务需要的时间。这里我们先测试最短单次搜索需要耗费的时间，由于我们需要让每个最优参数落在某个区间的中间，因此每个超参数的取值范围区间至少包含三个数值，例如\"min_samples_leaf\": range(4, 7)、该参数本次搜索至少有三个备选值，此外，如果有些参数包含非数值型参数，则需要在数值参数区间基础上再加上一个非数值型参数，例如\"max_samples\":\\[None, 0.6, 0.5, 0.4\\]。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69100a3b-6e48-440f-acd9-53e1ce51e17f",
   "metadata": {},
   "source": [
    "### 5.首次搜索时超参数取值范围的经验依据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0a36a2-e0a5-40e6-a299-206a6d544115",
   "metadata": {},
   "source": [
    "&emsp;&emsp;接下来介绍首次搜索时超参数取值范围的经验依据，也就是在第一次设置超参数搜索空间时，随机森林模型推荐的超参数取值范围。我们知道，从理论上来说，每个超参数都有可能有非常多个备选的取值，例如min_samples_leaf，就可以在1到样本总数之间取任意值，但实际上根据长期模型优化的结果来看，大多数情况下min_samples_leaf的最优取值都是在2到10之间，因此min_samples_leaf的初始三个取值可以设置为range(1, 10, 3)，也就是[1, 4, 7]。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "96e9484b-a0a9-49f7-9c33-ad0a74f00dbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 4, 7]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(1, 10, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b437ae-9c64-4a7a-9fd7-0b5b88462e42",
   "metadata": {},
   "source": [
    "并且在这次搜索过程中，如果出现最优取值为4，则说明最优取值在4附近，下一轮就可以设置为[3, 4, 5]，进一步确定最优取值。类似的情况还有min_samples_split。而max_depth的取值范围一般在5到20之间，超过20层的树往往都是过拟合的模型，而如果本身数据量较小，max_depth的最优取值一般不会超过15，因此max_depth的初始搜索范围可以设置为range(5, 16, 5)，即[5, 10, 15]。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "25e017ec-3c68-4a80-86d8-a8643f5c884c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 10, 15]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(5, 16, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25c7655-8f70-4349-8947-9868180933d9",
   "metadata": {},
   "source": [
    "而max_features的参数范围设置会跟样本特征数量有关。我们知道，在默认情况下max_features='auto'，假设样本总共有m个特征，每个决策树将分配$\\sqrt{m}$个特征，max_features备选参数为log2，即每个决策树将分配$log_2{m}$个特征。一般来说max_features的最优解会落在[$log_2{m}$*50%,$\\sqrt{m}$*150%]范围内，假设现在有100个特征，则max_features的最优值经验范围为："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "52589b6f-380b-48a2-92fb-a46ced28172b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.321928094887362"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log2(100) * 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "92d18fbb-00b1-4b52-be73-975a71515b3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(100) * 1.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4b9757-cd50-49fe-b825-9cda0064f24b",
   "metadata": {},
   "source": [
    "即[3, 15]之间，但需要注意的是，除了搜索具体的数值外，还需要加上sqrt和log2两个参数，因此，对于一个包含了100个特征的数据集来说，我们可以设置如下max_features初始参数搜索范围："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6e76cd11-e12c-45ab-a261-c0b11daf4a55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sqrt', 'log2', 3, 6, 9, 12]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "['sqrt', 'log2'] + list(range(3, 15, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7ea40c-3f2e-4749-b2cf-cf5d8349ee14",
   "metadata": {},
   "source": [
    "> 对于随机森林来说，max_features参数也可以设置为0到1之间的浮点数，此时就是按比例设置带入特征。出于更精准的角度考虑，最好是搜索到带入多少个特征，而不是带入百分之多少特征。另外，百分比实际上也是连续变量，正如此前所说，对连续变量进行网格搜索，也会产生较大误差。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e00c5a-0206-4868-867e-8f7b020f9892",
   "metadata": {},
   "source": [
    "&emsp;&emsp;接下来是n_estimators，树模型总数，这是一个变动很大的参数，总的来说会和特征彼此之间的相似程度有关，特征彼此之间相似度越高、n_estimators取值就越小，反之n_estimators取值就越大，当然n_estimators也会一定程度受到样本数量影响。但综合来看，n_estimators基本是在10到200之间取值，如果样本数量较少（例如样本数量不足1万条），则n_estimators会在10到150之间取值。本数据集实际上属于样本数量较少的数据集，因此n_estimators基本会在10到150之间取值，我们可以设置如下初步搜索范围："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "11b002e8-3a51-44e9-9fbc-482df2f3f4eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 80, 150]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(10, 160, 70))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21321bea-21f0-4851-96b3-228f48d58259",
   "metadata": {},
   "source": [
    "> 对于最优值高度不确定的超参数，我们往往会设置一个较大的初始搜索超参数空间，但代价就是往往可能需要更多轮的搜索才能确定最优超参数。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8d0eca-25df-48d8-b270-a927ff175e4b",
   "metadata": {},
   "source": [
    "&emsp;&emsp;接下来是max_leaf_nodes，该参数默认情况下为None，也就是不限制叶节点个数，该参数会受到树深度、每棵树接受到的数据量有关，一般来说max_leaf_nodes的数值往往在20到100之间，而对于小样本数据集，max_leaf_nodes初始范围建议设置在20到70之间："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "487ba1e5-1f99-4b30-a5aa-70f39b030b3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, 20, 40, 60]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[None] + list(range(20, 70, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c888225a-2d14-42fc-a1b2-564ecae2e306",
   "metadata": {},
   "source": [
    "&emsp;&emsp;max_samples的默认参数同样也是None，即每棵决策树都接受和原始样本数量相同的样本量，和max_features一样，max_samples也支持输入整数对象和浮点数对象，输入整数对象时表示具体带入多少条数据，而输入浮点数对象时，则表示每棵树接收样本数量占总样本比例。对于大部分模型来说，将max_samples调到0.5以下（也就是输入50%的样本）才会有模型提升效果，因此初始情况下建议设置如下参数组："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fbc9899a-3533-43bc-ad87-5c022a580bf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, 0.4, 0.5, 0.6]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[None, 0.4, 0.5, 0.6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73168ffa-2793-49f2-8ba8-b71912a28c39",
   "metadata": {},
   "source": [
    "先确定一个大概的最优比例，然后再搜索具体带入多少条样本的样本数。例如假设总共是100条样本，第一轮搜索结果是max_samples=0.4，则接下来可以继续搜索[35, 40, 45]，进一步缩小范围，并最终搜索到一个更加精准的数值。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1b6ba7-3220-41e9-a059-c7bdc73bbbca",
   "metadata": {},
   "source": [
    "&emsp;&emsp;总结一下，随机森林需要搜索的7个参数及其第一轮搜索时建议的参数空间如下："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b636b29-e000-45a4-8df3-fd28893afffa",
   "metadata": {},
   "source": [
    "|params|经验最优范围|\n",
    "|:--:|:--:|\n",
    "|min_samples_leaf|[1, 4, 7]; range(1, 10, 3)|\n",
    "|min_samples_split|[1, 4, 7]; range(1, 10, 3)| \n",
    "|max_depth|[5, 10, 15]; range(5, 16, 5) |\n",
    "|max_leaf_nodes|[None, 20, 40, 60]; [None] + list(range(20, 70, 20))|\n",
    "|n_estimators|[10, 80, 150]; range(10, 160, 70)|\n",
    "|max_features|['sqrt', 'log2'] +[$log_2{(m)}$*50%,$\\sqrt{m}$*150%]  其中m为特征数量|\n",
    "|max_samples|[None, 0.4, 0.5, 0.6]|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40753543-6cf4-402a-8999-9445f2f030e9",
   "metadata": {},
   "source": [
    "&emsp;&emsp;在设置了初始参数后，接下来就是一轮轮搜索与调整了，我们需要大致掌握每一次搜索任务所需要耗费的时间，然后在每次搜索任务结束时及时回到电脑前，准备设置调整参数空间并进行下一次搜索。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665c7bcd-0305-41ad-91ff-15e889354d16",
   "metadata": {},
   "source": [
    "### 6.超参数之间的交叉影响"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edd1a94-804c-4c88-a7c1-fa62e6cc05ca",
   "metadata": {},
   "source": [
    "&emsp;&emsp;并且需要注意的是，在进行超参数搜索时，超参数彼此之间是存在交叉影响的，因此如果某次搜索只带入了部分参数进行搜索，那么如果后续增加了其他参数，则再次搜索时这些超参数的最优值也会发生变化。例如某次搜索超参数A在[1,2,3]中取值，找到了最优值A=2，现在如果继续加入超参数B，同时搜索A在[1,2,3]和B在[2,3,4]中最优取值组合，则极有可能出现A的最优取值变成了A=3，此时就要移动A的取值范围了（最优值落在了边界上），接下来如果继续加入超参数C、超参数D、超参数E等，每次加入一个都需要重新搜索一次，这个过程就会变得非常麻烦。当然，需要注意的是，如果只有A和B两个超参数，那么确实可以先搜索A、再搜索B，因为在两个超参数的情况下，二者相互影响有限，单独围绕A搜索出来的最优值2，在加入超参数B之后，A的最优值极有可能仍然在2附近变动，此时我们可以以2为中心设置搜索范围，之前搜索出来的A=2的最优值结果，在同时搜索A和B时仍然具有参考价值。但如果后续加入了C、D、E等更多的超参数，由于超参数彼此之间相互影响也会呈现指数级变动，因此极有可能后续A的取值会偏离2较远，有可能会变成10、20甚至是30，此时反观最开始搜索出来的A=2的最优值，对后续A的搜索过程就变得毫无价值了。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fb2360-66cd-431e-a6cd-d236518550e7",
   "metadata": {},
   "source": [
    "&emsp;&emsp;因此，受此启发，一般来说如果超参数个数较多，则可以分两批、甚至是分三批进行搜索，例如有A、B、C、D、E五个超参数时，可以先搜索A、B、C，在搜索出一组最优值后，再以此为中心创建搜索空间并加入新的D、E两个参数，设置各自对应的搜索空间，并进行第二批搜索。基本过程如下："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302c1203-9405-45f1-a053-a44020495de6",
   "metadata": {},
   "source": [
    "<center><img src=\"https://s2.loli.net/2022/05/02/Utqh532l7dfnJSj.png\" alt=\"image-20220502165350402\" style=\"zoom:50%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89213a49-ec15-4c59-a3fa-6fbea30117d3",
   "metadata": {},
   "source": [
    "> 总之，最终一定要得到一个全部超参数每个最优点都在给定区间范围内的结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68cb2b1-d71e-4f91-8999-33c086268ae1",
   "metadata": {},
   "source": [
    "&emsp;&emsp;此外，正如此前所说，如果算力有限或者经过尝试发现以此搜索任务耗费时间过长，则可以将所有的参数分两批进行搜索，对于上述这七个参数来说，我们可以先围绕彼此关联度较为紧密的min_samples_leaf、min_samples_split、max_depth、max_leaf_nodes和n_estimators五个参数进行搜索，然后再加入max_features和max_samples进行搜索。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfbadf5-58e7-42ff-bf89-4693138cadcb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 二、随机森林网格搜索调参实战"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb80c9c-4a49-468f-b1d4-82d8e0247462",
   "metadata": {},
   "source": [
    "&emsp;&emsp;在有了网格搜索优化技巧的基础知识储备后，接下来我们围绕Telco原生数据集来进行随机森林网格搜索实战。一方面测试在原始数据集情况下随机森林模型超参数优化的最好结果，同时我们也将用过一个实例来具体观察我们制定的“小步迭代、快速调整”的调优策略是否能真的帮助我们高效快速的确定最优超参数。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab90ff0d-3ea3-42b2-98ce-9e3843b36670",
   "metadata": {},
   "source": [
    "### 1.设置初始参数空间与第一轮搜索"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf597832-1202-41e1-a48b-e00b0a0680e1",
   "metadata": {},
   "source": [
    "- 首轮搜索"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56167cc5-dfcf-4584-a689-5974c65ab58a",
   "metadata": {},
   "source": [
    "&emsp;&emsp;首先，根据此前介绍，设置初始参数空间并进行搜索，同时计算本次运行的时间。原始数据集总共有19条特征，开方运算与log2计算结果如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2b2664a7-52de-470c-970a-ddc618f843fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.358898943540674"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "aa6b4583-5b88-4f50-9d88-e665c97ad44c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.538348415311011"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(19) * 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2a595748-aac2-4daa-a72a-e90ed713de09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1239637567217926"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log2(19) * 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c30cd94-14de-437e-8b6d-3f6950fb344c",
   "metadata": {},
   "source": [
    "此时max_features可以设置参数如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a1afd8ab-1407-4072-b2be-e222a1d4865a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sqrt', 'log2', 2, 4, 6]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "['sqrt', 'log2'] + list(range(2, 7, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04cf694-11d6-47ac-8ea5-0b4266a61350",
   "metadata": {},
   "source": [
    "据此可执行第一轮搜索如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e7ab521a-58a4-499a-9038-728ab91ca486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226.55377650260925\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# 设置超参数空间\n",
    "parameter_space = {\n",
    "    \"min_samples_leaf\": range(1, 10, 3), \n",
    "    \"min_samples_split\": range(1, 10, 3),\n",
    "    \"max_depth\": range(5, 16, 5),\n",
    "    \"max_leaf_nodes\": [None] + list(range(20, 70, 20)), \n",
    "    \"n_estimators\": range(10, 160, 70), \n",
    "    \"max_features\":['sqrt', 'log2'] + list(range(2, 7, 2)), \n",
    "    \"max_samples\":[None, 0.4, 0.5, 0.6]}\n",
    "\n",
    "# 实例化模型与评估器\n",
    "RF_0 = RandomForestClassifier(random_state=12)\n",
    "grid_RF_0 = GridSearchCV(RF_0, parameter_space, n_jobs=15)\n",
    "\n",
    "# 模型训练\n",
    "grid_RF_0.fit(X_train_OE, y_train)\n",
    "\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40de5df1-9cee-4055-92f0-0acc45f8a462",
   "metadata": {},
   "source": [
    "- 计算运行时间与参数空间"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150ecc42-38c1-4206-9bb6-a2db8b8a0588",
   "metadata": {},
   "source": [
    "第一轮搜索在五折交叉验证的条件下，总共搜索了6480组参数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4cf1d9d-1d4a-412b-8846-bf323102b604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6480"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3 * 3 * 3 * 4 * 3 * 5 * 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14520d2-43b8-43de-91d3-c440a35c03b6",
   "metadata": {},
   "source": [
    "且在n_jobs=15的情况下，本次搜索任务总耗时226.5s，约4分钟："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1b7e978-6c43-4ee5-8adc-c1d220568128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.7758962750434875"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "226.55377650260925 / 60"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555ffe76-bdd4-426d-a2ed-75f59611ecd0",
   "metadata": {},
   "source": [
    "约0.035s完成一组超参数的计算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "6f7300a0-22b4-450e-b765-8ae104b1a8ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.034962002546698956"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "226.55377650260925 / 6480"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ccd954f-d63e-4cf0-a932-42e7cf3aab47",
   "metadata": {},
   "source": [
    "> 需要注意的是，这里的运行时间只能作为参考，并不是一个绝对的运行时间。在很多情况下，小段代码的运行时间会受到很多因素影响，包括硬件条件（对于机器学习来说主要是CPU和内存）、是否是首次运行代码等，都会对代码运行时间有较大影响。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c0fddf-f0a1-4c0c-b560-ef01e1088569",
   "metadata": {},
   "source": [
    "- 查看运行结果"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93190e4-f4fb-4bed-9554-bfa038e58732",
   "metadata": {},
   "source": [
    "&emsp;&emsp;然后查看当前情况下模型预测结果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2f535817-ce91-4ab2-b7c6-170afa5bfa06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8084053639517215"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_RF_0.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "22764fc3-5880-4468-9437-3182ed387dd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8517606967057932, 0.7847813742191937)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_RF_0.score(X_train_OE, y_train), grid_RF_0.score(X_test_OE, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fc0b27-142d-42f5-9ef1-335dfed43b80",
   "metadata": {},
   "source": [
    "能够看出，在进行第一轮超参数搜索时，模型结果的过拟合倾向已经得到了有效抑制，并且对比此前逻辑回归最终的优化结果，目前模型已经得到了一个较好的结果了："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c91a7b0-8e67-44cf-bec0-feea86e286fb",
   "metadata": {},
   "source": [
    "|Models|CV.best_score_|train_score|test_score|\n",
    "|:--:|:--:|:--:|:--:|\n",
    "|Logistic+grid|0.8045|0.8055|0.7932|\n",
    "|RF+grid_R1|0.8084|0.8517|0.7848|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e754fe1-5969-49c3-accb-e716c2e0f70f",
   "metadata": {},
   "source": [
    "&emsp;&emsp;最后，重点关注本轮搜索得出的超参数最优取值："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "98ae4385-365e-4e7c-827b-5e62072dca1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 10,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': 0.4,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 7,\n",
       " 'n_estimators': 80}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_RF_0.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c34917-c57a-4821-91a3-ac633c0a1080",
   "metadata": {},
   "source": [
    "并据此设置下一轮搜索策略："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4e6c13-2659-452e-9cbb-93ced4088425",
   "metadata": {},
   "source": [
    "- max_depth本轮最优取值为10，而原定搜索空间为[5, 10, 15]，因此第二轮搜索时就可以以10为中心，缩小步长，进行更精准的搜索；\n",
    "- max_features本轮最优取值为sqrt，说明最优解极有可能在4附近，因此第二轮搜索时可以设置一组更加精准的在4附近的数值，搭配sqrt参数一起进行搜索；\n",
    "- max_leaf_nodes本轮最优取值为None，则有可能说明上一轮给出的其他备选数值不够激进，下一轮搜索时可以在一个更大的区间范围内设置备选数值；\n",
    "- max_samples本轮最优取值为0.4，下一轮可以以0.4为中心，设置一组跨度更小、精度更高的取值进行搜索；\n",
    "- min_samples_leaf本轮最优取值为1，下一轮可以设置range(1, 4)进行搜索（参数不能取得比1更小的值）；\n",
    "- min_samples_split本轮最优取值为7，下一轮可以以7为中心，设置更小的范围进行搜索；\n",
    "- n_estimators本轮最优取值为80，下一轮可以以80为中心，设置更小的范围进行搜索，但需要注意的是，上一轮n_estimators取值搜索的跨度为70，下轮搜索时可以缩减到10。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f68f90-c4d0-43a1-a3b8-603564fd2c66",
   "metadata": {},
   "source": [
    "### 2.第二轮搜索"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560c02a1-8468-4407-a1c2-dd79fffe1cd2",
   "metadata": {},
   "source": [
    "&emsp;&emsp;根据调整策略，重新设置超参数空间，开始第二轮搜索："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7b8b963b-d4ab-4907-af56-98a4d267cb1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235.17643809318542\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# 设置超参数空间\n",
    "parameter_space = {\n",
    "    \"min_samples_leaf\": range(1, 4), \n",
    "    \"min_samples_split\": range(6, 9),\n",
    "    \"max_depth\": range(9, 12),\n",
    "    \"max_leaf_nodes\": [None] + list(range(10, 100, 30)), \n",
    "    \"n_estimators\": range(70, 100, 10), \n",
    "    \"max_features\":['sqrt'] + list(range(2, 5)), \n",
    "    \"max_samples\":[None, 0.35, 0.4, 0.45]}\n",
    "\n",
    "# 实例化模型与评估器\n",
    "RF_0 = RandomForestClassifier(random_state=12)\n",
    "grid_RF_0 = GridSearchCV(RF_0, parameter_space, n_jobs=15)\n",
    "\n",
    "# 模型训练\n",
    "grid_RF_0.fit(X_train_OE, y_train)\n",
    "\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d7e757-0e42-441e-b1c0-a4ee48aaf5a9",
   "metadata": {},
   "source": [
    "#### 2.1 计算运行时间与参数空间"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b88bbd-6512-41e1-ae65-ed5459339c72",
   "metadata": {},
   "source": [
    "&emsp;&emsp;第二轮搜索时对参数空间范围控制的仍然很好，整体来看每个参数的数值设置都在一个比较范围内，最终计算了5184组参数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "92d987f3-ae82-4641-9097-ae7eb477d43c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5184"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3 * 3 * 3 * 4 * 3 * 4 * 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c5371c-2228-4182-a623-9c90073a9de0",
   "metadata": {},
   "source": [
    "实际运行时间仍然为4分钟："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e3b562af-0fa6-4702-b84f-db7763b02a45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.9196073015530906"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "235.17643809318542/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "467fdc04-0fb1-4238-9d41-cf2be7e76dfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.045365825249457065"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "235.17643809318542 / 5184"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d36b9eb-6145-4070-ba30-90d7303c97bb",
   "metadata": {},
   "source": [
    "约0.05s完成一组超参数搜索。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1107864e-7d2e-465d-b2ed-c6961cda0ee0",
   "metadata": {},
   "source": [
    "#### 2.2 查看运行结果"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c93fbfe-1276-4b0c-a9bf-05ed2ed7b176",
   "metadata": {},
   "source": [
    "&emsp;&emsp;接下来查看模型运行结果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "268e00fa-8103-410c-8560-81243d264fba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.808785226914366"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_RF_0.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "371e9eaa-6300-4f1f-89e1-00e316ce0dd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8458917076864824, 0.7921635434412265)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_RF_0.score(X_train_OE, y_train), grid_RF_0.score(X_test_OE, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f75bc52-6c34-434a-86c9-b96fed62d07c",
   "metadata": {},
   "source": [
    "|Models|CV.best_score_|train_score|test_score|\n",
    "|:--:|:--:|:--:|:--:|\n",
    "|Logistic+grid|0.8045|0.8055|0.7932|\n",
    "|RF+grid_R1|0.8084|0.8517|0.7848|\n",
    "|RF+grid_R2|0.8088|0.8459|0.7922|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e8c4f9-c382-4a6a-aee1-cabda542340b",
   "metadata": {},
   "source": [
    "经过第二轮搜索，模型评分（CV_score）进一步提高，并且训练集评分略有下降、但测试集评分有所提升，也说明模型泛化能力也得到了提高。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffe5b01-e5aa-4bc0-b0c2-a7d70e1454bd",
   "metadata": {},
   "source": [
    "&emsp;&emsp;接下来进一步查看本轮搜索的到的最有超参数组："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8269a28e-0e62-4e1d-b72c-8e5834eb2c09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 11,\n",
       " 'max_features': 2,\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': 0.4,\n",
       " 'min_samples_leaf': 2,\n",
       " 'min_samples_split': 7,\n",
       " 'n_estimators': 90}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_RF_0.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abeb5da-1b97-4c42-8be3-5a44a4220698",
   "metadata": {},
   "source": [
    "据此可以设置下一轮搜索策略："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db55615-aba1-48c6-a7fb-e8cda57598d1",
   "metadata": {},
   "source": [
    "- max_depth本轮最优取值为11，在原定搜索空间上界，下次搜索可以进一步向上拓展搜索空间；\n",
    "- max_features本轮最优取值为2，是原定搜索空间的下界，下次搜索可向下拓展搜索空间，也就是将1带入进行搜索。但需要注意的是，sqrt作为非数值型结果，仍然需要带入进行搜索，这轮被淘汰并不代表重新调整搜索空间后仍然被淘汰；\n",
    "- max_leaf_nodes本轮最优取值仍然为None，说明在一个更大的范围内进行更激进的搜索并没有达到预想的效果，下一轮可以反其道而行之，设置一个上一轮没有搜索到的数值较小的空间（1-20），来进行更加精准的搜索；\n",
    "- max_samples本轮最优取值仍然为0.4，基本可以确定最优取值就在0.4附近，下一轮可以进一步设置一个步长更小的区间进行搜索；\n",
    "- min_samples_leaf本轮最优取值为2，恰好落在本轮搜索空间的中间，下一轮搜索时不用调整取值；\n",
    "- min_samples_split本轮最优取值仍然为7，恰好落在本轮搜索空间的中间，下一轮搜索时不用调整取值；\n",
    "- n_estimators本轮最优取值为90，下一轮可以以90为中心，设置更小的范围进行搜索，但需要注意的是，上一轮n_estimators取值搜索的跨度为10，下轮搜索时可以缩减到4。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fb683f-8c80-494a-86a1-8d3598031e72",
   "metadata": {},
   "source": [
    "### 3.第三轮搜索"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6143866b-e97e-443f-af94-f54bea194abe",
   "metadata": {},
   "source": [
    "&emsp;&emsp;根据调整策略，开始第三轮搜索："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a63e5abf-2b6e-483f-b6fa-a82153aff50e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1268.0402607917786\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# 设置超参数空间\n",
    "parameter_space = {\n",
    "    \"min_samples_leaf\": range(1, 4), \n",
    "    \"min_samples_split\": range(6, 9),\n",
    "    \"max_depth\": range(10, 15),\n",
    "    \"max_leaf_nodes\": [None] + list(range(1, 20, 2)), \n",
    "    \"n_estimators\": range(85, 100, 4), \n",
    "    \"max_features\":['sqrt'] + list(range(1, 4)), \n",
    "    \"max_samples\":[None, 0.38, 0.4, 0.42]}\n",
    "\n",
    "# 实例化模型与评估器\n",
    "RF_0 = RandomForestClassifier(random_state=12)\n",
    "grid_RF_0 = GridSearchCV(RF_0, parameter_space, n_jobs=15)\n",
    "\n",
    "# 模型训练\n",
    "grid_RF_0.fit(X_train_OE, y_train)\n",
    "\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394bbd23-f085-4b10-8a43-580a9d10c67a",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 3.1 计算运行时间与参数空间"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff3c106-c46d-4faa-87bf-108cef116368",
   "metadata": {},
   "source": [
    "&emsp;&emsp;由于经过了两轮搜索，执行第三轮时预判即将能够搜网得到最优取值（实际并没有），因此设置了一个相比之前更大的超参数搜索空间："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "be0012b2-e6f6-4535-b7f3-f4b87cbb49e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25344"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3 * 3 * 4 * 11 * 4 * 4 * 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e701fb-fc33-43a8-86e8-a371cc4a38d1",
   "metadata": {},
   "source": [
    "在参数设置时，只在max_leaf_nodes参数部分增加设置了4个备选搜索取值，但参数空间就扩大成了第二轮搜索的参数空间的5倍，而本轮搜索耗时也差不多是第二轮计算用时的5倍："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9577616d-bb9e-4fde-9652-7b08e4e810ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.134004346529643"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1268.0402607917786/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "04542d70-e125-47c8-91aa-f10875f714d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05003315422947359"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1268.0402607917786 / 25344"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0b16e6-f204-4a45-a488-a15439fc91cb",
   "metadata": {},
   "source": [
    "约0.05s完成一组超参数搜索。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78b56cf-e42a-4541-a046-415e8c76057c",
   "metadata": {},
   "source": [
    "#### 3.2 查看运行结果"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a396467a-0cfa-412d-839b-f3f976177ccd",
   "metadata": {},
   "source": [
    "&emsp;&emsp;接下来查看模型运行结果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e33eeecc-1de6-4838-9b34-e4a926e83045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8087841518305094"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_RF_0.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f8b6a648-1263-40cb-8414-99e298387750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8415372964786065, 0.7927314026121521)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_RF_0.score(X_train_OE, y_train), grid_RF_0.score(X_test_OE, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f277da9-a54f-4a49-a1fd-e584b946d935",
   "metadata": {},
   "source": [
    "|Models|CV.best_score_|train_score|test_score|\n",
    "|:--:|:--:|:--:|:--:|\n",
    "|Logistic+grid|0.8045|0.8055|0.7932|\n",
    "|RF+grid_R1|0.8084|0.8517|0.7848|\n",
    "|RF+grid_R2|0.808785|0.8459|0.7922|\n",
    "|RF+grid_R3|0.808784|0.8415|0.7927|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce4e705-93bc-4630-95a9-aaee144c1563",
   "metadata": {},
   "source": [
    "&emsp;&emsp;能够发现，第三轮搜索的结果相比第二轮，模型整体效果其实是略微下降的（根据CV.best_score_），这其实也是在超参数搜索过程是中经常会遇到的问题，也就是多轮搜索过程中模型评分可能出现波动的问题。不过不要气馁，继续观察本轮输出的最优超参数组，继续调参。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "58c7e4f3-5e85-4cea-875a-5df4ca7c90c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 10,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': 0.38,\n",
       " 'min_samples_leaf': 3,\n",
       " 'min_samples_split': 7,\n",
       " 'n_estimators': 97}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_RF_0.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190cf7cd-0d3e-4164-bcae-1c6f96b6528c",
   "metadata": {},
   "source": [
    "- max_depth本轮最优取值为10，在原定搜索空间下界，下次搜索可以进一步向下拓展搜索空间，当然，根据第二轮第三轮max_depth在9和10反复变动的现象，估计max_depth最终的最优取值也就是9、10左右；\n",
    "- max_features本轮最优取值又回到了sqrt，也就是4附近，结合第一轮sqrt的最优结果，预计max_features最终最优取值也就在4附近，接下来的搜索将是收尾阶段，我们可以设计一个sqrt+log2+4附近的搜索组合；\n",
    "- max_leaf_nodes本轮最优取值仍然为None，三轮搜索都没有改变max_leaf_nodes的最优取值，并且本轮还设置了非常多的备选取值，说明max_leaf_nodes的最优取值极有可能就是None，接下来我们只需保留None+大范围搜索的组合即可，以防其他参数变动时max_leaf_nodes的最优取值发生变化；\n",
    "- max_samples本轮最优取值变成了0.38，而训练集总样本数为5282，5282\\*0.38约为2007，下轮开始我们将把比例转化为具体的样本数，进行更加精准的搜索，及围绕2007附近的数值空间进行搜索；\n",
    "- min_samples_leaf本轮最优取值为3，恰好落在本轮搜索空间的上届，下一轮搜索时略微拓展搜索空间的上界；\n",
    "- min_samples_split本轮最优取值仍然为7，恰好落在本轮搜索空间的中间，下一轮搜索时不用调整取值；\n",
    "- n_estimators本轮最优取值为97，下一轮可以以97为中心，设置更小的范围进行搜索；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "893f7cea-122f-40a5-8f6c-61e276fd807c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5282"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_OE.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fba9d3a2-8b30-40b1-baff-5d535d979f34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2007.16"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_OE.shape[0] * 0.38"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bdf1d0-073d-4564-85c4-7c58048c0524",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4.第四轮搜索"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f7f796-aaac-41ef-908d-e0e6d02f8632",
   "metadata": {},
   "source": [
    "&emsp;&emsp;继续进行第四轮搜索："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f5b96cfc-0e74-4d95-930e-0c57d30a23d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1218.2634932994843\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# 设置超参数空间\n",
    "parameter_space = {\n",
    "    \"min_samples_leaf\": range(2, 5), \n",
    "    \"min_samples_split\": range(6, 9),\n",
    "    \"max_depth\": range(8, 12),\n",
    "    \"max_leaf_nodes\": [None] + list(range(10, 70, 20)), \n",
    "    \"n_estimators\": range(95, 105, 2), \n",
    "    \"max_features\":['sqrt', 'log2'] + list(range(1, 6, 2)), \n",
    "    \"max_samples\":[None] + list(range(2002, 2011, 2))}\n",
    "\n",
    "# 实例化模型与评估器\n",
    "RF_0 = RandomForestClassifier(random_state=12)\n",
    "grid_RF_0 = GridSearchCV(RF_0, parameter_space, n_jobs=15)\n",
    "\n",
    "# 模型训练\n",
    "grid_RF_0.fit(X_train_OE, y_train)\n",
    "\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacd45dd-9587-4617-9e4b-6317753f6f54",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 4.1 计算运行时间与参数空间"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d883ee96-99b7-4799-b85e-ed3dd0940566",
   "metadata": {},
   "source": [
    "&emsp;&emsp;由于很多参数都基本能确定最优值的范围，因此本轮搜索时很多参数都略微放大的参数取值范围，这也导致备选超参数组的数量急剧增加："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d44b8cef-6a52-42ce-a7eb-52bd96b7e232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21600"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3 * 3 * 4 * 5 * 4 * 5 * 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c26791b-01f4-4bb8-ad5c-fd4cf45ac10b",
   "metadata": {},
   "source": [
    "最终计算时长和第三轮搜索时的计算时长接近。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "64ddc31e-6b02-4322-8a9e-c50109f94d96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.304391554991405"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1218.2634932994843 / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "7503c64f-78e9-47dd-829a-fd09fad7a228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0564010876527539"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1218.2634932994843 / 21600"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3028a123-74d7-486b-83e3-ee34c2ace356",
   "metadata": {},
   "source": [
    "约0.06s执行完一组超参数搜索。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5106e27d-c89b-48ac-9a86-6935a4c5dc5d",
   "metadata": {},
   "source": [
    "#### 4.2 查看运行结果"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908ac083-1022-4a85-8d4f-e87be78ea0ff",
   "metadata": {},
   "source": [
    "&emsp;&emsp;接下来查看模型运行结果："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97aec691-36d5-49ba-80c0-18e86ee711b4",
   "metadata": {},
   "source": [
    "&emsp;&emsp;第相比第三轮搜索，第四轮的搜索结果有显著提高："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6f5718b3-5d8d-4a06-83c9-5c0fda8a81c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8095422651300135"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_RF_0.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6ba39c09-f19b-492b-8fa3-20cb3b589784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8405906853464596, 0.7881885292447472)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_RF_0.score(X_train_OE, y_train), grid_RF_0.score(X_test_OE, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22459fec-c322-4ea7-9e8c-5856c078b12d",
   "metadata": {},
   "source": [
    "|Models|CV.best_score_|train_score|test_score|\n",
    "|:--:|:--:|:--:|:--:|\n",
    "|Logistic+grid|0.8045|0.8055|0.7932|\n",
    "|RF+grid_R1|0.8084|0.8517|0.7848|\n",
    "|RF+grid_R2|0.808785|0.8459|0.7922|\n",
    "|RF+grid_R3|0.808784|0.8415|0.7927|\n",
    "|RF+grid_R4|0.809542|0.8406|0.7882|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ef150b-9e50-4470-93b6-a7b1ff8d13e8",
   "metadata": {},
   "source": [
    "接下来我们查看本轮输出的最优参数组，并制定后续搜索策略："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "240318e8-2d10-4b2b-b2ff-ef674e08b261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 9,\n",
       " 'max_features': 5,\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': 2002,\n",
       " 'min_samples_leaf': 3,\n",
       " 'min_samples_split': 8,\n",
       " 'n_estimators': 99}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_RF_0.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e0bff6-e04d-4141-8533-234e9af211a5",
   "metadata": {},
   "source": [
    "- max_depth本轮最优取值为9，能够进一步肯定max_depth最终的最优取值也就是9、10左右；\n",
    "- max_features本轮最优取值变成了5，仍然在4附近变化，后续继续保留sqrt+log2+4附近的搜索组合；\n",
    "- max_leaf_nodes本轮最优取值仍然为None，并没有发生任何变化，后续仍然保留原定搜索范围；\n",
    "- max_samples本轮最优取值为2002，这是第一次围绕max_samples进行整数搜索，接下来可以以2002为中心，设置一个更小搜索空间；\n",
    "- min_samples_leaf本轮最优取值为3，恰好落在本轮搜索空间的上届，下一轮搜索时略微拓展搜索空间的上界；\n",
    "- min_samples_split本轮最优取值变成了8，根据之前的搜索结果，该参数最优取值基本都在7和8之间变动，因此可以设置一个6-9的搜索空间，确保下次如果再出现参数在7、8之间变动时，仍然在搜索范围内；\n",
    "- n_estimators本轮最优取值为99，结合之前搜索出来的97的结果，预计该参数最终的最优取值应该就是97-99之间，可以据此设置下一轮搜索空间；"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79704b81-8537-428f-89bd-44f17ede78d0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 5.第五轮搜索"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94436bc-74be-4ef8-868f-2fffb97a04ec",
   "metadata": {},
   "source": [
    "&emsp;&emsp;接下来，继续进行第五轮搜索。经过了前几轮搜索，大多数参数都已经能确定最优解的大概取值范围，因此第五轮搜索时可以将我们判断的可能的最优解全部包括在内，进行大规模搜索，当然，为了不至于搜索时间过长，我们可以适当删除部分我们判断不会出现最优解的取值范围："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "03295909-4149-495f-970a-51db921fc768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "604.7498576641083\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# \"min_samples_leaf\"：以3为中心\n",
    "# \"min_samples_split\"：重点搜索7、8两个值\n",
    "# \"max_depth\"：重点搜索9、10两个值\n",
    "# \"max_leaf_nodes\"：大概率为None\n",
    "# \"n_estimators\": 重点搜索97、98、99三个值\n",
    "# \"max_features\":5附近的值+['sqrt', 'log2']\n",
    "# \"max_samples\":2002向下搜索，重点搜索2002、2001和2000三个值\n",
    "\n",
    "# 设置超参数空间\n",
    "parameter_space = {\n",
    "    \"min_samples_leaf\": range(2, 5), \n",
    "    \"min_samples_split\": range(6, 10),\n",
    "    \"max_depth\": range(8, 12),\n",
    "    \"max_leaf_nodes\": [None], \n",
    "    \"n_estimators\": range(96, 101), \n",
    "    \"max_features\":['sqrt', 'log2'] + list(range(3, 7)), \n",
    "    \"max_samples\":[None] + list(range(2000, 2005))}\n",
    "\n",
    "# 实例化模型与评估器\n",
    "RF_0 = RandomForestClassifier(random_state=12)\n",
    "grid_RF_0 = GridSearchCV(RF_0, parameter_space, n_jobs=15)\n",
    "\n",
    "# 模型训练\n",
    "grid_RF_0.fit(X_train_OE, y_train)\n",
    "\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f511afb8-8c78-4351-ac11-d582ba0f22f3",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 5.1 计算运行时间与参数空间"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de6b0f7-67cc-47a0-abf2-41ef376925f1",
   "metadata": {},
   "source": [
    "&emsp;&emsp;这一轮中我们删除了max_leaf_nodes参数的数值取值，极大程度缩减了参数空间："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e77eb2ba-2607-4c8c-871d-8eb0b20c97d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8640"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3 * 4 * 4 * 1 * 5 * 6 * 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "37d70e6f-3855-45e5-9ffb-ef3e1ff854e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06999419648890141"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "604.7498576641083 / 8640"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f27d4c8-ee46-4b7c-b171-2d2c47b681ae",
   "metadata": {},
   "source": [
    "因此最终计算用时控制在10分钟左右，平均0.07s执行一组超参数的计算。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6415e2bb-d344-4eea-bffa-e63384bf2043",
   "metadata": {},
   "source": [
    "#### 5.2 查看运行结果"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89e76ba-66cd-4878-94dc-796445b9e6d8",
   "metadata": {},
   "source": [
    "&emsp;&emsp;接下来查看模型运行结果，相比第四轮搜索，第五轮的搜索结果继续提升："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "91bb6aa7-b90e-4973-9fdb-28fdbca25ec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8104878013818411"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_RF_0.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3f45512b-2b30-4a76-bb03-33ecdf353406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8483528966300644, 0.7955706984667802)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_RF_0.score(X_train_OE, y_train), grid_RF_0.score(X_test_OE, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d63031-2434-49cf-99f4-39eebec40224",
   "metadata": {},
   "source": [
    "|Models|CV.best_score_|train_score|test_score|\n",
    "|:--:|:--:|:--:|:--:|\n",
    "|Logistic+grid|0.8045|0.8055|0.7932|\n",
    "|RF+grid_R1|0.8084|0.8517|0.7848|\n",
    "|RF+grid_R2|0.808785|0.8459|0.7922|\n",
    "|RF+grid_R3|0.808784|0.8415|0.7927|\n",
    "|RF+grid_R4|0.809542|0.8406|0.7882|\n",
    "|RF+grid_R5|0.810488|0.8483|0.7955|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3daf3760-0fa3-4305-bb0f-edc9cd9c0aff",
   "metadata": {},
   "source": [
    "该结果也是目前的最好结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0174ce-76a8-427a-9e65-49d3bebdcce3",
   "metadata": {},
   "source": [
    "&emsp;&emsp;接下来继续查看超参数搜索结果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c4278f55-0f45-4a18-a83e-f05a36a9d43e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 10,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': 2000,\n",
       " 'min_samples_leaf': 2,\n",
       " 'min_samples_split': 7,\n",
       " 'n_estimators': 97}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_RF_0.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01be6fd-c2b4-4367-a9f3-f9aa3356708e",
   "metadata": {},
   "source": [
    "&emsp;&emsp;能够看出，除了min_samples_leaf和max_samples各自取到了搜索范围下界外，其他参数的最优取值都在设置的取值范围中间。据此我们可以判断搜索任务即将结束，下一轮搜索极有可能是最后一轮搜索，为此我们可以制定下一轮搜索策略：除了刚才的两个参数需要调整取值范围外，其他参数可以以本次搜索结果为中心设置更大的取值范围，最好能包括最近三轮各参数的最优值点，同时max_leaf_nodes恢复之前的大范围数值搜索范围，这么做必然会导致参数空间变得非常大，但为了确保最终结果具有较高的可信度，最后一轮搜索建议放大范围，具体原因稍后解释。这里我们可以简单回顾最近三轮搜索时各参数的最优值点："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8d7c62-17d3-444c-a0a7-5b8ee8a82b6b",
   "metadata": {},
   "source": [
    "|leaf|split|depth|nodes|estimators|features|samples|\n",
    "|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n",
    "|3|7|10|None|97|sqrt|0.38|\n",
    "|3|8|9|None|99|5|2002|\n",
    "|2|7|10|None|97|sqrt|2000|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758262d2-1dbc-46f1-8349-dba42e6b5dce",
   "metadata": {},
   "source": [
    "据此，我们可以设置最后一轮搜索超参数空间如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a80da984-f2f1-48be-b81a-8ac34eff23de",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_space = {\n",
    "    \"min_samples_leaf\": range(1, 5), \n",
    "    \"min_samples_split\": range(6, 10),\n",
    "    \"max_depth\": range(8, 12),\n",
    "    \"max_leaf_nodes\": [None] + list(range(10, 70, 20)), \n",
    "    \"n_estimators\": range(96, 101), \n",
    "    \"max_features\":['sqrt', 'log2'] + list(range(1, 7)),\n",
    "    \"max_samples\":[None] + list(range(1999, 2004))}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0d7555-d481-4e74-9e89-c268cb7de75a",
   "metadata": {},
   "source": [
    "如此一来，最后一轮搜索的参数空间备选参数组数量如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6c405473-8f95-47b7-85c2-364f709c09b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61440"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4 * 4 * 4 * 4 * 5 * 8 * 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3199870-834b-4580-b3e9-be60437addbe",
   "metadata": {},
   "source": [
    "而根据此前测算的平均计算时间，约0.06s完成一组超参数的计算，因此在总共有61440组超参数的情况下，最终估计计算时间为："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ab8baecd-54c7-40f3-a6d8-0e6d38ec21e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3686.3999999999996"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "61440 * 0.06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "51dae692-3eb9-497c-bad7-37eaea359c1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61.43999999999999"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "61440 * 0.06 / 60"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64159e76-ccc7-4296-b068-6c644ab79491",
   "metadata": {},
   "source": [
    "约一小时。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f01993-f0ba-4a96-9226-a2b9a3a2537f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 6.第六轮搜索"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d3773d-d503-40d2-a73e-8c9c78cb1d8f",
   "metadata": {},
   "source": [
    "&emsp;&emsp;接下来执行第六轮搜索："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e92ec39a-2c9c-4089-9f9b-b85870a48ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3601.6263830661774\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# 设置超参数空间\n",
    "parameter_space = {\n",
    "    \"min_samples_leaf\": range(1, 5), \n",
    "    \"min_samples_split\": range(6, 10),\n",
    "    \"max_depth\": range(8, 12),\n",
    "    \"max_leaf_nodes\": [None] + list(range(10, 70, 20)), \n",
    "    \"n_estimators\": range(96, 101), \n",
    "    \"max_features\":['sqrt', 'log2'] + list(range(1, 7)),\n",
    "    \"max_samples\":[None] + list(range(1999, 2004))}\n",
    "\n",
    "# 实例化模型与评估器\n",
    "RF_0 = RandomForestClassifier(random_state=12)\n",
    "grid_RF_0 = GridSearchCV(RF_0, parameter_space, n_jobs=15)\n",
    "\n",
    "# 模型训练\n",
    "grid_RF_0.fit(X_train_OE, y_train)\n",
    "\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9f9ddc-7d38-46ee-a0f3-ddf2c8a1ecaa",
   "metadata": {},
   "source": [
    "最终计算时间和此前预估相差不大，差不多1小时完成计算。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b834057-2cba-4164-9f9b-0e9c43504b02",
   "metadata": {},
   "source": [
    "- 查看运行结果"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c4a229-01fd-43a4-b725-d4eec345b645",
   "metadata": {},
   "source": [
    "&emsp;&emsp;接下来查看模型运行结果，能够发现，在修改了超参数搜索空间后，最终仍然输出了第五次搜索最终输出的结果。尽管没有模型效果上的提升，但两次重复的结果也让我们更加肯定当前输出的超参数组就是最优超参数组。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "525791a2-1d02-4386-8a53-411a2be0ee48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8104878013818411"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_RF_0.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "0490c79e-a958-4de2-a926-271d98d85068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8483528966300644, 0.7955706984667802)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_RF_0.score(X_train_OE, y_train), grid_RF_0.score(X_test_OE, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "131b9de1-c0c4-4876-bf31-ddd5a01a16dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 10,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': 2000,\n",
       " 'min_samples_leaf': 2,\n",
       " 'min_samples_split': 7,\n",
       " 'n_estimators': 97}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_RF_0.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0f5912-c241-4e06-b495-c4ec39ffa86c",
   "metadata": {},
   "source": [
    "|Models|CV.best_score_|train_score|test_score|\n",
    "|:--:|:--:|:--:|:--:|\n",
    "|Logistic+grid|0.8045|0.8055|0.7932|\n",
    "|RF+grid_R1|0.8084|0.8517|0.7848|\n",
    "|RF+grid_R2|0.808785|0.8459|0.7922|\n",
    "|RF+grid_R3|0.808784|0.8415|0.7927|\n",
    "|RF+grid_R4|0.809542|0.8406|0.7882|\n",
    "|RF+grid_R5|0.810488|0.8483|0.7955|\n",
    "|RF+grid_final|0.810488|0.8483|0.7955|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0b656c-dfff-4188-8ca9-051e461ed0c9",
   "metadata": {},
   "source": [
    "最终，在当前建模流程和当前数据集情况下，随机森林能够达到的最好表现就是0.810488。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10b287e-8b44-4c72-978c-5392aa29e973",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 7.最优超参数组的可信度"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfb29ca-1ded-47eb-8a1c-093170f0349f",
   "metadata": {},
   "source": [
    "&emsp;&emsp;通过结果我们不难发现，第六轮搜索的结果和第五轮搜索的结果并没有任何区别，那为何还要进行第六轮搜索？或者说，考虑到第五轮搜索时确实存在部分超参数取到了搜索区间的边界值，那简单拓展搜索边界即可，为何需要加入那么多备选参数、导致计算量激增？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a3fcdc-3ea7-4e1e-9e0c-c254c0c1b25d",
   "metadata": {},
   "source": [
    "&emsp;&emsp;这里就要介绍关于最优超参数组的可信度的问题了。其实从原理上来说，超参数和模型效果之间并没有真正意义上的凸函数关系，如果有这种关系，超参数就不是超参数、而是一般参数了，就可以采用其他更加自动化的优化算法来确定最优值了。因此，哪怕在第五轮的时候我们几乎可以确定超参数的最优取值，但在第六轮搜索时仍然需要扩大参数范围进行验证，就是担心万一超参数取值边界扩大、最优取值发生变化了呢？毕竟我们不能完全相信所谓凸函数的特征。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9db29a-0fd6-44da-a51c-9ea0cacd83da",
   "metadata": {},
   "source": [
    "&emsp;&emsp;事实证明，这种担心也是必要的，我们可以查看如下一组结果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4866289a-c9b3-42e0-ab09-44cbe377afa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8101093718643387"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_RF_0.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2d0d7aea-e78d-4bb8-aa69-54fbc1c4e999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "409.4373540878296\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# 设置超参数空间\n",
    "parameter_space = {\n",
    "    \"min_samples_leaf\": range(1, 4), \n",
    "    \"min_samples_split\": range(6, 8),\n",
    "    \"max_depth\": range(9, 12),\n",
    "    \"max_leaf_nodes\": [None] + list(range(10, 70, 20)), \n",
    "    \"n_estimators\": range(98, 101), \n",
    "    \"max_features\":['sqrt', 'log2'] + list(range(1, 7)), \n",
    "    \"max_samples\":[None] + list(range(1999, 2002))}\n",
    "\n",
    "# 实例化模型与评估器\n",
    "RF_0 = RandomForestClassifier(random_state=12)\n",
    "grid_RF_0 = GridSearchCV(RF_0, parameter_space, n_jobs=15)\n",
    "\n",
    "# 模型训练\n",
    "grid_RF_0.fit(X_train_OE, y_train)\n",
    "\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9de8af3a-5815-4969-b897-9b822bb2a57c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 10,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': 2000,\n",
       " 'min_samples_leaf': 2,\n",
       " 'min_samples_split': 7,\n",
       " 'n_estimators': 99}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_RF_0.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6bd028e2-0c89-492a-b9ef-583be9f11c63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8492995077622113, 0.7938671209540034)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_RF_0.score(X_train_OE, y_train), grid_RF_0.score(X_test_OE, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5396bb-6b18-454c-8405-ecbba6a839d0",
   "metadata": {},
   "source": [
    "能够看到，在这次搜索中，确实每个超参数最终取值都落在搜索区间的中间，也似乎满足了我们之前介绍的搜索停止的条件。但是最终输出结果并不如我们上面第六轮搜索得到的结果。对比最终输出的超参数也能看出，其实差距就在n_estimators的取值，n_estimators在[98,99,100]中搜索时，最优取值是99，但如果稍微放宽搜索区间时，如设置为[96, 97, 98, 99, 100]，也就是第六轮搜索时的参数设置，此时网格搜索会判断n_estimators的最优取值为97。这也说明至少n_estimators的取值和模型效果并不是“凸函数”的关系（因为如果是，则模型效果会在n_estimators=97左右两边单调变化，在搜索[98,99,100]时将判断98是最优取值）。但同时，97这个取值也并不陌生，在相对精准的第三轮搜索时就被选为最优超参数取值，因此，为了一定抵消超参数和模型效果之间这种不确定性关系所带来的风险，最后一轮搜索时必须扩大搜索范围，最好是将前几轮精确搜索（不是大步长搜索）得出的结果一起带入进行搜索，以期得到一个相对更加准确的结论。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800ce395-92cc-4012-9534-698d4ae55d1c",
   "metadata": {},
   "source": [
    "&emsp;&emsp;不过尽管如此，我们也不能百分之百确定目前第六轮搜索出来的结果就一定是绝对意义的最优解、就不存在比这组超参数更优的解，但我们仍然建议采用上述流程进行搜索，也是因为这是长期实践经验总结的产物，根据长期实践证明，这样的一套搜索策略能够以非常高的效率得到一个相对来说非常好的结果（大概率是全域最优解），尽管不是100%的最优解，但这其实是我们借助有限的算力去解决无限的未知的一种手段，毕竟超参数空间取值理论上是无限的，枚举不可能穷尽，目前也没有理论可以通过某种公式确定最优解（贝叶斯也只是估计）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5db4d16-26dd-4b9a-84da-178959d344d4",
   "metadata": {},
   "source": [
    "- 借助有限的资源去解决无限的未知，这就是“人”的价值"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b2daaa-806c-4b9d-9d3b-aa8d26903148",
   "metadata": {},
   "source": [
    "&emsp;&emsp;当然，既然讨论到关于“借助有限的算力去解决无限的未知”的问题，我们也可以从这个角度出发，简单探讨关于AutoML的发展方向与当前算法工程师的可能存在的职业发展焦虑的问题。从根本上来说，机器学习模型的超参数看起来是模型的“缺陷”，因为如果没有超参数的话，模型就可以完全自动化训练了，模型确定参数就像$y=x^2$找最小值一样简单，但实际上，机器学习模型的超参数确是解决模型“缺陷”的手段。简单理解，世界上并不存在绝对意义上完美的机器学习模型，影响模型的所有变量并不能够通过一套理论完美求解，因此机器学习模型选择将将所有的不确定性都交给了超参数，才使得参数能够顺利的被求解，这样也才使得其基本原理得以成立。而正式因为这些超参数的优化需要人去解决，算法工程师的工作才变得有价值和有意义——能够帮助模型达到更好的效果（“《自私的模型》”），当然，特征工程也是类似。但是，如果某一天人们创造了某个算法没有超参数、或者超参数求解的问题能够被一套理论或者一套计算流程完美解决，这个过程不需要人工干预，那么算法工程师的工作价值可能就会大打折扣。不过值得庆幸的是，截止目前，并没有这种算法或者相关理论出现，甚至这都不是一个热门的研究方向，因为大多数学者判断，以当前基础科学发展情况来看（主要是基础数学和物理），这些理论突破暂时不可能做到。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a090e0-8018-429d-808b-95794ebe9501",
   "metadata": {},
   "source": [
    "&emsp;&emsp;而新兴的AutoML，听名字好像是全自动化机器学习，但其实并不是完全自动化解决超参数优化的问题，而是将超参数优化问题转化为了另一种更高层次的建模问题，但这个问题仍然需要人来解决，也就是需要算法工程人员去解决，只不过不再是一个个参数进行调节，而是使用一个更加复杂的工具来进行模型整体层面的优化，你可以将AutoML看成是一个更加高级的网格搜索工具，效果更好、理论更加复杂、操作难度更高。不过截至目前，尽管AutoML得到了一定程度的应用，但其基础理论和实践工具仍然有待进一步的突破，才能够成为新的算法工程师们趁手的工具。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06555616-7dc0-42ec-9f86-8c0dbe877eb0",
   "metadata": {},
   "source": [
    "> 所以说替代算法工程师工作的不是某个工具，而是一个没有“超参数”的世界，或者说，当模型不再需要“人”去优化时。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d44f4b-443c-4526-9ae4-5fb387d272e9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 8.其他搜索方案"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a146efcf-0f35-4818-b64f-0d4380c0e62b",
   "metadata": {},
   "source": [
    "&emsp;&emsp;当然，除了网格搜索外，此处也可以考虑先进行大规模随机网格搜索或者对半搜索，锁定的最优参数后再划定范围进行更加精准的网格搜索，也就是所谓的组合搜索策略，不过由于初始搜索出来的最优参数精度不够，外加随机搜索时抽样过程不确定，也会对最终结果造成影响。其实从另一个角度来看，网格搜索前几轮设置的大步长搜索策略，其实也就相当于是随机网格搜索，只不过随机抽样的取值是人工固定的。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628bd335-9d92-4e4a-b891-4a4382b436e7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 三、网格搜索流程总结"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d65c1f-fba9-4ae0-808d-aa0a77401cab",
   "metadata": {},
   "source": [
    "&emsp;&emsp;最后，让我们简单总结上述介绍的网格搜索实战流程，帮助大家从一个更加整体的角度看待网格搜索参数优化的全过程。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb09e54-edc0-4e8a-a948-fa748f943753",
   "metadata": {},
   "source": [
    "<center><img src=\"https://s2.loli.net/2022/05/04/ehx8SqawpXMU1Co.png\" alt=\"image-20220504171546863\" style=\"zoom:50%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1146aee8-26b6-4ff8-9260-df94427c41d9",
   "metadata": {},
   "source": [
    "&emsp;&emsp;至此，我们就完成了随机森林+网格搜索在当前数据集上的全部训练与优化工作，并借此完整详细的介绍了网格搜索这一优化器的具体实战操作技巧。当然，要做到活学活用，还需要在日后更多的实践中不断积累经验，需要注意的是，后续课程中在进行网格搜索调优时，只会展示最后一轮的搜索结果，但实际搜索流程和本节介绍的一致，也希望同学课后多加练习，甚至提炼和总结自己的调优流程。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b008abd7-c58d-4c4d-aa2e-2b51f3460d5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
