{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a298c96-0922-4da2-9a52-15f611b24459",
   "metadata": {
    "tags": []
   },
   "source": [
    "# <center> 【Kaggle】Telco Customer Churn 电信用户流失预测案例"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37bd0ca-c641-4748-be9c-f86bbf1c0575",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2b4be7-e787-4165-80c3-6c2b5b352f3f",
   "metadata": {},
   "source": [
    "## <font face=\"仿宋\">第四部分导读"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566c1a6e-9660-45a5-8d75-f516565f5ff4",
   "metadata": {},
   "source": [
    "&emsp;&emsp;<font face=\"仿宋\">在案例的第二、三部分中，我们详细介绍了关于特征工程的各项技术，特征工程技术按照大类来分可以分为数据预处理、特征衍生、特征筛选三部分，其中特征预处理的目的是为了将数据集整理、清洗到可以建模的程度，具体技术包括缺失值处理、异常值处理、数据重编码等，是建模之前必须对数据进行的处理和操作；而特征衍生和特征筛选则更像是一类优化手段，能够帮助模型突破当前数据集建模的效果上界。并且我们在第二部分完整详细的介绍机器学习可解释性模型的训练、优化和解释方法，也就是逻辑回归和决策树模型。并且此前我们也一直以这两种算法为主，来进行各个部分的模型测试。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6b41de-3b78-4a43-8596-ee7df9daed2e",
   "metadata": {},
   "source": [
    "&emsp;&emsp;<font face=\"仿宋\">而第四部分，我们将开始介绍集成学习的训练和优化的实战技巧，尽管从可解释性角度来说，集成学习的可解释性并不如逻辑回归和决策树，但在大多数建模场景下，集成学习都将获得一个更好的预测结果，这也是目前效果优先的建模场景下最常使用的算法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65329553-9832-40d6-812f-85eb91bdae26",
   "metadata": {},
   "source": [
    "&emsp;&emsp;<font face=\"仿宋\">总的来说，本部分内容只有一个目标，那就是借助各类优化方法，抵达每个主流集成学习的效果上界。换而言之，本部分我们将围绕单模优化策略展开详细的探讨，涉及到的具体集成学习包括随机森林、XGBoost、LightGBM、和CatBoost等目前最主流的集成学习算法，而具体的优化策略则包括超参数优化器的使用、特征衍生和筛选方法的使用、单模型自融合方法的使用，这些优化方法也是截至目前，提升单模效果最前沿、最有效、同时也是最复杂的方法。其中有很多较为艰深的理论，也有很多是经验之谈，但无论如何，我们希望能够围绕当前数据集，让每个集成学习算法优化到极限。值得注意的是，在这个过程中，我们会将此前介绍的特征衍生和特征筛选视作是一种模型优化方法，衍生和筛选的效果，一律以模型的最终结果来进行评定。而围绕集成学习进行海量特征衍生和筛选，也才是特征衍生和筛选技术能发挥巨大价值的主战场。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7317c9-4ae2-4242-bc79-7765ce46d5df",
   "metadata": {},
   "source": [
    "&emsp;&emsp;<font face=\"仿宋\">而在抵达了单模的极限后，我们就会进入到下一阶段，也就是模型融合阶段。需要知道的是，只有单模的效果到达了极限，进一步的多模型融合、甚至多层融合，才是有意义的，才是有效果的。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4bc863-75b8-4dca-b5e0-79f9ae0c1cb8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1465e4ee-9f15-4a9e-b33b-8030d86639a3",
   "metadata": {},
   "source": [
    "# <center>Part 4.集成算法的训练与优化技巧"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d9c76b6-97e4-49d8-9971-0e49c382468c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 基础数据科学运算库\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 可视化库\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 时间模块\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# sklearn库\n",
    "# 数据预处理\n",
    "from sklearn import preprocessing\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# 实用函数\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 常用评估器\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 网格搜索\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 自定义评估器支持模块\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, ClassifierMixin\n",
    "\n",
    "# 自定义模块\n",
    "from telcoFunc import *\n",
    "# 导入特征衍生模块\n",
    "import features_creation as fc\n",
    "from features_creation import *\n",
    "\n",
    "# re模块相关\n",
    "import inspect, re\n",
    "\n",
    "# 其他模块\n",
    "from tqdm import tqdm\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c759e1c-a2c1-45eb-a26f-10213b31afd4",
   "metadata": {},
   "source": [
    "&emsp;&emsp;然后执行Part 1中的数据清洗相关工作："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23f47ed9-51b5-4011-9f77-d1bc8991c0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "tcc = pd.read_csv('WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
    "\n",
    "# 标注连续/离散字段\n",
    "# 离散字段\n",
    "category_cols = ['gender', 'SeniorCitizen', 'Partner', 'Dependents',\n",
    "                'PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', \n",
    "                'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling',\n",
    "                'PaymentMethod']\n",
    "\n",
    "# 连续字段\n",
    "numeric_cols = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
    " \n",
    "# 标签\n",
    "target = 'Churn'\n",
    "\n",
    "# ID列\n",
    "ID_col = 'customerID'\n",
    "\n",
    "# 验证是否划分能完全\n",
    "assert len(category_cols) + len(numeric_cols) + 2 == tcc.shape[1]\n",
    "\n",
    "# 连续字段转化\n",
    "tcc['TotalCharges']= tcc['TotalCharges'].apply(lambda x: x if x!= ' ' else np.nan).astype(float)\n",
    "tcc['MonthlyCharges'] = tcc['MonthlyCharges'].astype(float)\n",
    "\n",
    "# 缺失值填补\n",
    "tcc['TotalCharges'] = tcc['TotalCharges'].fillna(0)\n",
    "\n",
    "# 标签值手动转化 \n",
    "tcc['Churn'].replace(to_replace='Yes', value=1, inplace=True)\n",
    "tcc['Churn'].replace(to_replace='No',  value=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "455b70b5-8d40-4dbd-a618-f82895b4fcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = tcc.drop(columns=[ID_col, target]).copy()\n",
    "labels = tcc['Churn'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6541c4-0c27-4837-98a5-19f2091eca0f",
   "metadata": {},
   "source": [
    "&emsp;&emsp;同时，创建自然编码后的数据集以及经过时序特征衍生的数据集："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c6d7d55-2762-465a-aa94-b3c608196736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分训练集和测试集\n",
    "train, test = train_test_split(tcc, random_state=22)\n",
    "\n",
    "X_train = train.drop(columns=[ID_col, target]).copy()\n",
    "X_test = test.drop(columns=[ID_col, target]).copy()\n",
    "\n",
    "y_train = train['Churn'].copy()\n",
    "y_test = test['Churn'].copy()\n",
    "\n",
    "X_train_seq = pd.DataFrame()\n",
    "X_test_seq = pd.DataFrame()\n",
    "\n",
    "# 年份衍生\n",
    "X_train_seq['tenure_year'] = ((72 - X_train['tenure']) // 12) + 2014\n",
    "X_test_seq['tenure_year'] = ((72 - X_test['tenure']) // 12) + 2014\n",
    "\n",
    "# 月份衍生\n",
    "X_train_seq['tenure_month'] = (72 - X_train['tenure']) % 12 + 1\n",
    "X_test_seq['tenure_month'] = (72 - X_test['tenure']) % 12 + 1\n",
    "\n",
    "# 季度衍生\n",
    "X_train_seq['tenure_quarter'] = ((X_train_seq['tenure_month']-1) // 3) + 1\n",
    "X_test_seq['tenure_quarter'] = ((X_test_seq['tenure_month']-1) // 3) + 1\n",
    "\n",
    "# 独热编码\n",
    "enc = preprocessing.OneHotEncoder()\n",
    "enc.fit(X_train_seq)\n",
    "\n",
    "seq_new = list(X_train_seq.columns)\n",
    "\n",
    "# 创建带有列名称的独热编码之后的df\n",
    "X_train_seq = pd.DataFrame(enc.transform(X_train_seq).toarray(), \n",
    "                           columns = cate_colName(enc, seq_new, drop=None))\n",
    "\n",
    "X_test_seq = pd.DataFrame(enc.transform(X_test_seq).toarray(), \n",
    "                          columns = cate_colName(enc, seq_new, drop=None))\n",
    "\n",
    "# 调整index\n",
    "X_train_seq.index = X_train.index\n",
    "X_test_seq.index = X_test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0ab1e49-e66e-4192-bf3e-a769682925e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ord_enc = OrdinalEncoder()\n",
    "ord_enc.fit(X_train[category_cols])\n",
    "\n",
    "X_train_OE = pd.DataFrame(ord_enc.transform(X_train[category_cols]), columns=category_cols)\n",
    "X_train_OE.index = X_train.index\n",
    "X_train_OE = pd.concat([X_train_OE, X_train[numeric_cols]], axis=1)\n",
    "\n",
    "X_test_OE = pd.DataFrame(ord_enc.transform(X_test[category_cols]), columns=category_cols)\n",
    "X_test_OE.index = X_test.index\n",
    "X_test_OE = pd.concat([X_test_OE, X_test[numeric_cols]], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab86d7f0-5bc0-48d2-9c31-6bb14138e89b",
   "metadata": {},
   "source": [
    "然后是模型融合部分所需的第三方库、准备的数据以及训练好的模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c92637f-39f4-4fa0-ac6e-e9fab49155d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 本节新增第三方库\n",
    "from joblib import dump, load\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from hyperopt import hp, fmin, tpe\n",
    "from numpy.random import RandomState\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43935025-4d57-414b-a4a0-b005176becd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_search = load('logistic_search.joblib') \n",
    "tree_model = load('tree_model.joblib') \n",
    "RF_0 = load('RF_0.joblib') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9f76bd-e760-46ee-bdb6-f0d7b90a5520",
   "metadata": {},
   "source": [
    "## <center>Ch.3 模型融合基础方法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988f066a-a0b3-4330-a154-2f6ec923e178",
   "metadata": {},
   "source": [
    "## 二、Voting投票法与Averaging平均法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5be6173-3128-4b60-938e-10012de8e5e2",
   "metadata": {},
   "source": [
    "&emsp;&emsp;首先是较为基础的投票法和平均法，熟悉Bagging的大家肯定对这两类方法并不陌生，这类方法简单但同样实用，是模型融合实践过程中必不可少的融合方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c782a2-e270-4ce5-ad46-584b41865371",
   "metadata": {},
   "source": [
    "&emsp;&emsp;首先我们先从这类方法的基础应用开始介绍，然后逐步深入。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8466191-9e2a-474a-856c-e2b829396b24",
   "metadata": {},
   "source": [
    "### 1.基本方法介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5664e9c4-f7d8-426d-b0ed-e2bb812b8c5a",
   "metadata": {},
   "source": [
    "- Voting投票法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e6fccd-07c3-46bd-b009-0535d0cd6021",
   "metadata": {},
   "source": [
    "&emsp;&emsp;首先是相对较为简单的模型融合方法：投票法与平均法。在深入学习了集成算法后，我们对投票法和均值法的计算过程并不陌生，我们可以简单回顾下投票法和平均法的集成过程，首先如果模型最终输出的是类别判别结果，则可以通过投票法进行模型融合，投票法会根据少数服从多数的规则进行结果输出，例如现有A、B、C三个模型对现有数据进行预测，结果如下："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f1db7e-4557-4f5a-861d-01130c91af75",
   "metadata": {},
   "source": [
    "<center><img src=\"https://s2.loli.net/2022/05/20/1JjNFKy8Uo4ftvW.png\" alt=\"image-20220520153024128\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543c4faf-9570-469c-8947-7c0127514ff4",
   "metadata": {},
   "source": [
    "很明显，根据少数如从多数的原则，投票得出三个样本的预测结果分别为1、0、1、0。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96516772-6dbd-4e18-8089-a3b03f692eba",
   "metadata": {},
   "source": [
    "&emsp;&emsp;当然，很多时候为了计算方便，我们会把这个少数服从多数的过程等价转化是否超过半数评估器认为该样本应该属于1类，如果是，则输出结果为1，反之则输出预测结果为0。需要注意的是，该做法会更加方便代码层面的实现，也是后续我们主要采用的计算流程。例如上述简单示例可以修改流程如下："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d7cfd0-cd61-41b9-abd0-7b85186a201f",
   "metadata": {},
   "source": [
    "<center><img src=\"https://s2.loli.net/2022/05/20/qY5UI3gDzSc8p2H.png\" alt=\"image-20220520153651685\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67a6394-aeac-4bd6-ac42-fe1d71627338",
   "metadata": {},
   "source": [
    "&emsp;&emsp;而这样的一个投票集成的过程，到底能带来多少性能上的提升呢？从理论上来说，根据[Narasimhamurthy，2003]研究表明，在多样性构建的比较好的情况下，投票融合性能边界如下："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3946a8e9-122e-43d9-8736-6570c153e668",
   "metadata": {},
   "source": [
    "<center><img src=\"https://s2.loli.net/2022/05/20/uVrzS79LaBsJgKp.png\" alt=\"image-20220520122231347\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491e68ea-de78-419a-8fa5-50c1f8aa15d1",
   "metadata": {},
   "source": [
    "能够看出，在单体分类器准确率为80%左右（较为普遍的情况）时，模型投票融合能有平均约15%的准确率提升。当然，该理论实际上是基于分类器相互独立的假设推导而来，而在大多数真实场景下，该假设并不成立，因此该理论的结论可以视作一个理论上限，并不能代表一般情况。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb9979a-3f89-44f2-bb1a-bd5719541aba",
   "metadata": {},
   "source": [
    "- Averaging平均法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2377d7f0-6db2-4d2f-966e-dc3f370c1214",
   "metadata": {},
   "source": [
    "&emsp;&emsp;而平均法，则是基于连续型预测结果进行融合，例如现在如果是回归类问题，三个模型对三个样本预测结果如下："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b1a4c5-ec80-40a3-a938-45cad586e5e3",
   "metadata": {},
   "source": [
    "<center><img src=\"https://s2.loli.net/2022/05/16/xEtCmoWaV4AS3cj.png\" alt=\"image-20220516172028022\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94618d6a-832f-4092-ba29-2e10aa36f963",
   "metadata": {},
   "source": [
    "则通过三个模型的预测结果进行平均，就能够得到最终模型融合的预测结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4b52e7-ab2c-4c47-83ce-47089c98401d",
   "metadata": {},
   "source": [
    "&emsp;&emsp;平均法的理论则可以通过更为简单的公式推导出来，一般来说，N个相互独立且误差为err的分类器进行简单平均法融合，最终得到的融合结果的误差为$\\frac{1}{T}$。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0a9b97-380c-4621-8403-98d518da1b3c",
   "metadata": {},
   "source": [
    "- 概率均值法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495b3cec-69f9-481a-828a-2a90eee97f45",
   "metadata": {},
   "source": [
    "&emsp;&emsp;不过需要注意的是，平均法并不是只能针对回归问题的预测结果进行平均，对于分类问题，有时候我们也可以对分类问题的概率预测结果进行平均，即计算每个样本不同模型的预测概率平均值，然后根据给定阈值计算该样本最终类别，这种方法也被称作概率均值法，例如在如下预测概率的假设情况下，概率均值法有如下计算过程："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11eda59-e469-4b79-90de-68e6f9064777",
   "metadata": {},
   "source": [
    "<center><img src=\"https://s2.loli.net/2022/05/16/yWYZEbfmRUntxjo.png\" alt=\"image-20220516173712093\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7374899a-68bf-4f2a-8d57-cd0518ba8f8b",
   "metadata": {},
   "source": [
    "这里需要注意，在某些时候，投票法和概率均值法可能得到不同的结果，例如上述样本2，在投票法计算时最终结果为0类，而在概率均值融合时预测结果为1，这其实是由于0类样本概率较高（接近0.5）且1类样本概率趋近于1导致的。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1292862-45e2-4c99-b18f-5958759b9562",
   "metadata": {},
   "source": [
    "&emsp;&emsp;在跟多时候，概率均值法也被称作软投票法Soft Voting，对应的，基于类别的投票法则被称为硬投票法Hard Voting。而从理论角度出发，软投票的性能理论上限与硬投票类似。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49faf219-278e-4362-a8af-c93b8c2d30ba",
   "metadata": {},
   "source": [
    "### 2.基础方法实践"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d88626-b66f-4e02-ac65-03c899211fc2",
   "metadata": {},
   "source": [
    "&emsp;&emsp;接下来开始尝试借助上述模型进行投票法和平均法的实践。相关融合方法可以手动实现也可以借助sklearn中的评估器来实现，我们先尝试手动实现，然后再介绍调用sklearn评估器进行融合的方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503e7d5a-7131-43ae-81c5-6d7c320fbcc9",
   "metadata": {},
   "source": [
    "#### 2.1 手动实现过程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fc8ed6-8430-4075-926f-430dedcd5472",
   "metadata": {},
   "source": [
    "&emsp;&emsp;由于当前数据集是分类问题，因此可以考虑围绕上述三个模型进行投票法融合，或者概率平均法进行融合。当然如果是回归问题，也可以参照这里的概率平均法进行平均法融合操作。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9114dbfa-b306-4e19-81a3-e23ac2119f5c",
   "metadata": {},
   "source": [
    "&emsp;&emsp;首先分别记录三个模型在训练集和测试集上的预测结果与概率预测结果，为了更加清晰的展示相关过程，这里我们先将每个结果单独保存，在大家熟悉了这个过程后，我们可以考虑直接将所有同类结果保存在一个DataFrame中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f0693cc3-fd45-4d10-93b4-6e83c9b163ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 训练集上的预测结果\n",
    "train_prediction1 = logistic_search.best_estimator_.predict(X_train_OE)\n",
    "train_prediction2 = tree_model.predict(X_train_OE)\n",
    "train_prediction3 = RF_0.predict(X_train_OE)\n",
    "\n",
    "# 训练集上的预测概率(预测为1的概率)\n",
    "train_prediction1_proba = logistic_search.best_estimator_.predict_proba(X_train_OE)[:, 1]\n",
    "train_prediction2_proba = tree_model.predict_proba(X_train_OE)[:, 1]\n",
    "train_prediction3_proba = RF_0.predict_proba(X_train_OE)[:, 1]\n",
    "\n",
    "# 测试集上的预测结果\n",
    "test_prediction1 = logistic_search.best_estimator_.predict(X_test_OE)\n",
    "test_prediction2 = tree_model.predict(X_test_OE)\n",
    "test_prediction3 = RF_0.predict(X_test_OE)\n",
    "\n",
    "# 测试集上的预测概率\n",
    "test_prediction1_proba = logistic_search.best_estimator_.predict_proba(X_test_OE)[:, 1]\n",
    "test_prediction2_proba = tree_model.predict_proba(X_test_OE)[:, 1]\n",
    "test_prediction3_proba = RF_0.predict_proba(X_test_OE)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "807ec300-2831-4987-a490-e562fd733ca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99327033, 0.00672967],\n",
       "       [0.48125643, 0.51874357],\n",
       "       [0.89506715, 0.10493285],\n",
       "       ...,\n",
       "       [0.39270528, 0.60729472],\n",
       "       [0.9843395 , 0.0156605 ],\n",
       "       [0.99464364, 0.00535636]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_0.predict_proba(X_train_OE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9295ad24-e67a-4a2e-afbc-f4f345082cee",
   "metadata": {},
   "source": [
    "&emsp;&emsp;然后先尝试投票法（硬投票法）进行融合，首先计算训练集上的投票结果，这里我们可以计算累计票数，也可以计算平均票数，例如累计票数的计算与判别结果如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "abfc07f4-f761-49ed-9b3c-5bb453478e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 大于等于两个评估器预测结果为1，则最终投票结果为1\n",
    "Voting_train_hard = ((train_prediction1 + \n",
    "                      train_prediction2 + \n",
    "                      train_prediction3) >= 2) * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6448adf4-2fba-492b-8c38-6b4f527fa9cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 1, 0, 0])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Voting_train_hard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2c5beef7-0c62-4b32-a4d5-f5ced8f730bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Voting_test_hard = ((test_prediction1 + \n",
    "                     test_prediction2 + \n",
    "                     test_prediction3) >= 2) * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2b7db398-f6a5-4f64-bdde-11f755fbb685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 1, 0])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Voting_test_hard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d06e95e-e09b-423a-9d24-f89af0b6bd6c",
   "metadata": {},
   "source": [
    "然后进一步计算准确率："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fb5114c7-8a32-4bc8-9feb-0c0eb1801299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8345323741007195, 0.7910278250993753)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Voting_train_hard, y_train), accuracy_score(Voting_test_hard, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1104b871-3030-4edb-97b2-076b75202d2e",
   "metadata": {},
   "source": [
    "也可以计算平均得票，即用总票数除以分类器个数（也就是3），结果如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8fc96b3b-e2d0-46f1-b7ce-3919141da99e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8345323741007195, 0.7910278250993753)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 50%及以上的分类器判别为1，则结果为1，反之亦然\n",
    "Voting_train_hard = (((train_prediction1 + \n",
    "                       train_prediction2 + \n",
    "                       train_prediction3) / 3) >= 0.5) * 1\n",
    "\n",
    "Voting_test_hard = (((test_prediction1 + \n",
    "                      test_prediction2 + \n",
    "                      test_prediction3) / 3) >= 0.5) * 1\n",
    "\n",
    "accuracy_score(Voting_train_hard, y_train), accuracy_score(Voting_test_hard, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d843a251-8759-40f4-8059-e3054524b2f7",
   "metadata": {},
   "source": [
    "当然，在当前分类器较为简单的情况下两种结果没有任何区别，不过需要注意的是，在后续加权硬投票的过程中，二者结果会在高精度计算时会有略微差异，这里建议采用后面一种硬投票的计算方式，这也是sklearn中默认的硬投票的计算方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60b1ca3-4872-4f58-b1bd-966d95b89c81",
   "metadata": {},
   "source": [
    "&emsp;&emsp;接下来简单对比单模型输出结果，很明显，简单的硬投票法还有一定的效果提升空间。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7770fa0d-08f7-4be1-a717-eb97cd50c297",
   "metadata": {},
   "source": [
    "|Models|train_score|test_score|\n",
    "|:--:|:--:|:--:|\n",
    "|logistic_search|0.8123|0.7836|\n",
    "|tree_model|0.7991|0.7683|\n",
    "|RF_0|0.8483|0.7955|\n",
    "|Voting_hard|0.8345|0.7910|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3ded4f-5d09-4edf-a6bc-ffec40c8ae7b",
   "metadata": {},
   "source": [
    "&emsp;&emsp;接下来继续考虑进行概率均值（软投票）方法进行融合："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fc63b892-2e00-4f49-a3a2-0121b341dd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "Voting_train_soft = (((train_prediction1_proba + \n",
    "                       train_prediction2_proba + \n",
    "                       train_prediction3_proba) / 3) >= 0.5) * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dd58b015-4c3d-447d-b08d-f84043a0b1d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 1, 0, 0])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Voting_train_soft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "81498e08-6d6e-4cba-a6bb-124b2cc0b66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Voting_test_soft = (((test_prediction1_proba + \n",
    "                      test_prediction2_proba + \n",
    "                      test_prediction3_proba) / 3) >= 0.5) * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8b1953df-81b9-4fc5-8458-4e0525e2ec41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 1, 0])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Voting_test_soft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "69fb14f4-68ac-46ce-b7cc-f334aa042fa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8258235516849678, 0.787052810902896)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Voting_train_soft, y_train), accuracy_score(Voting_test_soft, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4769ae-1ab3-4a25-ac9e-f440ab805ae7",
   "metadata": {},
   "source": [
    "能够发现，概率均值的融合结果不如投票法融合的结果："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8dda37-0605-4f32-bc82-e3b9d8ecec26",
   "metadata": {},
   "source": [
    "|Models|train_score|test_score|\n",
    "|:--:|:--:|:--:|\n",
    "|logistic_search|0.8123|0.7836|\n",
    "|tree_model|0.7991|0.7683|\n",
    "|RF_0|0.8483|0.7955|\n",
    "|Voting_hard|0.8345|0.7910|\n",
    "|Voting_soft|0.8258|0.7870"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0345bcbd-81d6-46da-a6c3-2f4c94299cdc",
   "metadata": {},
   "source": [
    "&emsp;&emsp;不难发现，看似更加死板的加权硬投票法却得到了一个更高的评分。这里需要注意的是，尽管从数值层面来看，软投票的数值表现更丰富——都是高精度浮点数运算，并且配如果可以进一步配合阈值移动或者加权融合，则有较大的调优空间。不过呢，硬投票实际上也有自己的优势，其中最大的优势就在于硬投票的过程实际上自带一个将概率转化为投票的过程，而这个过程实际上是非线性的，即概率小于0.5时输出为0、概率大于0.5时输出为1，而这个非线性的过程就极有可能进一步提升最终融合效果。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172efb29-1866-45bf-9bd0-23775829e6cb",
   "metadata": {},
   "source": [
    "&emsp;&emsp;在了解了手动实现过程之后，接下来考虑借助sklearn实现上述过程。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bc055f-745f-498c-a1e9-f3fb38ad900a",
   "metadata": {},
   "source": [
    "#### 2.2 sklearn实现过程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84100328-4a8f-449b-bb21-1c199a45022b",
   "metadata": {},
   "source": [
    "&emsp;&emsp;在sklearn中，我们可以在ensemble模块内找到投票法评估器。并且根据sklearn的一贯设置，会根据分类问题和回归问题的不同设置不同的评估器，当前问题是分类问题，因此我们需要导入VotingClassifier评估器："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7bfb85ce-b942-4530-9077-a23debeb5716",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "43a993b4-75bf-4c06-84a0-63eb28b8bdb2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m\n",
       "\u001b[0mVotingClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mestimators\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mvoting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'hard'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mflatten_transform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m     \n",
       "Soft Voting/Majority Rule classifier for unfitted estimators.\n",
       "\n",
       "Read more in the :ref:`User Guide <voting_classifier>`.\n",
       "\n",
       ".. versionadded:: 0.17\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "estimators : list of (str, estimator) tuples\n",
       "    Invoking the ``fit`` method on the ``VotingClassifier`` will fit clones\n",
       "    of those original estimators that will be stored in the class attribute\n",
       "    ``self.estimators_``. An estimator can be set to ``'drop'``\n",
       "    using ``set_params``.\n",
       "\n",
       "    .. versionchanged:: 0.21\n",
       "        ``'drop'`` is accepted. Using None was deprecated in 0.22 and\n",
       "        support was removed in 0.24.\n",
       "\n",
       "voting : {'hard', 'soft'}, default='hard'\n",
       "    If 'hard', uses predicted class labels for majority rule voting.\n",
       "    Else if 'soft', predicts the class label based on the argmax of\n",
       "    the sums of the predicted probabilities, which is recommended for\n",
       "    an ensemble of well-calibrated classifiers.\n",
       "\n",
       "weights : array-like of shape (n_classifiers,), default=None\n",
       "    Sequence of weights (`float` or `int`) to weight the occurrences of\n",
       "    predicted class labels (`hard` voting) or class probabilities\n",
       "    before averaging (`soft` voting). Uses uniform weights if `None`.\n",
       "\n",
       "n_jobs : int, default=None\n",
       "    The number of jobs to run in parallel for ``fit``.\n",
       "    ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
       "    ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
       "    for more details.\n",
       "\n",
       "    .. versionadded:: 0.18\n",
       "\n",
       "flatten_transform : bool, default=True\n",
       "    Affects shape of transform output only when voting='soft'\n",
       "    If voting='soft' and flatten_transform=True, transform method returns\n",
       "    matrix with shape (n_samples, n_classifiers * n_classes). If\n",
       "    flatten_transform=False, it returns\n",
       "    (n_classifiers, n_samples, n_classes).\n",
       "\n",
       "verbose : bool, default=False\n",
       "    If True, the time elapsed while fitting will be printed as it\n",
       "    is completed.\n",
       "\n",
       "    .. versionadded:: 0.23\n",
       "\n",
       "Attributes\n",
       "----------\n",
       "estimators_ : list of classifiers\n",
       "    The collection of fitted sub-estimators as defined in ``estimators``\n",
       "    that are not 'drop'.\n",
       "\n",
       "named_estimators_ : :class:`~sklearn.utils.Bunch`\n",
       "    Attribute to access any fitted sub-estimators by name.\n",
       "\n",
       "    .. versionadded:: 0.20\n",
       "\n",
       "le_ : :class:`~sklearn.preprocessing.LabelEncoder`\n",
       "    Transformer used to encode the labels during fit and decode during\n",
       "    prediction.\n",
       "\n",
       "classes_ : ndarray of shape (n_classes,)\n",
       "    The classes labels.\n",
       "\n",
       "n_features_in_ : int\n",
       "    Number of features seen during :term:`fit`. Only defined if the\n",
       "    underlying classifier exposes such an attribute when fit.\n",
       "\n",
       "    .. versionadded:: 0.24\n",
       "\n",
       "feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
       "    Names of features seen during :term:`fit`. Only defined if the\n",
       "    underlying estimators expose such an attribute when fit.\n",
       "    .. versionadded:: 1.0\n",
       "\n",
       "See Also\n",
       "--------\n",
       "VotingRegressor : Prediction voting regressor.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> import numpy as np\n",
       ">>> from sklearn.linear_model import LogisticRegression\n",
       ">>> from sklearn.naive_bayes import GaussianNB\n",
       ">>> from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
       ">>> clf1 = LogisticRegression(multi_class='multinomial', random_state=1)\n",
       ">>> clf2 = RandomForestClassifier(n_estimators=50, random_state=1)\n",
       ">>> clf3 = GaussianNB()\n",
       ">>> X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\n",
       ">>> y = np.array([1, 1, 1, 2, 2, 2])\n",
       ">>> eclf1 = VotingClassifier(estimators=[\n",
       "...         ('lr', clf1), ('rf', clf2), ('gnb', clf3)], voting='hard')\n",
       ">>> eclf1 = eclf1.fit(X, y)\n",
       ">>> print(eclf1.predict(X))\n",
       "[1 1 1 2 2 2]\n",
       ">>> np.array_equal(eclf1.named_estimators_.lr.predict(X),\n",
       "...                eclf1.named_estimators_['lr'].predict(X))\n",
       "True\n",
       ">>> eclf2 = VotingClassifier(estimators=[\n",
       "...         ('lr', clf1), ('rf', clf2), ('gnb', clf3)],\n",
       "...         voting='soft')\n",
       ">>> eclf2 = eclf2.fit(X, y)\n",
       ">>> print(eclf2.predict(X))\n",
       "[1 1 1 2 2 2]\n",
       ">>> eclf3 = VotingClassifier(estimators=[\n",
       "...        ('lr', clf1), ('rf', clf2), ('gnb', clf3)],\n",
       "...        voting='soft', weights=[2,1,1],\n",
       "...        flatten_transform=True)\n",
       ">>> eclf3 = eclf3.fit(X, y)\n",
       ">>> print(eclf3.predict(X))\n",
       "[1 1 1 2 2 2]\n",
       ">>> print(eclf3.transform(X).shape)\n",
       "(6, 6)\n",
       "\u001b[1;31mFile:\u001b[0m           d:\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_voting.py\n",
       "\u001b[1;31mType:\u001b[0m           ABCMeta\n",
       "\u001b[1;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "VotingClassifier?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85729126-94af-4ad5-adad-9f5e17133a3a",
   "metadata": {},
   "source": [
    "评估器核心参数解释如下："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf3a9e1-8f92-476e-9b17-98963a97988e",
   "metadata": {},
   "source": [
    "|Name|Description|   \n",
    "|:--:|:--:| \n",
    "|estimators|由（评估器名称，评估器）所组成的列表|\n",
    "|voting|融合的方式，包括此前介绍的硬投票和软投票两种|\n",
    "|weights|融合过程中各评估器的权重|\n",
    "|flatten_transform|在软投票时打印结果方式|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbed719-8cc1-4afe-9cc2-444c5d1d4672",
   "metadata": {},
   "source": [
    "&emsp;&emsp;其中关于如何进行加权投票，稍后我们会详细讨论，这里先快速实践VotingClassifier的使用方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d160be7-f884-474f-bc55-7c730465eafa",
   "metadata": {},
   "source": [
    "&emsp;&emsp;首先将参与融合的几个模型放在一个列表中："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2160dc57-830c-48be-8e01-f84dde0e8090",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [('lr', logistic_search.best_estimator_), ('tree', tree_model), ('rf', RF_0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79d7815-fb55-4faa-ac8a-fdc9c569ad37",
   "metadata": {},
   "source": [
    "这里有个细节需要注意，在使用sklearn的评估器进行投票法融合时，需要将之前的网格搜索评估器转化为模型评估器，否则后续VotingClassifier在执行fit时，会完整执行一遍网格搜索评估器的搜索过程。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ed9ebf-68e1-4336-869e-a45518dd5eba",
   "metadata": {},
   "source": [
    "> 注意这个自定义评估器、pipline、网格搜索评估器和投票法评估器相互嵌套的过程，以后会经常用到。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e901b488-e8b4-4ca9-9a7a-07a6a8d9091e",
   "metadata": {},
   "source": [
    "&emsp;&emsp;然后实例化投票法评估器，先尝试执行硬投票。和所有其他的评估器一样，VotingClassifier采集数据的投票结果是基于一个fit过程："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6265d2ba-f479-4854-8f3a-18c9b16c22a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "VC_hard = VotingClassifier(estimators).fit(X_train_OE, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b3d72c-880b-48a1-9d30-6ccffd348632",
   "metadata": {},
   "source": [
    "然后直接在给定数据集上进行predicate即可输出预测结果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "614a4f9b-a085-4f02-bc28-d534e1ce4a59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VC_hard.predict(X_train_OE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3582eddc-9b5f-45b6-a60e-735c25f3170d",
   "metadata": {},
   "source": [
    "注意，这里的predicate实际上就是每个模型在训练集上训练完成后，对训练数据进行预测然后硬投票之后的结果，该结果和手动计算结果基本一致："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ab358325-d239-40fd-82dc-a8e0354ca490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8345323741007195, 0.7910278250993753)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VC_hard.score(X_train_OE, y_train), VC_hard.score(X_test_OE, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e730d99-db68-4c37-b249-47b1dd55ef23",
   "metadata": {},
   "source": [
    "&emsp;&emsp;当然，我们也可以尝试令其执行软投票过程，只需要将voting参数改为soft即可："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d420829d-a96a-4663-81db-a123a1d343a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "VC_soft = VotingClassifier(estimators, voting='soft').fit(X_train_OE, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "74fadfc2-c323-4e0b-8b75-362fa18f1596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VC_soft.predict(X_train_OE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8b2925fc-6da5-4506-b2d0-9ca8793d6eab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.98627385, 0.01372615],\n",
       "       [0.38954929, 0.61045071],\n",
       "       [0.84200955, 0.15799045],\n",
       "       ...,\n",
       "       [0.42045843, 0.57954157],\n",
       "       [0.93886922, 0.06113078],\n",
       "       [0.98874499, 0.01125501]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 只有在软投票情况下，才能输出概率预测结果\n",
    "VC_soft.predict_proba(X_train_OE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4202489e-6d95-477a-8bf6-a6977cf5a3a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8258235516849678, 0.787052810902896)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VC_soft.score(X_train_OE, y_train), VC_soft.score(X_test_OE, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad32412d-8e76-448d-b3ee-26c7935b6ee0",
   "metadata": {},
   "source": [
    "最终结果对比如下："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa10abf8-c7be-45be-9fa5-0dda0e7f462f",
   "metadata": {},
   "source": [
    "|Models|train_score|test_score|\n",
    "|:--:|:--:|:--:|\n",
    "|logistic_search|0.8123|0.7836|\n",
    "|tree_model|0.7991|0.7683|\n",
    "|RF_0|0.8483|0.7955|\n",
    "|Voting_hard|0.8345|0.7910|\n",
    "|Voting_soft|0.8258|0.7870"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204c54cc-6769-431e-9261-5945069dd4ca",
   "metadata": {},
   "source": [
    "&emsp;&emsp;总的来说，当我们发现投票法的融合结果并不理想、想进一步提升融合效果时，一般来说有两种思路：其一是在多样性层面进行更进一步的优化，例如进一步优化模型多样性——更换效果更好同时（相互之间）更加独立的模型进行融合，或者优化样本多样性和特征多样性——不同模型考虑带入不同数据和不同特征进行训练，等等；其二则是在融合方法上进行优化，哪怕是在投票法的范畴，也有一些更加复杂的融合方法，例如几何平均数投票、加权投票、基于优化器的加权投票、两阶段建模等等方法。本节我们重点探讨模型融合方法层面的内容，下一小节再统一讨论如何构建多样性。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1589471-c94c-4f3e-8da1-6035ce392ac8",
   "metadata": {},
   "source": [
    "## 二、投票法&平均法的改进策略"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a1d35d-bbd1-4037-a5bf-fdf5dde8f106",
   "metadata": {},
   "source": [
    "&emsp;&emsp;接下来进一步讨论投票法&平均法的进阶融合策略。当然，所谓的进阶方法，只是在融合的方法层面更加复杂，但正如开篇所言，对于模型融合来说，没有哪种方法一定有效，并且也不是融合方法越复杂结果就越好。不过在方法学习阶段，我们应该尽可能掌握更多的方法更多的思路，然后在实践阶段尽可能多的尝试更多方法、组合更多方法，以期获得一个更好的结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004a4c1a-1a14-46d6-8e95-e0bc30feedea",
   "metadata": {},
   "source": [
    "### 1.几何平均数融合方法 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89bf9df-1543-4175-a747-61db4c7b8533",
   "metadata": {},
   "source": [
    "&emsp;&emsp;首先我们可以将平均法求均值的过程，改为求几何平均数的过程。这是一种非常简单改进策略，关于算术平均和几何平均的数学计算过程如下："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d96ea3e-40f7-4faf-a91c-b79f5e5134d2",
   "metadata": {},
   "source": [
    "$$算术平均数：\\bar x = \\frac{x_1+x_2+x_3+...+x_n}{n}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2b5de3-097a-4b07-a8ba-7fb4d1bf7330",
   "metadata": {},
   "source": [
    "$$几何平均数：G_n = \\sqrt[n]{x_1*x_2*x_3*...*x_n}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58645c37-ec28-4a46-8d66-031a7f69c8db",
   "metadata": {},
   "source": [
    "&emsp;&emsp;需要注意的是，几何平均数也是很多场景下求均值的最佳方法，例如复利下的平均利率、平均发展速度等，因此在很多时候我们也可以尝试通过几何平均求均值。上述三个模型的几何平均的平均概率结果如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ea05daf1-392a-47e5-a430-ea31e9ae5579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01195754, 0.60273938, 0.15058701, ..., 0.57184631, 0.04580045,\n",
       "       0.0083983 ])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.power(train_prediction1_proba * train_prediction2_proba * train_prediction3_proba, 1/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3b2868ff-73fc-44f8-8194-3238863bfe84",
   "metadata": {},
   "outputs": [],
   "source": [
    "Voting_train_GN = (np.power(train_prediction1_proba * \n",
    "                            train_prediction2_proba * \n",
    "                            train_prediction3_proba, 1/3) >= 0.5) * 1\n",
    "\n",
    "Voting_test_GN = (np.power(test_prediction1_proba * \n",
    "                           test_prediction2_proba * \n",
    "                           test_prediction3_proba, 1/3) >= 0.5) * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a2aea35b-bff0-4e91-970a-5da7cb6c525f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8237410071942446, 0.7842135150482681)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Voting_train_GN, y_train), accuracy_score(Voting_test_GN, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbef9f3-1436-4aa9-a940-453046b179b2",
   "metadata": {},
   "source": [
    "能够看出，融合效果并没有任何提升，不过这也只是该方法在当前数据集和当前模型上的表现结果，考虑到该方法实现成本较低，因此在很多情况下都可以快速的进行尝试。事实上，该方法也的确是很多竞赛队伍在模型融合阶段第一阶段会尝试的方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d560a66d-0f12-4c29-acad-981dd44cae06",
   "metadata": {},
   "source": [
    "### 2.排序平均法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b0cbc3-4583-4f11-b280-a0da5e684a58",
   "metadata": {},
   "source": [
    "&emsp;&emsp;另外还有一种平均法的改进策略——排序平均法。可以说这是一种转为提升ROC-AUC指标量身定制的方法，基本流程如下："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91354a5d-63b4-46f6-8340-ed1a43b43d64",
   "metadata": {},
   "source": [
    "<center><img src=\"https://s2.loli.net/2022/05/22/vyw453SGoJWF91c.png\" alt=\"image-20220522154322226\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648ae539-0e31-42ee-af8a-14d7f29d775b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.绝对多数票法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db1b6d3-029b-4bcf-b899-a233068d84d0",
   "metadata": {},
   "source": [
    "&emsp;&emsp;在投票法范畴，除了简单投票外，还有一种更加严格的投票方法——绝对多数票法。不同于投票法的少数服从多数，绝对多数票法要求票数达到某个临界值后才能输出结果，而如果没达到这个临界值，则不进行预测、而是暂时以某个其他的数值对结果进行标记。当然这个临界值肯定是多于半数票的，例如，假设我们要求只有取得3票以上才能输出结果，则投票法中的极简示例将输出如下结果："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63af83b6-c4fe-46fe-aa26-f9245a1bc94b",
   "metadata": {},
   "source": [
    "<center><img src=\"https://s2.loli.net/2022/05/20/HOzePD4T8hbSAmK.png\" alt=\"image-20220520154348748\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42e0dc9-05a1-4f1d-80e6-f0e5a7c383ed",
   "metadata": {},
   "source": [
    "其中只有2号样本输出了0值预测结果，其他样本都暂时标记为-1，即无法判别。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ca5a57-45e8-4d40-8844-500fb782c5b1",
   "metadata": {},
   "source": [
    "&emsp;&emsp;一般来说，为了方便区分，我们也会将遵循少数服从多数的投票法称为相对多数票法，在3个分类器的情况下，相对多数票其实就等价于临界值为2的绝对多数票法，而如上所示，如果我们提高这个临界值，则会直接导致两个结果：其一是输出的判别结果更加可信；但同时也将输出大量无法判别类别的样本。如何对剩余样本进行进一步的类别预测？一般来说有两种思路，其一是单独带入这些不确定的样本进行模型训练，然后再进行融合；其二则是采用别的融合方法在现有模型基础上进行预测。而无论采用哪种策略，其实本质上都是一种两阶段建模的方法，这也是模型融合中较为进阶的内容。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e545869-a4a1-4627-8c86-b7b1bb09ad0a",
   "metadata": {},
   "source": [
    "> 把不太确定类别的样本单独筛选出来再进行建模，其实非常类似于Boosting的思想。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a81b8a-d199-4336-b77b-19635fbb4368",
   "metadata": {},
   "source": [
    "### 4.阈值移动"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256b079a-7c00-4a73-8250-46f34e32fa0a",
   "metadata": {},
   "source": [
    "&emsp;&emsp;如果说有什么方法一定能够在投票&平均法基础上提升融合效果，那么一定阈值移动一定榜上有名。所谓阈值移动，其实就是改变判别样本类别时的阈值。此前无论是平均法还是几何平均法，在最终将平均后的概率转化为类别预测结果时，其实都是以0.5为阈值进行的判别——当平均后的概率大于0.5时判别为1类、小于0.5时判别为0类。但实际上这个阈值是可以改变的，就像此前逻辑回归模型优化时阈值移动一样，很多时候我们甚至可以将其视作一个超参数来进行优化。并且，相比后面要讨论的加权平均，阈值移动的过拟合风险更小，是融合阶段必不可少的尝试方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03de2920-6210-4940-93e6-36c0258e640c",
   "metadata": {},
   "source": [
    "#### 4.1 阈值移动的简单测试"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00adb554-10f7-49d3-b60e-9ce4fb31d343",
   "metadata": {},
   "source": [
    "&emsp;&emsp;一般来说，最佳阈值会在0.5附近，因此我们设置一组0.48、0.5和0.52作为阈值来计算训练集和测试集上的融合准确率："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d9332907-3e8b-4bed-ab8a-cfaffd313458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold 0.48:\n",
      "train_Accuracy 0.8263915184\n",
      "test_Accuracy 0.7904599659\n",
      "threshold 0.50:\n",
      "train_Accuracy 0.8258235517\n",
      "test_Accuracy 0.7870528109\n",
      "threshold 0.52:\n",
      "train_Accuracy 0.8226050738\n",
      "test_Accuracy 0.7813742192\n"
     ]
    }
   ],
   "source": [
    "for thr in [0.48, 0.5, 0.52]:\n",
    "\n",
    "    Voting_train_soft_thr = (((train_prediction1_proba + \n",
    "                               train_prediction2_proba + \n",
    "                               train_prediction3_proba) / 3) >= thr) * 1\n",
    "    \n",
    "    train_acc = accuracy_score(Voting_train_soft_thr, y_train)\n",
    "    \n",
    "    Voting_test_soft_thr = (((test_prediction1_proba + \n",
    "                              test_prediction2_proba + \n",
    "                              test_prediction3_proba) / 3) >= thr) * 1\n",
    "    \n",
    "    test_acc = accuracy_score(Voting_test_soft_thr, y_test)\n",
    "    \n",
    "    print(\"threshold %0.2f:\" % thr)\n",
    "    print(\"train_Accuracy %0.10f\" % train_acc)\n",
    "    print(\"test_Accuracy %0.10f\" % test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9513589e-dfe6-46ba-b599-680a4d48858c",
   "metadata": {},
   "source": [
    "从上面结果我们不难发现，相比0.5，阈值取为0.48时训练集得到的准确率更高，该结果能够说明两点，其一是阈值移动确实能够提升融合效果，其二则是我们发现训练集和测试集表现出了同步变化的趋势，也就说明阈值移动的过拟合风险较少。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823f719a-b7d2-47a6-896d-1de7da30248e",
   "metadata": {},
   "source": [
    "> 需要注意的是，尽管目前该问题还不明显，但实际上控制过拟合其实是所有模型融合优化方法最核心的问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abca2405-0f86-46c1-9885-f61c1213da1c",
   "metadata": {},
   "source": [
    "> 一般来说，最佳阈值都不会低于0.4也不会超过0.6，为何最佳阈值会在0.5附近，稍后在介绍投票法理论依据时一并介绍。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a022de-1c66-4d30-9cc5-a154b9a145cd",
   "metadata": {},
   "source": [
    "#### 4.2 借助hyperopt搜索最优阈值"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064929c9-54b1-4379-9ce0-ae17c35b5ac1",
   "metadata": {},
   "source": [
    "- hyperopt优化器使用方法回顾"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e41125d-f366-411c-9c0a-b7dbb48c2c20",
   "metadata": {},
   "source": [
    "&emsp;&emsp;当我们发现了阈值移动可以提升融合效果之后，接下来的问题就是，0.48是否就是最佳阈值呢？还是0.475或者0.478效果更好呢？当然这里可以一个个试，但更推荐的做法是将其视作超参数，带入到优化器当中进行搜索。由于课程已经进展到后期，熟练的组合不同工具来进行使用也是算法工程人员必备技能，因此这里我们考虑组合一个优化器来进行阈值搜索。这里的阈值是一个0到1之间的连续变量，因此可以考虑使用随机网格搜索，但考虑到随机网格搜索的准确性，这里更推荐使用hyperopt进行TPE搜索，能同时保证效果和效率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0b424092-483c-4e3f-81e8-df50c798f763",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp, fmin, tpe\n",
    "from numpy.random import RandomState"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a9a10b-fb2e-4b3f-bd49-eeb9c899eff4",
   "metadata": {},
   "source": [
    "&emsp;&emsp;hyperopt的使用需要设置超参数空间、创建目标函数以及创建搜索函数，首先是定义超参数空间，根据经验，大多数情况下最佳阈值都在0.4-0.6之间，因此可以据此设置超参数空间，当然这里设置一个0-1的空间也是可以的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "56ee0360-c6cf-4922-afb1-adc45b18923e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义超参数空间\n",
    "params_space = {'thr': hp.uniform(\"thr\",0.4,0.6)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5500b8-2a39-4afd-ad94-486c27531bc8",
   "metadata": {},
   "source": [
    "然后是定义目标函数，这里需要注意，由于hyperopt只能搜索最小值，因此如果我们希望准确率越高，在使用hyperopt进行搜索时需要将目标等价转化为搜索负准确率越小："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "578f855d-5f3c-448f-af11-0d786420b92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义目标函数\n",
    "def hyperopt_objective(params):\n",
    "    thr = params['thr']\n",
    "    \n",
    "    Voting_train_soft_thr = (((train_prediction1_proba + \n",
    "                               train_prediction2_proba + \n",
    "                               train_prediction3_proba) / 3) >= thr) * 1\n",
    "    \n",
    "    train_acc = accuracy_score(Voting_train_soft_thr, y_train)\n",
    "    \n",
    "    return -train_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623ebce9-d224-4d1e-aa3a-b7f75aca0d5b",
   "metadata": {},
   "source": [
    "最后则是优化函数，同时关联目标函数和搜索空间，并设置搜索过程所需相关参数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "513a40d4-2734-4b5a-9304-59bade17943a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_hyperopt(max_evals):\n",
    "    params_best = fmin(hyperopt_objective,\n",
    "                       space=params_space,\n",
    "                       algo=tpe.suggest,\n",
    "                       max_evals=max_evals, \n",
    "                       rstate=np.random.default_rng(17))    \n",
    "    return params_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "754a8afb-4916-4d36-9e02-40251a46be54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 3000/3000 [00:15<00:00, 193.85trial/s, best loss: -0.8271488072699735]\n"
     ]
    }
   ],
   "source": [
    "params_best = param_hyperopt(max_evals=3000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9ec559b3-433a-4a87-94e6-a209508d6231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4787137835346912"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_best['thr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "590c915e-8b7f-4e19-be28-13b61dde90d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7904599659284497"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Voting_test_soft_thr = (((test_prediction1_proba + \n",
    "                          test_prediction2_proba + \n",
    "                          test_prediction3_proba) / 3) >= params_best['thr']) * 1\n",
    "    \n",
    "test_acc = accuracy_score(Voting_test_soft_thr, y_test)\n",
    "\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72aead68-b0b1-4e5f-a815-0a0b0f7b4c09",
   "metadata": {},
   "source": [
    "&emsp;&emsp;能够发现，最终搜索得到结果是阈值取值为0.4787时最优，此时训练集准确率为0.8271，测试集准确率为0.7904，相比阈值为0.48时训练集上结果略有提升，尽管测试集目前并没有提升，但从流程上来看，借助优化器来进行搜索肯定比手动验算更准确更高效，该方法也是我们必须要掌握的方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef54b8e-f24d-4a32-b228-1a7cad812b4b",
   "metadata": {},
   "source": [
    "- 阈值移动效果的上限测试"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4eed40-31d3-43e8-8049-204959a5e892",
   "metadata": {},
   "source": [
    "&emsp;&emsp;接下来我们进行一个略显“犯规”的操作，即带入测试集进行阈值移动搜索。通常来说测试集的数据信息是不允许在模型训练阶段被泄露的，但这里尝试在测试集上进行最佳阈值搜索，实际上是希望“探探底”，看看阈值移动能在测试集上取得的最好成绩是多少，也就是的测试下阈值移动在测试集上的效果上限。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9351c9-3de8-4bf5-a829-c252292af8e0",
   "metadata": {},
   "source": [
    "&emsp;&emsp;该操作过程也非常简单，我们只需要把训练集的预测结果改为测试集的预测结果带入进行搜索即可："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5914bb26-5146-4518-9bad-0a61bfd877ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义超参数空间\n",
    "params_space = {'thr': hp.uniform(\"thr\",0.4,0.6)}\n",
    "\n",
    "# 定义目标函数\n",
    "def hyperopt_objective_test(params):\n",
    "    thr = params['thr']\n",
    "    \n",
    "    Voting_test_soft_thr = (((test_prediction1_proba + \n",
    "                              test_prediction2_proba + \n",
    "                              test_prediction3_proba) / 3) >= thr) * 1\n",
    "\n",
    "    test_acc = accuracy_score(Voting_test_soft_thr, y_test)\n",
    "    \n",
    "    return -test_acc\n",
    "\n",
    "# 定义优化函数\n",
    "def param_hyperopt(max_evals):\n",
    "    params_best = fmin(hyperopt_objective_test,\n",
    "                       space=params_space,\n",
    "                       algo=tpe.suggest,\n",
    "                       max_evals=max_evals, \n",
    "                       rstate=np.random.default_rng(17))    \n",
    "    return params_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9903a68f-bede-4ef7-a7ee-81890d926ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 3000/3000 [00:15<00:00, 197.30trial/s, best loss: -0.7915956842703009]\n"
     ]
    }
   ],
   "source": [
    "params_best = param_hyperopt(max_evals=3000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e8d3d38e-e940-464e-9ef3-969ce7685ae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'thr': 0.4714998631942625}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b04250-3c0b-4692-ac21-974ced6917c4",
   "metadata": {},
   "source": [
    "&emsp;&emsp;能够发现，在测试集上搜索的最佳阈值为0.4714，测试集的最佳得分0.7915，这其实就是阈值移动的效果上限了。该搜索结果和在训练集上搜索得到的结果并不一致，而在训练集上无法输出0.4714的原因也很简单，在训练集上阈值为0.4714时准确率不如0.4787："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "65976151-d1cb-40e1-ab06-ca54bccc8d56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8254449072321091"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 训练集得分\n",
    "Voting_train_soft_thr = (((train_prediction1_proba + \n",
    "                           train_prediction2_proba + \n",
    "                           train_prediction3_proba) / 3) >= params_best['thr']) * 1\n",
    "    \n",
    "train_acc = accuracy_score(Voting_train_soft_thr, y_train)\n",
    "\n",
    "train_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8463e46-1197-4cdd-8420-589afa0e6cd0",
   "metadata": {},
   "source": [
    "两次不同的搜索结果如下："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f260086-75bd-4d27-8847-e9a952d249c7",
   "metadata": {},
   "source": [
    "|搜索方法|thr|train_score|test_score|\n",
    "|:--:|:--:|:--:|:--:|\n",
    "|带入训练集搜索|0.4787|<font color=\"brown\">**0.8271**</font>|0.7904|\n",
    "|带入测试集搜索|0.4714|0.8254|<font color=\"brown\">**0.7915**</font>|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb910cf-a579-445e-b755-8b1c22f7fe98",
   "metadata": {},
   "source": [
    "&emsp;&emsp;两次搜索存在差异其实并不难理解，毕竟带入训练集进行搜索时是以训练集评分最高为目标输出的结果，而带入测试集进行搜索时是以测试集评分最高位目标输出最终结果。但是，我们其实更希望二者差异尽可能的减少，即能不能找到一个方法，能让我们在带入训练集的搜索结果也同时能在测试集上尽可能逼近0.7915这个上限呢？毕竟真实情况下我们只能带入训练集进行搜索，同时希望这个结果具备泛化能力（在新的数据集上也有很好的表现）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce638d8-5e1a-4468-bc05-186926fa495e",
   "metadata": {},
   "source": [
    "&emsp;&emsp;其实如果我们将阈值看成是算法的一个超参数，那么上面的问题就等价于是“如何找到一个泛化能力更强的超参数”。那么应该怎么做呢？熟悉网格搜索+CV过程的小伙伴肯定对此并不陌生，是的，要提升超参数的泛化能力，最好的方式就是交叉验证。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcef1126-19e9-4487-aa35-ac5fc93d016f",
   "metadata": {},
   "source": [
    "> 需要说明的是，相比其他方法，阈值移动在不进行交叉验证的情况下过拟合倾向并不严重（训练集结果和验证集结果差别不算特别大），甚至可以说是模型融合中过拟合风险较低的一种方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61769d66-047e-4910-ab55-77051eb8defd",
   "metadata": {},
   "source": [
    "- 借助交叉验证提升阈值搜索的泛化能力"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a19d9c-ac24-4ea2-ae50-e3a359478541",
   "metadata": {},
   "source": [
    "&emsp;&emsp;有了基本思路之后，接下来就要考虑如何实践了。首先补充介绍sklearn中的使用进行交叉验证评分的实用函数cross_val_score。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6adf1bfd-31c6-4785-ba02-031acbdd7d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "69ab8e9d-18d3-46e4-9c1b-4d3fab2d437b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m\n",
       "\u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mgroups\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mfit_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mpre_dispatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'2*n_jobs'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0merror_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnan\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Evaluate a score by cross-validation.\n",
       "\n",
       "Read more in the :ref:`User Guide <cross_validation>`.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "estimator : estimator object implementing 'fit'\n",
       "    The object to use to fit the data.\n",
       "\n",
       "X : array-like of shape (n_samples, n_features)\n",
       "    The data to fit. Can be for example a list, or an array.\n",
       "\n",
       "y : array-like of shape (n_samples,) or (n_samples, n_outputs),             default=None\n",
       "    The target variable to try to predict in the case of\n",
       "    supervised learning.\n",
       "\n",
       "groups : array-like of shape (n_samples,), default=None\n",
       "    Group labels for the samples used while splitting the dataset into\n",
       "    train/test set. Only used in conjunction with a \"Group\" :term:`cv`\n",
       "    instance (e.g., :class:`GroupKFold`).\n",
       "\n",
       "scoring : str or callable, default=None\n",
       "    A str (see model evaluation documentation) or\n",
       "    a scorer callable object / function with signature\n",
       "    ``scorer(estimator, X, y)`` which should return only\n",
       "    a single value.\n",
       "\n",
       "    Similar to :func:`cross_validate`\n",
       "    but only a single metric is permitted.\n",
       "\n",
       "    If `None`, the estimator's default scorer (if available) is used.\n",
       "\n",
       "cv : int, cross-validation generator or an iterable, default=None\n",
       "    Determines the cross-validation splitting strategy.\n",
       "    Possible inputs for cv are:\n",
       "\n",
       "    - `None`, to use the default 5-fold cross validation,\n",
       "    - int, to specify the number of folds in a `(Stratified)KFold`,\n",
       "    - :term:`CV splitter`,\n",
       "    - An iterable that generates (train, test) splits as arrays of indices.\n",
       "\n",
       "    For `int`/`None` inputs, if the estimator is a classifier and `y` is\n",
       "    either binary or multiclass, :class:`StratifiedKFold` is used. In all\n",
       "    other cases, :class:`KFold` is used. These splitters are instantiated\n",
       "    with `shuffle=False` so the splits will be the same across calls.\n",
       "\n",
       "    Refer :ref:`User Guide <cross_validation>` for the various\n",
       "    cross-validation strategies that can be used here.\n",
       "\n",
       "    .. versionchanged:: 0.22\n",
       "        `cv` default value if `None` changed from 3-fold to 5-fold.\n",
       "\n",
       "n_jobs : int, default=None\n",
       "    Number of jobs to run in parallel. Training the estimator and computing\n",
       "    the score are parallelized over the cross-validation splits.\n",
       "    ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
       "    ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
       "    for more details.\n",
       "\n",
       "verbose : int, default=0\n",
       "    The verbosity level.\n",
       "\n",
       "fit_params : dict, default=None\n",
       "    Parameters to pass to the fit method of the estimator.\n",
       "\n",
       "pre_dispatch : int or str, default='2*n_jobs'\n",
       "    Controls the number of jobs that get dispatched during parallel\n",
       "    execution. Reducing this number can be useful to avoid an\n",
       "    explosion of memory consumption when more jobs get dispatched\n",
       "    than CPUs can process. This parameter can be:\n",
       "\n",
       "        - ``None``, in which case all the jobs are immediately\n",
       "          created and spawned. Use this for lightweight and\n",
       "          fast-running jobs, to avoid delays due to on-demand\n",
       "          spawning of the jobs\n",
       "\n",
       "        - An int, giving the exact number of total jobs that are\n",
       "          spawned\n",
       "\n",
       "        - A str, giving an expression as a function of n_jobs,\n",
       "          as in '2*n_jobs'\n",
       "\n",
       "error_score : 'raise' or numeric, default=np.nan\n",
       "    Value to assign to the score if an error occurs in estimator fitting.\n",
       "    If set to 'raise', the error is raised.\n",
       "    If a numeric value is given, FitFailedWarning is raised.\n",
       "\n",
       "    .. versionadded:: 0.20\n",
       "\n",
       "Returns\n",
       "-------\n",
       "scores : ndarray of float of shape=(len(list(cv)),)\n",
       "    Array of scores of the estimator for each run of the cross validation.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> from sklearn import datasets, linear_model\n",
       ">>> from sklearn.model_selection import cross_val_score\n",
       ">>> diabetes = datasets.load_diabetes()\n",
       ">>> X = diabetes.data[:150]\n",
       ">>> y = diabetes.target[:150]\n",
       ">>> lasso = linear_model.Lasso()\n",
       ">>> print(cross_val_score(lasso, X, y, cv=3))\n",
       "[0.33150734 0.08022311 0.03531764]\n",
       "\n",
       "See Also\n",
       "---------\n",
       "cross_validate : To run cross-validation on multiple metrics and also to\n",
       "    return train scores, fit times and score times.\n",
       "\n",
       "cross_val_predict : Get predictions from each split of cross-validation for\n",
       "    diagnostic purposes.\n",
       "\n",
       "sklearn.metrics.make_scorer : Make a scorer from a performance metric or\n",
       "    loss function.\n",
       "\u001b[1;31mFile:\u001b[0m      d:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\n",
       "\u001b[1;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cross_val_score?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc58c97-ca22-4492-b205-00a7e3693dbb",
   "metadata": {},
   "source": [
    "顾名思义，该函数的核心用途是对输入的X、y进行训练集和验证集的划分，然后令输入的评估器在训练集上训练、在验证集上输出验证结果，例如一个简单的5折交叉验证过程如下："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb61184e-e929-457e-98f7-6a13fb779d0c",
   "metadata": {},
   "source": [
    "<center><img src=\"https://s2.loli.net/2022/05/18/1UAlpgwt2mSbTQ5.png\" alt=\"image-20220518205529331\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492c425c-7660-4453-86c7-15d8c3877571",
   "metadata": {},
   "source": [
    "此外，cross_val_score的关键参数解释如下："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a4d1f4-46d0-4310-a45c-2c7d4596697e",
   "metadata": {},
   "source": [
    "|Name|Description|   \n",
    "|:--:|:--:| \n",
    "|estimator|进行交叉验证的评估器|\n",
    "|X|交叉验证训练数据特征|\n",
    "|y|交叉验证训练数据标签|\n",
    "|scoring|模型评估指标|\n",
    "|cv|交叉验证折数|\n",
    "|fit_params|传入评估器的参数|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04cf17b-5796-4a71-ba2a-75b800ac2a7a",
   "metadata": {},
   "source": [
    "&emsp;&emsp;例如，我们可以借助cross_val_score函数，非常便捷的输出某个评估器五折交叉验证的结果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2e7f470e-7ca6-4621-85fe-97b291c79002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.75307474, 0.73226112, 0.72443182, 0.73579545, 0.73674242])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier()\n",
    "cross_val_score(tree, X_train_OE, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "48f07e1f-de97-42a8-8c5a-46b40b9079f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7360812476706518"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 输出验证集的平均得分\n",
    "cross_val_score(tree, X_train_OE, y_train).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c60acf6f-ee2c-4ea7-85fa-b8f1ef7a1634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7211811470755253"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 验证集得分和测试集非常接近\n",
    "tree.fit(X_train_OE, y_train)\n",
    "accuracy_score(tree.predict(X_test_OE), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cc1f8a-605b-42df-a480-d94833f9eb2c",
   "metadata": {},
   "source": [
    "这里有个细节需要注意，tree只进行了实例化，并没有fit，但最终还是输出了验证集上的准确率结果，说明在该模型在cross_val_score内部完成了训练，只不过这个过程没有显式的fit。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9987c31-87c8-4b5c-8b46-81cecd80206d",
   "metadata": {},
   "source": [
    "&emsp;&emsp;同时我们知道，VotingClassifier其实本质上也是个评估器，也是可以带入到cross_val_score当中进行计算的，因此一个完整的算法流程浮出水面：我们考虑将VotingClassifier封装到cross_val_score内，并输出交叉验证的平均结果，同时以该结果作为目标函数，进行TPE阈值搜索，此时就相当于手动创建了一个基于验证集的平均得分来进行超参数搜索的过程。这里唯一需要注意的是，VotingClassifier唯一的问题在于无法在predict方法里面调整阈值，我们需要手动封装一个能够实现阈值调整的VotingClassifier_threshold评估器。该评估器的封装过程和阈值移动逻辑回归评估器封装过程非常类似，只需要给出关键参数接口、同时在定义predict时设置根据阈值参数输出结果即可："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "96bcb796-5916-4760-b5bd-194273143f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VotingClassifier_threshold(BaseEstimator, ClassifierMixin, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, estimators, voting='hard', weights=None, thr=0.5):\n",
    "        self.estimators = estimators\n",
    "        self.voting = voting\n",
    "        self.weights = weights\n",
    "        self.thr = thr\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        VC = VotingClassifier(estimators = self.estimators, \n",
    "                              voting = self.voting, \n",
    "                              weights = self.weights)\n",
    "        \n",
    "        VC.fit(X, y)\n",
    "        self.clf = VC\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    def predict_proba(self, X):\n",
    "        if self.voting == 'soft':\n",
    "            res_proba = self.clf.predict_proba(X)\n",
    "        else:\n",
    "            res_proba = None\n",
    "        return res_proba\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if self.voting == 'soft':\n",
    "            res = (self.clf.predict_proba(X)[:, 1] >= self.thr) * 1\n",
    "        else:\n",
    "            res = self.clf.predict(X)\n",
    "        return res\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        acc = accuracy_score(self.predict(X), y)\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae6bd11-fd6d-429e-a554-fe0a9055144c",
   "metadata": {},
   "source": [
    "> 同样，该评估器也需要被写入telcoFunc.py文件中。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ed11ae-51b9-419d-8475-1fd3fd6b3144",
   "metadata": {},
   "source": [
    "简单测试VotingClassifier_threshold的实践效果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2355a8b8-82c1-4ba8-a9b0-65ba439ec38b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8271488072699735, 0.7904599659284497)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VC_soft_thr = VotingClassifier_threshold(estimators, voting='soft', thr=0.4787).fit(X_train_OE, y_train)\n",
    "VC_soft_thr.score(X_train_OE, y_train), VC_soft_thr.score(X_test_OE, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1660f514-50bb-47dc-9b40-5ab147f35900",
   "metadata": {},
   "source": [
    "然后尝试将VC_soft_thr作为estimator传入cross_val_score，计算验证集上的得分："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cf9e2a7c-1900-4491-ad64-30fec4c42a64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.82213813, 0.79659413, 0.80681818, 0.81155303, 0.80492424])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 每个验证集上的得分\n",
    "cross_val_score(VC_soft_thr, X_train_OE, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e037dc08-e809-48a1-80d2-a5f1a2dbb0b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8084055431323642"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 验证集上的平均得分\n",
    "cross_val_score(VC_soft_thr, X_train_OE, y_train, cv=5).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e863376d-26da-4c7f-be56-65fafdad276c",
   "metadata": {},
   "source": [
    "能够发现，相比训练集上的得分，验证集上的平均得分和测试集得分更为接近。这也更加坚定了我们的判断：以验证集的平均得分作为目标函数进行搜索能获得一个泛化能力更强的结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09894ea6-4f76-45b3-b608-f418f5349648",
   "metadata": {},
   "source": [
    "&emsp;&emsp;在一切准备妥当之后，接下来考虑以验证集的平均得分作为目标函数进行TPE搜索，基本过程如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4d4185ca-b496-4385-a502-1646cf631c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义超参数空间\n",
    "params_space = {'thr': hp.uniform(\"thr\", 0.4, 0.6)}\n",
    "\n",
    "# 定义目标函数\n",
    "def hyperopt_objective_val(params):\n",
    "    thr = params['thr']\n",
    "    \n",
    "    # 创建带阈值的平均法评估器\n",
    "    VC_soft_thr = VotingClassifier_threshold(estimators, voting='soft', thr=thr)\n",
    "\n",
    "    # 输出验证集上的平均得分\n",
    "    val_score = cross_val_score(VC_soft_thr, \n",
    "                                X_train_OE, \n",
    "                                y_train, \n",
    "                                scoring='accuracy', \n",
    "                                n_jobs=15,\n",
    "                                cv=3).mean()\n",
    "    \n",
    "    return -val_score\n",
    "\n",
    "# 定义优化函数\n",
    "def param_hyperopt_val(max_evals):\n",
    "    params_best = fmin(hyperopt_objective_val,\n",
    "                       space=params_space,\n",
    "                       algo=tpe.suggest,\n",
    "                       max_queue_len=5,\n",
    "                       max_evals=max_evals, \n",
    "                       rstate=np.random.default_rng(17))    \n",
    "    return params_best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18712e36-0e69-487d-b30f-d3a3153bd309",
   "metadata": {},
   "source": [
    "这里有两点需要注意，其一是可以在cross_val_score中设置一个n_jobs以提高每次验证集划分、训练、评分的速度，其二则是关于交叉验证折数划分的问题，这里建议划分三折，主要原因也是考虑到当前训练数据的数据总量，划分折数过多容易导致验证集数量太少，从而导致验证集评分方差过大，结果可信度降低。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "38605429-06d3-4e7a-9e89-6cac4781beaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 3000/3000 [11:08<00:00,  4.49trial/s, best loss: -0.8085965059453134]\n"
     ]
    }
   ],
   "source": [
    "params_best_val = param_hyperopt_val(max_evals=3000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f764a63f-acf3-4fd8-9db1-5ff512fd0294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'thr': 0.46991159868237964}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_best_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f8d324-5695-4053-bc15-7f53b21027df",
   "metadata": {},
   "source": [
    "能够发现，搜索出来的阈值结果会更加接近测试集上搜索出来的阈值最优解0.4714，接下来查看在该阈值情况下训练集和测试集的得分："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "aeb31e4c-feb2-4489-b302-6fc768303144",
   "metadata": {},
   "outputs": [],
   "source": [
    "VC_soft_thr = VotingClassifier_threshold(estimators, \n",
    "                                         voting='soft', \n",
    "                                         thr=params_best_val['thr']).fit(X_train_OE, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "824b7217-6c90-467c-a268-2defd0e2172c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8258235516849678, 0.7910278250993753)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VC_soft_thr.score(X_train_OE, y_train), VC_soft_thr.score(X_test_OE, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ecc27c-bd02-4fc2-af44-4140a6ffb8f5",
   "metadata": {},
   "source": [
    "能够发现，加入交叉验证之后，训练集和测试集的结果一致性得到了显著加强，相比只带入训练集而不进行交叉验证的搜索过程，本轮搜索得到了一个更好的结果，阈值的泛化能力进一步增强，在训练集上训练的结果到达了0.7910，能够看出交叉验证对于搜索结果泛化能力的提升还是较为明显的。虽然本次实验没有达到测试集效果上限，但这其实是也是一般情况，在很多时候，这个上限只能逼近但无法达到，很多时候交叉验证的引入能显著提升搜索结果的泛化能力，但训练数据和测试数据之间总是会存在无法捕捉且不一致的规律，我们要做的（能做的），就是取不断的提高泛化能力、取逼近这个上限。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d57c11-d7c5-4ecf-84a1-fdc8dc236e60",
   "metadata": {},
   "source": [
    "|搜索方法|thr|train_score|test_score|\n",
    "|:--:|:--:|:--:|:--:|\n",
    "|带入训练集搜索|0.4787|<font color=\"brown\">**0.8271**</font>|0.7904|\n",
    "|带入测试集搜索|0.4714|0.8254|<font color=\"brown\">**0.7915**</font>|\n",
    "|训练集+CV搜索|0.4699|0.8258|<font color=\"brown\">**0.7910**</font>|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d93035-c807-48f6-9d16-08a027820679",
   "metadata": {},
   "source": [
    "> 需要注意的是，带入交叉验证与提高模型泛化能力实际上也是一个概率问题，只能说大概率下引入交叉验证后能提升泛化能力，但并非100%能提高泛化能力，这和数据、模型都有很大的关系。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a51f66-0682-4025-9121-db1c05830baa",
   "metadata": {},
   "source": [
    "> 另外，这里我们说在测试集上的搜索结果是阈值调整的效果上限，实际上这个上限只是实践层面的上限，并不是理论层面的上限，其实投票法&平均法（包括阈值移动）的理论效果上限是非常高的。因此，这个实践层面的上限，我们也可以称其为软上限，而理论层面的上限，可以称其为硬上限。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb1958b-5a05-4047-8676-e8633fb68566",
   "metadata": {},
   "source": [
    "- 硬投票的阈值移动"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe30a2f5-4a65-4ca8-8152-fefb7b7951cd",
   "metadata": {},
   "source": [
    "&emsp;&emsp;关于硬投票能否进行阈值移动，当然也是可以的，不过对于一个二分类问题，在三个模型参与融合的情况下，每个样本的的票只可能在0-3之间，因此阈值调整空间有限，所需要"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
