{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8fcfd7d-34c8-4abc-884e-2ab220fe143e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# <center> 【Kaggle】Telco Customer Churn 电信用户流失预测案例"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431a94c7-69ae-4004-960f-b4a24cdc9eb0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f5de26-5a43-42a9-84d7-6052a0cdb913",
   "metadata": {},
   "source": [
    "## <font face=\"仿宋\">第四部分导读"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f11a7e-f97e-4781-b096-951d5b0f3f30",
   "metadata": {},
   "source": [
    "&emsp;&emsp;<font face=\"仿宋\">在案例的第二、三部分中，我们详细介绍了关于特征工程的各项技术，特征工程技术按照大类来分可以分为数据预处理、特征衍生、特征筛选三部分，其中特征预处理的目的是为了将数据集整理、清洗到可以建模的程度，具体技术包括缺失值处理、异常值处理、数据重编码等，是建模之前必须对数据进行的处理和操作；而特征衍生和特征筛选则更像是一类优化手段，能够帮助模型突破当前数据集建模的效果上界。并且我们在第二部分完整详细的介绍机器学习可解释性模型的训练、优化和解释方法，也就是逻辑回归和决策树模型。并且此前我们也一直以这两种算法为主，来进行各个部分的模型测试。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c981a8f8-191c-43c0-9a5f-585ff3dd9cee",
   "metadata": {},
   "source": [
    "&emsp;&emsp;<font face=\"仿宋\">而第四部分，我们将开始介绍集成学习的训练和优化的实战技巧，尽管从可解释性角度来说，集成学习的可解释性并不如逻辑回归和决策树，但在大多数建模场景下，集成学习都将获得一个更好的预测结果，这也是目前效果优先的建模场景下最常使用的算法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe876e6-8075-4b30-8ec1-d33fe70592c5",
   "metadata": {},
   "source": [
    "&emsp;&emsp;<font face=\"仿宋\">总的来说，本部分内容只有一个目标，那就是借助各类优化方法，抵达每个主流集成学习的效果上界。换而言之，本部分我们将围绕单模优化策略展开详细的探讨，涉及到的具体集成学习包括随机森林、XGBoost、LightGBM、和CatBoost等目前最主流的集成学习算法，而具体的优化策略则包括超参数优化器的使用、特征衍生和筛选方法的使用、单模型自融合方法的使用，这些优化方法也是截至目前，提升单模效果最前沿、最有效、同时也是最复杂的方法。其中有很多较为艰深的理论，也有很多是经验之谈，但无论如何，我们希望能够围绕当前数据集，让每个集成学习算法优化到极限。值得注意的是，在这个过程中，我们会将此前介绍的特征衍生和特征筛选视作是一种模型优化方法，衍生和筛选的效果，一律以模型的最终结果来进行评定。而围绕集成学习进行海量特征衍生和筛选，也才是特征衍生和筛选技术能发挥巨大价值的主战场。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e974b23-efb4-4e23-9f31-8075d42bdba7",
   "metadata": {},
   "source": [
    "&emsp;&emsp;<font face=\"仿宋\">而在抵达了单模的极限后，我们就会进入到下一阶段，也就是模型融合阶段。需要知道的是，只有单模的效果到达了极限，进一步的多模型融合、甚至多层融合，才是有意义的，才是有效果的。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c70dc0-fee3-4867-952e-b3dede8c16cb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b239810-71a2-4713-bf9a-2e89c16d7a3e",
   "metadata": {},
   "source": [
    "# <center>Part 4.集成算法的训练与优化技巧"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2155bafe-c4ff-4ead-bde7-d1733593f911",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 基础数据科学运算库\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 可视化库\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 时间模块\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# sklearn库\n",
    "# 数据预处理\n",
    "from sklearn import preprocessing\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# 实用函数\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 常用评估器\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 网格搜索\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 自定义评估器支持模块\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, ClassifierMixin\n",
    "\n",
    "# 自定义模块\n",
    "from telcoFunc import *\n",
    "# 导入特征衍生模块\n",
    "import features_creation as fc\n",
    "from features_creation import *\n",
    "\n",
    "# re模块相关\n",
    "import inspect, re\n",
    "\n",
    "# 其他模块\n",
    "from tqdm import tqdm\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cd7b8a-994e-44ce-9f8f-1ac6b883eb49",
   "metadata": {},
   "source": [
    "&emsp;&emsp;然后执行Part 1中的数据清洗相关工作："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3a238cc-7319-4fde-b92b-4e3fcdfa09b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "tcc = pd.read_csv('WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
    "\n",
    "# 标注连续/离散字段\n",
    "# 离散字段\n",
    "category_cols = ['gender', 'SeniorCitizen', 'Partner', 'Dependents',\n",
    "                'PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', \n",
    "                'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling',\n",
    "                'PaymentMethod']\n",
    "\n",
    "# 连续字段\n",
    "numeric_cols = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
    " \n",
    "# 标签\n",
    "target = 'Churn'\n",
    "\n",
    "# ID列\n",
    "ID_col = 'customerID'\n",
    "\n",
    "# 验证是否划分能完全\n",
    "assert len(category_cols) + len(numeric_cols) + 2 == tcc.shape[1]\n",
    "\n",
    "# 连续字段转化\n",
    "tcc['TotalCharges']= tcc['TotalCharges'].apply(lambda x: x if x!= ' ' else np.nan).astype(float)\n",
    "tcc['MonthlyCharges'] = tcc['MonthlyCharges'].astype(float)\n",
    "\n",
    "# 缺失值填补\n",
    "tcc['TotalCharges'] = tcc['TotalCharges'].fillna(0)\n",
    "\n",
    "# 标签值手动转化 \n",
    "tcc['Churn'].replace(to_replace='Yes', value=1, inplace=True)\n",
    "tcc['Churn'].replace(to_replace='No',  value=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c26a3c5b-03f4-41d7-a3a3-3f3a3a3f9e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = tcc.drop(columns=[ID_col, target]).copy()\n",
    "labels = tcc['Churn'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0712f58-e902-461a-8d9a-64cb801406e3",
   "metadata": {},
   "source": [
    "&emsp;&emsp;同时，创建自然编码后的数据集以及经过时序特征衍生的数据集："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfa26744-c42f-437d-92b5-9e94d3bf9a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分训练集和测试集\n",
    "train, test = train_test_split(tcc, random_state=22)\n",
    "\n",
    "X_train = train.drop(columns=[ID_col, target]).copy()\n",
    "X_test = test.drop(columns=[ID_col, target]).copy()\n",
    "\n",
    "y_train = train['Churn'].copy()\n",
    "y_test = test['Churn'].copy()\n",
    "\n",
    "X_train_seq = pd.DataFrame()\n",
    "X_test_seq = pd.DataFrame()\n",
    "\n",
    "# 年份衍生\n",
    "X_train_seq['tenure_year'] = ((72 - X_train['tenure']) // 12) + 2014\n",
    "X_test_seq['tenure_year'] = ((72 - X_test['tenure']) // 12) + 2014\n",
    "\n",
    "# 月份衍生\n",
    "X_train_seq['tenure_month'] = (72 - X_train['tenure']) % 12 + 1\n",
    "X_test_seq['tenure_month'] = (72 - X_test['tenure']) % 12 + 1\n",
    "\n",
    "# 季度衍生\n",
    "X_train_seq['tenure_quarter'] = ((X_train_seq['tenure_month']-1) // 3) + 1\n",
    "X_test_seq['tenure_quarter'] = ((X_test_seq['tenure_month']-1) // 3) + 1\n",
    "\n",
    "# 独热编码\n",
    "enc = preprocessing.OneHotEncoder()\n",
    "enc.fit(X_train_seq)\n",
    "\n",
    "seq_new = list(X_train_seq.columns)\n",
    "\n",
    "# 创建带有列名称的独热编码之后的df\n",
    "X_train_seq = pd.DataFrame(enc.transform(X_train_seq).toarray(), \n",
    "                           columns = cate_colName(enc, seq_new, drop=None))\n",
    "\n",
    "X_test_seq = pd.DataFrame(enc.transform(X_test_seq).toarray(), \n",
    "                          columns = cate_colName(enc, seq_new, drop=None))\n",
    "\n",
    "# 调整index\n",
    "X_train_seq.index = X_train.index\n",
    "X_test_seq.index = X_test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb66889e-2d71-4e59-8e32-6d97bf2d686d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ord_enc = OrdinalEncoder()\n",
    "ord_enc.fit(X_train[category_cols])\n",
    "\n",
    "X_train_OE = pd.DataFrame(ord_enc.transform(X_train[category_cols]), columns=category_cols)\n",
    "X_train_OE.index = X_train.index\n",
    "X_train_OE = pd.concat([X_train_OE, X_train[numeric_cols]], axis=1)\n",
    "\n",
    "X_test_OE = pd.DataFrame(ord_enc.transform(X_test[category_cols]), columns=category_cols)\n",
    "X_test_OE.index = X_test.index\n",
    "X_test_OE = pd.concat([X_test_OE, X_test[numeric_cols]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08e07405-fde1-44d0-8d5e-a12035ec0a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 本节新增第三方库\n",
    "from joblib import dump, load\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from hyperopt import hp, fmin, tpe\n",
    "from numpy.random import RandomState\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b189fc15-5092-4a39-b4ea-2f6e1edc4a54",
   "metadata": {},
   "source": [
    "## <center>Ch.3 模型融合基础方法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf2a9b2-7a89-4415-9cc2-a71cd94f0fc8",
   "metadata": {},
   "source": [
    "### 五、基于交叉训练的权重搜索融合"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999f297f-68dc-4a63-86f5-2b0f50751efc",
   "metadata": {},
   "source": [
    "&emsp;&emsp;接下来我们继续尝试权重搜索的第二种改进方案，即手动划分训练集和验证集，并在每次划分训练集上进行单独模型的超参数搜索和优化。这个过程并不复杂，但会有大量重复训练和超参数优化的环节。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afef2a71-06d0-4f4d-a149-11d0efdb98c7",
   "metadata": {},
   "source": [
    "<center><img src=\"https://s2.loli.net/2022/05/18/1UAlpgwt2mSbTQ5.png\" alt=\"image-20220518205529331\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb36ba3f-e4f3-462f-bdb2-eefd2bc7023d",
   "metadata": {},
   "source": [
    "### 1.数据准备"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf60a98-4b58-4a3c-aadf-3361466cd0e0",
   "metadata": {},
   "source": [
    "&emsp;&emsp;首先我们需要围绕当前数据集进行手动五折划分，可以借助KFold过程快速完成："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7683c6de-cba8-4f57-8653-21f45e1b1612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实例化KFold评估器\n",
    "kf = KFold(n_splits=5, random_state=12, shuffle=True)\n",
    "\n",
    "# 重置训练集和测试集的index\n",
    "X_train_OE = X_train_OE.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7df92d-a2c3-4ed2-a5cb-40045e5772f3",
   "metadata": {},
   "source": [
    "然后需要单独创建每一轮划分后的训练集和验证集，可以通过如下过程完成："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a3e998f-702f-42e1-b751-7760b340e85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   1    2    5 ... 5279 5280 5281]\n",
      "[   0    3    4 ... 5271 5274 5275]\n"
     ]
    }
   ],
   "source": [
    "# 循环一次，切分一次数据集和验证集\n",
    "for train_part_index, eval_index in kf.split(X_train_OE, y_train):\n",
    "    print(train_part_index)\n",
    "    print(eval_index)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7ffe605-491c-4791-86b4-6a6011fd7ef7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>OnlineBackup</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>tenure</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>80.00</td>\n",
       "      <td>241.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>19.00</td>\n",
       "      <td>73.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69</td>\n",
       "      <td>84.45</td>\n",
       "      <td>5848.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26</td>\n",
       "      <td>54.75</td>\n",
       "      <td>1406.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11</td>\n",
       "      <td>44.65</td>\n",
       "      <td>472.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5277</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>52</td>\n",
       "      <td>106.30</td>\n",
       "      <td>5487.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5278</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16</td>\n",
       "      <td>54.10</td>\n",
       "      <td>889.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5279</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>28</td>\n",
       "      <td>106.15</td>\n",
       "      <td>3152.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5280</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15</td>\n",
       "      <td>20.35</td>\n",
       "      <td>335.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5281</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68</td>\n",
       "      <td>24.00</td>\n",
       "      <td>1664.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4225 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender  SeniorCitizen  Partner  Dependents  PhoneService  MultipleLines  \\\n",
       "1        0.0            0.0      1.0         1.0           1.0            0.0   \n",
       "2        1.0            0.0      0.0         0.0           1.0            0.0   \n",
       "5        0.0            0.0      1.0         1.0           1.0            2.0   \n",
       "6        0.0            0.0      0.0         0.0           1.0            0.0   \n",
       "7        0.0            0.0      0.0         0.0           1.0            0.0   \n",
       "...      ...            ...      ...         ...           ...            ...   \n",
       "5277     1.0            0.0      1.0         0.0           1.0            0.0   \n",
       "5278     0.0            1.0      0.0         0.0           1.0            2.0   \n",
       "5279     0.0            1.0      0.0         0.0           1.0            2.0   \n",
       "5280     0.0            0.0      1.0         1.0           1.0            0.0   \n",
       "5281     1.0            0.0      1.0         1.0           1.0            2.0   \n",
       "\n",
       "      InternetService  OnlineSecurity  OnlineBackup  DeviceProtection  \\\n",
       "1                 1.0             0.0           2.0               0.0   \n",
       "2                 2.0             1.0           1.0               1.0   \n",
       "5                 1.0             2.0           0.0               2.0   \n",
       "6                 0.0             0.0           2.0               2.0   \n",
       "7                 0.0             0.0           0.0               0.0   \n",
       "...               ...             ...           ...               ...   \n",
       "5277              1.0             2.0           2.0               2.0   \n",
       "5278              0.0             2.0           0.0               0.0   \n",
       "5279              1.0             0.0           2.0               2.0   \n",
       "5280              2.0             1.0           1.0               1.0   \n",
       "5281              2.0             1.0           1.0               1.0   \n",
       "\n",
       "      TechSupport  StreamingTV  StreamingMovies  Contract  PaperlessBilling  \\\n",
       "1             2.0          0.0              0.0       0.0               1.0   \n",
       "2             1.0          1.0              1.0       0.0               0.0   \n",
       "5             0.0          0.0              0.0       1.0               0.0   \n",
       "6             0.0          0.0              0.0       0.0               1.0   \n",
       "7             0.0          0.0              0.0       0.0               1.0   \n",
       "...           ...          ...              ...       ...               ...   \n",
       "5277          2.0          2.0              2.0       2.0               1.0   \n",
       "5278          0.0          0.0              0.0       0.0               1.0   \n",
       "5279          0.0          2.0              2.0       0.0               1.0   \n",
       "5280          1.0          1.0              1.0       1.0               0.0   \n",
       "5281          1.0          1.0              1.0       2.0               1.0   \n",
       "\n",
       "      PaymentMethod  tenure  MonthlyCharges  TotalCharges  \n",
       "1               2.0       3           80.00        241.30  \n",
       "2               3.0       4           19.00         73.45  \n",
       "5               0.0      69           84.45       5848.60  \n",
       "6               1.0      26           54.75       1406.90  \n",
       "7               3.0      11           44.65        472.25  \n",
       "...             ...     ...             ...           ...  \n",
       "5277            2.0      52          106.30       5487.00  \n",
       "5278            2.0      16           54.10        889.00  \n",
       "5279            2.0      28          106.15       3152.50  \n",
       "5280            1.0      15           20.35        335.95  \n",
       "5281            0.0      68           24.00       1664.30  \n",
       "\n",
       "[4225 rows x 19 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_OE.loc[train_part_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90441f4a-6d75-404e-90e0-cd25e1307c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_part_index_l = []\n",
    "eval_index_l = []\n",
    "\n",
    "for train_part_index, eval_index in kf.split(X_train_OE, y_train):\n",
    "    train_part_index_l.append(train_part_index)\n",
    "    eval_index_l.append(eval_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abfa52a0-585f-4859-8687-b9ac1a4a441e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([   1,    2,    5, ..., 5279, 5280, 5281]),\n",
       " array([   0,    1,    2, ..., 5279, 5280, 5281]),\n",
       " array([   0,    1,    2, ..., 5279, 5280, 5281]),\n",
       " array([   0,    1,    3, ..., 5275, 5277, 5281]),\n",
       " array([   0,    2,    3, ..., 5278, 5279, 5280])]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_part_index_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38f3daf7-736d-474b-8186-a2b8e7e38642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练集特征\n",
    "X_train1 = X_train_OE.loc[train_part_index_l[0]]\n",
    "X_train2 = X_train_OE.loc[train_part_index_l[1]]\n",
    "X_train3 = X_train_OE.loc[train_part_index_l[2]]\n",
    "X_train4 = X_train_OE.loc[train_part_index_l[3]]\n",
    "X_train5 = X_train_OE.loc[train_part_index_l[4]]\n",
    "\n",
    "# 验证集特征\n",
    "X_eval1 = X_train_OE.loc[eval_index_l[0]]\n",
    "X_eval2 = X_train_OE.loc[eval_index_l[1]]\n",
    "X_eval3 = X_train_OE.loc[eval_index_l[2]]\n",
    "X_eval4 = X_train_OE.loc[eval_index_l[3]]\n",
    "X_eval5 = X_train_OE.loc[eval_index_l[4]]\n",
    "\n",
    "# 训练集标签\n",
    "y_train1 = y_train.loc[train_part_index_l[0]]\n",
    "y_train2 = y_train.loc[train_part_index_l[1]]\n",
    "y_train3 = y_train.loc[train_part_index_l[2]]\n",
    "y_train4 = y_train.loc[train_part_index_l[3]]\n",
    "y_train5 = y_train.loc[train_part_index_l[4]]\n",
    "\n",
    "# 验证集标签\n",
    "y_eval1 = y_train.loc[eval_index_l[0]]\n",
    "y_eval2 = y_train.loc[eval_index_l[1]]\n",
    "y_eval3 = y_train.loc[eval_index_l[2]]\n",
    "y_eval4 = y_train.loc[eval_index_l[3]]\n",
    "y_eval5 = y_train.loc[eval_index_l[4]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c88d36-9158-4368-9ba3-6fb118656c63",
   "metadata": {},
   "source": [
    "&emsp;&emsp;第一次手动交叉验证训练模型时我们尝试把所有的五次划分的训练集、验证集单独列出，便于大家理解。后面在熟练的情况下可以通过一个循环完成全部操作。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494e1f46-92e6-4767-99da-f305cfbaf533",
   "metadata": {},
   "source": [
    "&emsp;&emsp;接下来考虑将训练集的特征和标签、测试集的特征和标签分别放到两个list当中，方便后续调用："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c13d46bb-0065-4ffb-a370-2a7382048826",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = [(X_train1, y_train1), \n",
    "             (X_train2, y_train2), \n",
    "             (X_train3, y_train3), \n",
    "             (X_train4, y_train4), \n",
    "             (X_train5, y_train5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd37badd-65fd-41c3-91da-ed773e16e7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_set = [(X_eval1, y_eval1), \n",
    "            (X_eval2, y_eval2), \n",
    "            (X_eval3, y_eval3), \n",
    "            (X_eval4, y_eval4), \n",
    "            (X_eval5, y_eval5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fec27b-5057-44f5-80f1-f390b4ebba5b",
   "metadata": {},
   "source": [
    "### 2.模型训练"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e20733-c303-4d2e-add0-76bba2a9f8f7",
   "metadata": {},
   "source": [
    "&emsp;&emsp;数据集划分完成后，接下来考虑围绕每个训练数据集进行模型训练与超参数优化。实现该过程有两种基本方法，首先最简单的方法就是每个模型在5组训练数据下分别训练和超参数优化，按照上一节介绍的超参数优化策略，一个个模型进行优化，每类模型需要训练并优化得到5个不同的模型；其二则是批量模型超参数搜索，可以考虑设置一个非常大的超参数空间，然后循环带入五组训练数据集，进行五个模型训练和超参数优化，若每个模型的超参数都正好落在超参数搜素空间内，则五个模型都是最优模型，而如果某个模型的超参数正好落在搜索边界上，则需要围绕这个模型（带入对应的训练数据）再次设置超参数空间并进行超参数搜索。前者需要大量手动操作但较为节省时间，后者更加自动化但需要耗费更大量的计算时间。对于决策树和逻辑回归这种搜索过程较快的模型，可以采用批量搜索的方法，而对于随机森林，考虑到单个模型的超参数优化就会比较耗时，因此建议单独手动训练模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6988b2-a96c-4796-8c6a-5dc788b8897b",
   "metadata": {},
   "source": [
    "> 模型训练枯燥但至关重要，模型训练的好坏与否，直接决定最终融合效果。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fe2383-88cf-4d61-8916-fe8d5bef59ec",
   "metadata": {},
   "source": [
    "#### 2.1 随机森林的交叉训练"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab78f40-a0ca-409c-a1f5-351bafd1f535",
   "metadata": {},
   "source": [
    "- X_train1&y_train1训练过程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b554253-17b3-4532-a9d6-459f7d359d68",
   "metadata": {},
   "source": [
    "&emsp;&emsp;首先，围绕划分出来的第一个训练集进行模型训练与超参数优化，具体每一轮的超参数搜索可以参照上一小节方法执行，同时由于模型训练数据和全训练集样本差别不大，也可以以上一小节最终得到的最有超参数组为依据进行搜索。这里仅展示最后一轮搜索时超参数设置情况："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "939166f1-8600-493a-8282-df2f0634467d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "336.0223355293274\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# 设置超参数空间\n",
    "parameter_space = {\n",
    "    \"min_samples_leaf\": range(4, 7), \n",
    "    \"min_samples_split\": range(1, 4),\n",
    "    \"max_depth\": range(7, 11),\n",
    "    \"max_leaf_nodes\": [None] + list(range(31, 34)), \n",
    "    \"n_estimators\": range(93, 96), \n",
    "    \"max_features\":['sqrt', 'log2'] + list(range(5, 8)), \n",
    "    \"max_samples\":[None, 0.49, 0.5, 0.51]}\n",
    "\n",
    "# 实例化模型与评估器\n",
    "RF_1 = RandomForestClassifier(random_state=12)\n",
    "grid_RF_1 = GridSearchCV(RF_1, parameter_space, n_jobs=15)\n",
    "\n",
    "# 模型训练\n",
    "grid_RF_1.fit(X_train1, y_train1)\n",
    "\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "67ae99c7-9d91-42d0-a1cf-7b355557be77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.805680473372781"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_RF_1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "67b733b8-d3f2-4d3b-a14a-03f07dd1e03a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 8,\n",
       " 'max_features': 6,\n",
       " 'max_leaf_nodes': 32,\n",
       " 'max_samples': 0.5,\n",
       " 'min_samples_leaf': 5,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 94}"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_RF_1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "7f8b12bf-4f90-4684-a8fe-ffc838e191e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.818698224852071, 0.8164616840113529, 0.7819420783645656)"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_RF_1.score(X_train1, y_train1), grid_RF_1.score(X_eval1, y_eval1), grid_RF_1.score(X_test_OE, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec05a83-cded-4949-abf8-a3035e5eea7d",
   "metadata": {},
   "source": [
    "&emsp;&emsp;不过受限于样本量，当前训练集上得到的模型效果并不如完整数据集上的模型效果。并且能够发现，在很多情况下，验证集的得分会比训练集上的得分更接近测试集上的得分，这其实也是因为验证集同样也是没有参与模型训练的部分数据集，相比训练集，更能代表模型泛化能力。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e02bea7-602e-4c04-be96-61c6ee320429",
   "metadata": {},
   "source": [
    "&emsp;&emsp;当然，截至目前我们只进行了一次建模，还需要重复上述过程、在四组不同的训练集和验证集上进行建模和预测。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c448221-1321-441c-b414-4b897a798005",
   "metadata": {},
   "source": [
    "- X_train2&y_train2训练过程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079243ed-bd05-4d42-9276-b79333e2f23c",
   "metadata": {},
   "source": [
    "&emsp;&emsp;接下来继续在2号训练数据集上进行超参数优化："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "ff0bc82b-b513-4141-837c-bc2fcd7417ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234.58312821388245\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# 设置超参数空间\n",
    "parameter_space = {\n",
    "    \"min_samples_leaf\": range(4, 7), \n",
    "    \"min_samples_split\": range(1, 4),\n",
    "    \"max_depth\": range(8, 11),\n",
    "    \"max_leaf_nodes\": [None] + list(range(39, 42)), \n",
    "    \"n_estimators\": range(79, 82), \n",
    "    \"max_features\":['sqrt', 'log2'] + list(range(3, 7)), \n",
    "    \"max_samples\":[None, 0.369, 0.37, 0.371]}\n",
    "\n",
    "# 实例化模型与评估器\n",
    "RF_2 = RandomForestClassifier(random_state=12)\n",
    "grid_RF_2 = GridSearchCV(RF_2, parameter_space, n_jobs=15)\n",
    "\n",
    "# 模型训练\n",
    "grid_RF_2.fit(X_train2, y_train2)\n",
    "\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "e21a6d8b-fcd5-4bb4-b38b-f421dcb75974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8120710059171599"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_RF_2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "28821fc6-38e1-4900-81c5-d0c265fe08ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 9,\n",
       " 'max_features': 5,\n",
       " 'max_leaf_nodes': 40,\n",
       " 'max_samples': 0.37,\n",
       " 'min_samples_leaf': 5,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 80}"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_RF_2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "64508c48-9637-4e7e-9ae0-b4a6da8f4c30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8260355029585799, 0.7965941343424787, 0.7893242475865985)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_RF_2.score(X_train2, y_train2), grid_RF_2.score(X_eval2, y_eval2), grid_RF_2.score(X_test_OE, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507940dc-8140-4c0b-aa51-2ed304eca430",
   "metadata": {},
   "source": [
    "- X_train3&y_train3训练过程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3412f4db-67d4-44b6-b6b2-807ac60039ca",
   "metadata": {},
   "source": [
    "&emsp;&emsp;3号数据集超参数搜索过程如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "b084fc38-c7de-41f9-8b7e-7e3636a39eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "364.97769808769226\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# 设置超参数空间\n",
    "parameter_space = {\n",
    "    \"min_samples_leaf\": range(1, 4), \n",
    "    \"min_samples_split\": range(6, 9),\n",
    "    \"max_depth\": range(9, 12),\n",
    "    \"max_leaf_nodes\": [None] + list(range(10, 70, 20)), \n",
    "    \"n_estimators\": range(96, 99), \n",
    "    \"max_features\":['sqrt', 'log2'] + list(range(4, 7)),\n",
    "    \"max_samples\":[None] + list(range(1998, 2001))}\n",
    "\n",
    "# 实例化模型与评估器\n",
    "RF_3 = RandomForestClassifier(random_state=12)\n",
    "grid_RF_3 = GridSearchCV(RF_3, parameter_space, n_jobs=15)\n",
    "\n",
    "# 模型训练\n",
    "grid_RF_3.fit(X_train3, y_train3)\n",
    "\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "947bed4b-99a6-4ebf-b5a2-d862bfd5d96a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8130577587533399"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_RF_3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "48c69159-4158-4b18-ab5f-4ed7d2265b60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 10,\n",
       " 'max_features': 5,\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': 1999,\n",
       " 'min_samples_leaf': 2,\n",
       " 'min_samples_split': 7,\n",
       " 'n_estimators': 97}"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_RF_3.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "ee68aef2-6512-4d72-a01c-bceeadd6c3f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.862991008045433, 0.7964015151515151, 0.7853492333901193)"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_RF_3.score(X_train3, y_train3), grid_RF_3.score(X_eval3, y_eval3), grid_RF_3.score(X_test_OE, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a5f3e6-ac52-42a1-b04a-8add3fd21763",
   "metadata": {},
   "source": [
    "- X_train4&y_train4训练过程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df18a55-4615-4257-a27d-a92f8ac40227",
   "metadata": {},
   "source": [
    "&emsp;&emsp;4号数据集超参数搜索过程如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "bda00aff-9018-452e-936e-e1ef0a22f598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "319.0900549888611\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# 设置超参数空间\n",
    "parameter_space = {\n",
    "    \"min_samples_leaf\": range(4, 7), \n",
    "    \"min_samples_split\": range(1, 4),\n",
    "    \"max_depth\": range(9, 12),\n",
    "    \"max_leaf_nodes\": [None] + list(range(74, 77)), \n",
    "    \"n_estimators\": range(94, 97), \n",
    "    \"max_features\":['sqrt', 'log2'] + list(range(4, 8)), \n",
    "    \"max_samples\":[None, 0.459, 0.46, 0.461]}\n",
    "\n",
    "# 实例化模型与评估器\n",
    "RF_4 = RandomForestClassifier(random_state=12)\n",
    "grid_RF_4 = GridSearchCV(RF_4, parameter_space, n_jobs=15)\n",
    "\n",
    "# 模型训练\n",
    "grid_RF_4.fit(X_train4, y_train4)\n",
    "\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "a5ef5a45-172e-484b-b495-b00bdaaf6213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8116398785793221"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_RF_4.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "3d1766ed-089a-45c5-8c04-ea336f1d3aa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 10,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_leaf_nodes': 75,\n",
       " 'max_samples': 0.46,\n",
       " 'min_samples_leaf': 5,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 95}"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_RF_4.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "8aa6a15d-b342-4950-a53b-d8c0c8934b35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8338854708944629, 0.7982954545454546, 0.7887563884156729)"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_RF_4.score(X_train4, y_train4), grid_RF_4.score(X_eval4, y_eval4), grid_RF_4.score(X_test_OE, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb06a98d-1684-4bb9-89f4-135087129bf2",
   "metadata": {},
   "source": [
    "- X_train5&y_train5训练过程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d855eb5-b7c7-431d-8731-12880b26e336",
   "metadata": {},
   "source": [
    "&emsp;&emsp;5号数据集超参数搜索过程如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "5deacc63-828d-4ffd-8289-4a70828eeeb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "371.5700776576996\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# 设置超参数空间\n",
    "parameter_space = {\n",
    "    \"min_samples_leaf\": range(2, 5), \n",
    "    \"min_samples_split\": range(1, 4),\n",
    "    \"max_depth\": range(7, 10),\n",
    "    \"max_leaf_nodes\": [None] + list(range(10, 70, 20)), \n",
    "    \"n_estimators\": range(94, 97), \n",
    "    \"max_features\":['sqrt', 'log2'] + list(range(1, 7)),\n",
    "    \"max_samples\":[None] + list(range(2000, 2003))}\n",
    "\n",
    "# 实例化模型与评估器\n",
    "RF_5 = RandomForestClassifier(random_state=12)\n",
    "grid_RF_5 = GridSearchCV(RF_5, parameter_space, n_jobs=15)\n",
    "\n",
    "# 模型训练\n",
    "grid_RF_5.fit(X_train5, y_train5)\n",
    "\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "27768552-2e82-4432-9cc6-882b7d35b4cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8125841062011275"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_RF_5.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "825ba0ca-3d80-44ad-8c0c-c84fe43b624b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 8,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': 2001,\n",
       " 'min_samples_leaf': 3,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 95}"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_RF_5.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986dd157-1ab6-4deb-afaa-d7283fbe9ca2",
   "metadata": {},
   "source": [
    "#### 2.2 模型保存"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b1b491-7bdd-444c-916d-583eb051b84c",
   "metadata": {},
   "source": [
    "&emsp;&emsp;训练一组模型不易，但是严谨细致的模型训练却是保证融合效果的关键，如果完全是从第一轮搜索开始进行超参数优化，则上述五个模型的训练预计需要耗时（运行时间）4小时左右。因此在训练结束后，切记将模型进行本地保存："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "1ede28c5-fe35-4fdb-a5e0-2c0343335c0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['grid_RF_5.joblib']"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(grid_RF_1, 'grid_RF_1.joblib') \n",
    "dump(grid_RF_2, 'grid_RF_2.joblib') \n",
    "dump(grid_RF_3, 'grid_RF_3.joblib') \n",
    "dump(grid_RF_4, 'grid_RF_4.joblib') \n",
    "dump(grid_RF_5, 'grid_RF_5.joblib') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d4353a-08f0-4867-b8a2-e0408e7a674f",
   "metadata": {},
   "source": [
    "而后续在调用时，则可以通过如下语句进行调用："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "64121628-80f8-4f55-a625-d9534f081313",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_RF_1 = load('grid_RF_1.joblib') \n",
    "grid_RF_2 = load('grid_RF_2.joblib') \n",
    "grid_RF_3 = load('grid_RF_3.joblib') \n",
    "grid_RF_4 = load('grid_RF_4.joblib') \n",
    "grid_RF_5 = load('grid_RF_5.joblib') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e8e4e8-4551-49f4-911d-8703a49b4d28",
   "metadata": {},
   "source": [
    "同时，我们挑选模型（而非超参数优化器）放到一个列表中，方便后续进行调用："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "e56e9900-575f-4a93-aafb-85135a596c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_1 = grid_RF_1.best_estimator_\n",
    "RF_2 = grid_RF_2.best_estimator_\n",
    "RF_3 = grid_RF_3.best_estimator_\n",
    "RF_4 = grid_RF_4.best_estimator_\n",
    "RF_5 = grid_RF_5.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "50f3741e-de85-49ee-aa30-7a7910091f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_l = [RF_1, RF_2, RF_3, RF_4, RF_5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e0fd09-f6d5-45e5-bbaf-5d42b8e34513",
   "metadata": {},
   "source": [
    "#### 2.3 模型性能评估"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a54e78-cf46-40b1-8928-dd9454fd3ad5",
   "metadata": {},
   "source": [
    "&emsp;&emsp;接下来，我们可以简单测试这一组模型的表现。在模型训练过程中，我们看到了单独模型在训练集、验证集和测试集上的表现，但由于后续我们并不是要单独使用其中某个模型，而是综合这一组模型的结果进行判别，因此我们要对这一组5个模型的性能进行整体的评估。而评估的只要方法就是这5个模型在验证集上的表现。当然我们可以快速计算5个模型分别在验证集上得分的均值，基本过程如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "44ec9f36-f96b-4d9f-8c1e-9253d80f5d37",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8173065207419512"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5个验证集准确率均值计算过程\n",
    "eval_score = 0\n",
    "\n",
    "for i  in range(5):\n",
    "    X, y = eval_set[i]\n",
    "    eval_score += RF_l[i].score(X, y)\n",
    "    \n",
    "eval_score / 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4a16f7-c5df-48c8-af6b-984fe23ca5f3",
   "metadata": {},
   "source": [
    "&emsp;&emsp;能够发现，在信息训练集和测试集信息严格隔离的情况下，验证集的准确率有所下降。当然对于验证集的准确率计算，还有一种更加严谨的做法，是先将5个验证集拼凑成一个完整的“训练集”，然后这个“训练集”上的准确率。5个验证集拼凑成完整训练集过程如下："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f78a912-6d97-4dcb-a8c0-72e3b0706a98",
   "metadata": {},
   "source": [
    "<center><img src=\"https://s2.loli.net/2022/05/10/bPyRBSnD8ZwmQI9.png\" alt=\"image-20220510162151351\" style=\"zoom:50%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98099ea2-b0cd-4807-94eb-a1c6e154d3f6",
   "metadata": {},
   "source": [
    "这里我们首先输出每个验证集的预测结果，并将其保存为Series对象，并且每个Series的index就是验证集样本的index，方便后续进行拼接："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "bf15bd25-2b87-4fa1-b8c5-10c5469bfc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval1_predict_proba_RF = pd.Series(RF_l[0].predict_proba(X_eval1)[:, 1], index=X_eval1.index)\n",
    "eval2_predict_proba_RF = pd.Series(RF_l[1].predict_proba(X_eval2)[:, 1], index=X_eval2.index)\n",
    "eval3_predict_proba_RF = pd.Series(RF_l[2].predict_proba(X_eval3)[:, 1], index=X_eval3.index)\n",
    "eval4_predict_proba_RF = pd.Series(RF_l[3].predict_proba(X_eval4)[:, 1], index=X_eval4.index)\n",
    "eval5_predict_proba_RF = pd.Series(RF_l[4].predict_proba(X_eval5)[:, 1], index=X_eval5.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8e63bc-d231-478d-bf0f-d5a03203ce3a",
   "metadata": {},
   "source": [
    "然后拼接为一个完整的Series，并对index进行顺序排序："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "0d9f9b34-4bf4-41eb-912c-cc3ac0df1e8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.044787\n",
       "1       0.572187\n",
       "2       0.161815\n",
       "3       0.250871\n",
       "4       0.122533\n",
       "          ...   \n",
       "5277    0.082653\n",
       "5278    0.346562\n",
       "5279    0.551481\n",
       "5280    0.049011\n",
       "5281    0.002783\n",
       "Length: 5282, dtype: float64"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_predict_proba_RF = pd.concat([eval1_predict_proba_RF, \n",
    "                                   eval2_predict_proba_RF, \n",
    "                                   eval3_predict_proba_RF, \n",
    "                                   eval4_predict_proba_RF, \n",
    "                                   eval5_predict_proba_RF]).sort_index()\n",
    "\n",
    "eval_predict_proba_RF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b59c03-6290-46c6-bcee-322fed0d7d15",
   "metadata": {},
   "source": [
    "能够看到，拼接后的验证集长度和训练集样本数量相同，验证集“拼”成了一个完整的训练集。换个更加准确的说法，我们通过验证集获得了一个完整的训练集上预测结果。接下来我们以0.5为阈值，测试训练集（或者完整验证集）上准确率："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "dafe74a8-cbed-461a-ab46-db46fd7ad1a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8173040514956456"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score((eval_predict_proba_RF >= 0.5) * 1, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847d344e-209b-4bf3-8cbb-64b870ca2c01",
   "metadata": {},
   "source": [
    "准确率为0.8173。需要注意的是，5个验证集准确率的均值和上述结果略有差异，一般来说，出于严谨性考虑，同时也是为了后续加权融合代码更加便捷，建议采用后者进行一组模型效果整体评估。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62161e03-2aff-4c6d-81e4-5449760fb58b",
   "metadata": {},
   "source": [
    "> 对验证集的预测结果进行拼接也是Stacking方法要求的必要数据对象。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0eec25-5894-4b18-a06f-f382ce6894fe",
   "metadata": {},
   "source": [
    "> 这里有5个模型，并且要求最终输出一个结果，有没有想过对这五个模型进行加权融合？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c9b2ee-6d28-4a1e-b3b8-85fa1172aca9",
   "metadata": {},
   "source": [
    "&emsp;&emsp;当然，我们也可以尝试计算测试集上准确率，同样我们可以简单计算这5个模型在测试集上准确率的均值，计算过程如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c3aaec5e-a7d8-4813-a6db-c775e223a66e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7904599659284497"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_score = 0\n",
    "\n",
    "for i in range(5):\n",
    "    test_score += RF_l[i].score(X_test_OE, y_test)\n",
    "    \n",
    "test_score / 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce55888b-6545-4be4-91b8-9c6e667a2ecd",
   "metadata": {},
   "source": [
    "但是，这里需要注意的是，如果我们利用这样一组模型对测试数据进行预测，实际上的预测流程应该是软投票，即根据每个模型输出的概率结果求均值后以阈值0.5进行判断，基本过程如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "e12b9c9c-1486-44cd-9af2-6db1a177d1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict_proba_RF = []\n",
    "\n",
    "for i in range(5):\n",
    "    test_predict_proba_RF.append(RF_l[i].predict_proba(X_test_OE)[:, 1])\n",
    "\n",
    "test_predict_proba_RF = np.array(test_predict_proba_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "578857a9-1ed6-42a3-964c-f9e7ae5da6cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.93370391e-02, 2.49403422e-01, 2.83410667e-02, ...,\n",
       "        1.49452536e-01, 4.98110882e-01, 1.18764226e-01],\n",
       "       [4.61954631e-02, 2.45875467e-01, 3.00760027e-02, ...,\n",
       "        1.38993336e-01, 5.02889767e-01, 1.16184501e-01],\n",
       "       [2.00137393e-03, 4.16662468e-01, 4.90918017e-04, ...,\n",
       "        1.42216654e-01, 6.08904016e-01, 8.56019321e-02],\n",
       "       [3.59908839e-02, 3.22891626e-01, 1.62280766e-02, ...,\n",
       "        1.52682083e-01, 5.04891040e-01, 1.27421886e-01],\n",
       "       [2.25733214e-02, 3.25064759e-01, 6.08561589e-03, ...,\n",
       "        1.43386982e-01, 5.38634836e-01, 8.61879770e-02]])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predict_proba_RF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354ae8c2-1404-45f5-aca7-c4548b4ca895",
   "metadata": {},
   "source": [
    "然后按行求均值，即可计算每条测试数据的平均预测概率："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "bab93dc9-763a-4d3d-849d-eed5d5a0a359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02921962, 0.31197955, 0.01624434, ..., 0.14534632, 0.53068611,\n",
       "       0.1068321 ])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predict_proba_RF = test_predict_proba_RF.mean(0)\n",
    "test_predict_proba_RF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0745f55e-1f1f-4927-83ac-377afbd58150",
   "metadata": {},
   "source": [
    "计算最终准确率："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "9fd4d5e1-857d-4f66-b15d-21dbca35eef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7915956842703009"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score((test_predict_proba_RF>=0.5)*1, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d41bf5-0728-4c00-85be-aa785da1a95d",
   "metadata": {},
   "source": [
    "能够发现，两种结果略有差异。不过需要注意的是，随机森林交叉训练的这组模型平均测试集准确率比带入全部数据集训练得到的模型表现稍差，根本原因在于训练每个模型的数据量减少，导致模型本身判别效力有所下降。但是，单个模型判别效力的下降并不代表融合结果会更差，这点我们将在后面着重讨论。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4bea09-36e0-4624-bb52-011d21ea5012",
   "metadata": {},
   "source": [
    "|Models|eval_train_score|test_score|\n",
    "|:--:|:--:|:--:|\n",
    "|Logistic+grid|0.8104|0.7836|\n",
    "|tree+grid|0.7991|0.7683|\n",
    "|RF+grid|0.8104|0.7955|\n",
    "|RF_l|0.8173|0.7915|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025e8ea7-e2bd-4473-a631-72fda7e97cbf",
   "metadata": {},
   "source": [
    "#### 2.4 决策树交叉训练与效果测试"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7859d838-eba3-4523-95ec-0d15957e89e7",
   "metadata": {},
   "source": [
    "- 决策树模型训练"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8d8b65-7838-4ddc-8ff5-cb4fab900d34",
   "metadata": {},
   "source": [
    "&emsp;&emsp;决策树的超参数搜索过程较为简单快捷，因此可以设置一个较大的超参数搜索空间，循环带入5组训练数据，并分别训练与优化5个决策树模型。首先我们可以简单测试在一个较大的参数空间下训练和优化一个模型耗时："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "541b855b-844f-4e20-be4f-7725b7be20f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实例化决策树评估器\n",
    "tree_model = DecisionTreeClassifier()\n",
    "\n",
    "tree_param = {'max_depth': np.arange(2, 16, 1).tolist(), \n",
    "              'min_samples_split': np.arange(1, 5, 1).tolist(), \n",
    "              'min_samples_leaf': np.arange(1, 4, 1).tolist(), \n",
    "              'max_leaf_nodes':np.arange(6, 30, 1).tolist()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b8c2260a-575e-4122-86ab-87d5becd98fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实例化网格搜索评估器\n",
    "tree_search = GridSearchCV(estimator = tree_model,\n",
    "                           param_grid = tree_param,\n",
    "                           n_jobs = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "19a4ab56-bb0c-4adc-b901-67531ea92d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.22828483581543 s\n"
     ]
    }
   ],
   "source": [
    "# 在训练集上进行训练\n",
    "s = time.time()\n",
    "tree_search.fit(X_train2, y_train2)\n",
    "print(time.time()-s, \"s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c71833-9729-4339-9596-2b50eb8b1e10",
   "metadata": {},
   "source": [
    "然后即可循环带入五组数据进行训练："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1605f770-e027-4434-97ea-2ca18d3bb330",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:45<00:00,  9.11s/it]\n"
     ]
    }
   ],
   "source": [
    "tree_search_l = []\n",
    "\n",
    "for X, y in tqdm(train_set):\n",
    "    tree_model = DecisionTreeClassifier(random_state=12)\n",
    "    tree_search = GridSearchCV(estimator = tree_model,\n",
    "                               param_grid = tree_param,\n",
    "                               n_jobs = 12).fit(X, y)\n",
    "    tree_search_l.append(tree_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7fc54042-da7f-4e62-90e1-8f2bbc777519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tree_search_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbed8b4-9255-4e6b-8a34-bacb00e4b47a",
   "metadata": {},
   "source": [
    "&emsp;&emsp;这里需要注意，当我们训练完5个模型之后，需要每个模型单独查看其超参数是否在初始设置的范围内的，若超参数取值在搜索范围的便捷，则需要重新设置超参数搜索范围。这里展示的结果是已经验算多次后的结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa840f9-2bb8-4f28-957f-03a6e2ca5be0",
   "metadata": {},
   "source": [
    "- 决策树模型保存"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8d9a1e-d9e0-4d03-85a5-7f64e0b12435",
   "metadata": {},
   "source": [
    "&emsp;&emsp;在模型训练完成后，接下来即可对其进行本地保存："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e3798aea-f509-4954-a710-606d9a75ee96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['grid_tree_5.joblib']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(tree_search_l[0], 'grid_tree_1.joblib') \n",
    "dump(tree_search_l[1], 'grid_tree_2.joblib') \n",
    "dump(tree_search_l[2], 'grid_tree_3.joblib') \n",
    "dump(tree_search_l[3], 'grid_tree_4.joblib') \n",
    "dump(tree_search_l[4], 'grid_tree_5.joblib') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382fa8cd-6950-4137-99e9-c251708fb872",
   "metadata": {},
   "source": [
    "后续运行时，可以直接按照如下方式读取模型，以及将其保存为一个列表："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4ceda295-63fa-4d3a-83df-626b598308b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_tree_1 = load('grid_tree_1.joblib')\n",
    "grid_tree_2 = load('grid_tree_2.joblib')\n",
    "grid_tree_3 = load('grid_tree_3.joblib')\n",
    "grid_tree_4 = load('grid_tree_4.joblib')\n",
    "grid_tree_5 = load('grid_tree_5.joblib')\n",
    "\n",
    "tree_1 = grid_tree_1.best_estimator_\n",
    "tree_2 = grid_tree_2.best_estimator_\n",
    "tree_3 = grid_tree_3.best_estimator_\n",
    "tree_4 = grid_tree_4.best_estimator_\n",
    "tree_5 = grid_tree_5.best_estimator_\n",
    "\n",
    "tree_l = [tree_1, tree_2, tree_3, tree_4, tree_5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d4e1e7-9eb0-49a6-9b3a-bf2907c35c7a",
   "metadata": {},
   "source": [
    "- 验证集效果测试"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1606c227-d0c1-4362-b2f1-b59fd6cdc4e6",
   "metadata": {},
   "source": [
    "&emsp;&emsp;接下来继续按照此前介绍的方法，构建一个基于验证集的完整训练集预测结果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "15de50a3-7ce4-47dc-bb4b-af42eedf603d",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval1_predict_proba_tree = pd.Series(tree_l[0].predict_proba(X_eval1)[:, 1], index=X_eval1.index)\n",
    "eval2_predict_proba_tree = pd.Series(tree_l[1].predict_proba(X_eval2)[:, 1], index=X_eval2.index)\n",
    "eval3_predict_proba_tree = pd.Series(tree_l[2].predict_proba(X_eval3)[:, 1], index=X_eval3.index)\n",
    "eval4_predict_proba_tree = pd.Series(tree_l[3].predict_proba(X_eval4)[:, 1], index=X_eval4.index)\n",
    "eval5_predict_proba_tree = pd.Series(tree_l[4].predict_proba(X_eval5)[:, 1], index=X_eval5.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79b67df-036d-446c-9099-d5b090abf6b8",
   "metadata": {},
   "source": [
    "然后拼接为一个完整的Series，并对index进行顺序排序："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "39cb8c62-6d48-4fa4-bb5e-bc357d9dcf87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.037669\n",
       "1       0.787986\n",
       "2       0.222819\n",
       "3       0.259434\n",
       "4       0.107345\n",
       "          ...   \n",
       "5277    0.062959\n",
       "5278    0.222819\n",
       "5279    0.438538\n",
       "5280    0.066419\n",
       "5281    0.026367\n",
       "Length: 5282, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_predict_proba_tree = pd.concat([eval1_predict_proba_tree, \n",
    "                                     eval2_predict_proba_tree, \n",
    "                                     eval3_predict_proba_tree, \n",
    "                                     eval4_predict_proba_tree, \n",
    "                                     eval5_predict_proba_tree]).sort_index()\n",
    "\n",
    "eval_predict_proba_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e69be8-a01a-438b-9b83-8a2bf6152d94",
   "metadata": {},
   "source": [
    "最后计算准确率："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f1adac2a-7bd4-4bfa-b05c-2fd263b4dd3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7913669064748201"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score((eval_predict_proba_tree >= 0.5) * 1, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31729084-4478-4f3b-ac02-7acc26957698",
   "metadata": {},
   "source": [
    "同时测试这组决策树模型在测试集上的准确率："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6a541192-363e-4389-8393-496d97f5d714",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict_proba_tree = []\n",
    "\n",
    "for i in range(5):\n",
    "    test_predict_proba_tree.append(tree_l[i].predict_proba(X_test_OE)[:, 1])\n",
    "\n",
    "test_predict_proba_tree = np.array(test_predict_proba_tree)\n",
    "test_predict_proba_tree = test_predict_proba_tree.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aee9984b-3301-470c-a2a4-8ae1de870f03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04647312, 0.15890043, 0.04647312, ..., 0.15890043, 0.43740054,\n",
       "       0.1303992 ])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predict_proba_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e747b2-77a2-4eb9-abb9-509af896dc56",
   "metadata": {},
   "source": [
    "计算最终准确率："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7d0d7770-6fd7-4b0f-82a1-600293d2a1ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7745599091425327"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score((test_predict_proba_tree>=0.5)*1, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfce3da-5f7e-4fa2-bf76-28852d7fccd7",
   "metadata": {},
   "source": [
    "非常有趣的是，决策树模型在经过交叉训练后得到的测试集上平均准确率会比单独更高。这里我们可以简单思考其背后的原因。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a3d489-41a7-4d3d-a11f-ecab03d9d4c0",
   "metadata": {},
   "source": [
    "&emsp;&emsp;其实不难发现，整个交叉训练模型的过程其实就非常类似于抽取自助集然后进行Bagging集成，只不过这里没有更进一步为不同的树分配不同的特征，否则就是一个简单的随机森林模型了。此外，决策树本身稳定性较差，样本上的差异就能构成模型结果的较大差异，因此会非常适合Bagging集成，几棵树的集成就能立竿见影看到效果。而反观随机森林，其本身学习能力较强、稳定性也非常强，因此简单的交叉训练并不能造成模型之间非常明显的差异，反而因为样本量的减少较大程度上影响了随机森林模型的学习效果，导致整体判别能力下降。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9b2f6e-4f35-4fde-b229-427935491b2e",
   "metadata": {},
   "source": [
    "|Models|eval_train_score|test_score|\n",
    "|:--:|:--:|:--:|\n",
    "|Logistic+grid|0.8104|0.7836|\n",
    "|tree+grid|0.7991|0.7683|\n",
    "|tree_l|0.7913|<font color=\"red\">**0.7745(↑)**</font>|\n",
    "|RF+grid|0.8104|0.7955|\n",
    "|RF_l|0.8173|<font color=\"green\">**0.7915(↓)**</font>|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d686dcfd-c561-419a-8bef-10770a14ed08",
   "metadata": {},
   "source": [
    "> 当然，从这个结果也能看出为何决策树“容易集成”，而随机森林“难以集成”。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ae12d9-dbfb-40dd-9930-62fe9009b9fd",
   "metadata": {},
   "source": [
    "#### 2.5 逻辑回归交叉训练与效果测试"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8737be-a5f3-44e0-94fe-1f2818b2110f",
   "metadata": {},
   "source": [
    "- 逻辑回归交叉训练"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9e689b-b182-4e00-9685-45b1bdf12a1c",
   "metadata": {},
   "source": [
    "&emsp;&emsp;和决策树的交叉训练类似，这里我们同样批量交叉训练5个逻辑回归模型，过程如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "id": "6bc2e6a2-3de7-4a18-9710-f19070965288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置超参数空间\n",
    "logistic_param = [\n",
    "    {'columntransformer__num':num_pre, 'logit_threshold__thr': np.arange(0.1, 1, 0.1).tolist(), 'logit_threshold__penalty': ['l1'], 'logit_threshold__C': np.arange(0.1, 1.1, 0.1).tolist(), 'logit_threshold__solver': ['saga']}, \n",
    "    {'columntransformer__num':num_pre, 'logit_threshold__thr': np.arange(0.1, 1, 0.1).tolist(), 'logit_threshold__penalty': ['l2'], 'logit_threshold__C': np.arange(0.1, 1.1, 0.1).tolist(), 'logit_threshold__solver': ['lbfgs', 'newton-cg', 'sag', 'saga']}, \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "id": "dbd03aea-ec58-442f-bffb-b6aaf7d5c42c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [19:24<00:00, 232.80s/it]\n"
     ]
    }
   ],
   "source": [
    "lr_search_l = []\n",
    "\n",
    "num_pre = ['passthrough', \n",
    "           preprocessing.StandardScaler(), \n",
    "           preprocessing.KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='kmeans')]\n",
    "\n",
    "for X, y in tqdm(train_set):\n",
    "    # 实例化相关评估器\n",
    "    logistic_model = logit_threshold(max_iter=int(1e6))\n",
    "    logistic_pre = ColumnTransformer([('cat', preprocessing.OneHotEncoder(drop='if_binary'), category_cols), \n",
    "                                      ('num', 'passthrough', numeric_cols)])\n",
    "    # 构造机器学习流\n",
    "    logistic_pipe = make_pipeline(logistic_pre, logistic_model)\n",
    "    # 执行网格搜索\n",
    "    logistic_search = GridSearchCV(estimator = logistic_pipe,\n",
    "                                   param_grid = logistic_param,\n",
    "                                   scoring='accuracy',\n",
    "                                   n_jobs = 15).fit(X, y)\n",
    "    lr_search_l.append(logistic_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "id": "712eb4ba-4b3f-4748-b627-b069f8c5a3a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 594,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lr_search_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22287156-4c1c-4624-b371-7ea31ac7eec2",
   "metadata": {},
   "source": [
    "- 模型保存与读取"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4154a0b0-9c1e-47b2-b6bb-cf05adf578de",
   "metadata": {},
   "source": [
    "&emsp;&emsp;同样，我们对训练好的这批逻辑回归模型进行本地保存："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "id": "07cbb578-4c4e-49b9-924c-b76655b861ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['grid_lr_5.joblib']"
      ]
     },
     "execution_count": 595,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(lr_search_l[0], 'grid_lr_1.joblib') \n",
    "dump(lr_search_l[1], 'grid_lr_2.joblib') \n",
    "dump(lr_search_l[2], 'grid_lr_3.joblib') \n",
    "dump(lr_search_l[3], 'grid_lr_4.joblib') \n",
    "dump(lr_search_l[4], 'grid_lr_5.joblib') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84b261a-f5a5-4105-903d-a2f2fc79558f",
   "metadata": {},
   "source": [
    "后续可以直接按照下述方法进行读取，同时将模型保存为一个列表："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6a685d34-f4b2-4996-a748-bc3c535491b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_lr_1 = load('grid_lr_1.joblib')\n",
    "grid_lr_2 = load('grid_lr_2.joblib')\n",
    "grid_lr_3 = load('grid_lr_3.joblib')\n",
    "grid_lr_4 = load('grid_lr_4.joblib')\n",
    "grid_lr_5 = load('grid_lr_5.joblib')\n",
    "\n",
    "lr_1 = grid_lr_1.best_estimator_\n",
    "lr_2 = grid_lr_2.best_estimator_\n",
    "lr_3 = grid_lr_3.best_estimator_\n",
    "lr_4 = grid_lr_4.best_estimator_\n",
    "lr_5 = grid_lr_5.best_estimator_\n",
    "\n",
    "lr_l = [lr_1, lr_2, lr_3, lr_4, lr_5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d369c04f-384d-48f1-a493-1f7e483abc77",
   "metadata": {},
   "source": [
    "- 模型效果测试"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ba7aa8-e0c7-4af2-8f2a-42e33a023173",
   "metadata": {},
   "source": [
    "&emsp;&emsp;接下来进一步测试逻辑回归模型组的效果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7eb1346a-8541-4b58-b0d6-7ec1f32a6999",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval1_predict_proba_lr = pd.Series(lr_l[0].predict_proba(X_eval1)[:, 1], index=X_eval1.index)\n",
    "eval2_predict_proba_lr = pd.Series(lr_l[1].predict_proba(X_eval2)[:, 1], index=X_eval2.index)\n",
    "eval3_predict_proba_lr = pd.Series(lr_l[2].predict_proba(X_eval3)[:, 1], index=X_eval3.index)\n",
    "eval4_predict_proba_lr = pd.Series(lr_l[3].predict_proba(X_eval4)[:, 1], index=X_eval4.index)\n",
    "eval5_predict_proba_lr = pd.Series(lr_l[4].predict_proba(X_eval5)[:, 1], index=X_eval5.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83624df6-0463-4de3-bf9c-9b4493cc4dc8",
   "metadata": {},
   "source": [
    "然后拼接为一个完整的Series，并对index进行顺序排序："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e26e8b16-817c-49a9-8b90-53f529443f87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.011289\n",
       "1       0.542331\n",
       "2       0.154121\n",
       "3       0.273393\n",
       "4       0.158399\n",
       "          ...   \n",
       "5277    0.083575\n",
       "5278    0.365228\n",
       "5279    0.674365\n",
       "5280    0.050536\n",
       "5281    0.005250\n",
       "Length: 5282, dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_predict_proba_lr = pd.concat([eval1_predict_proba_lr, \n",
    "                                   eval2_predict_proba_lr, \n",
    "                                   eval3_predict_proba_lr, \n",
    "                                   eval4_predict_proba_lr, \n",
    "                                   eval5_predict_proba_lr]).sort_index()\n",
    "\n",
    "eval_predict_proba_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680d009b-96ab-4fdc-983f-0d41eabf0822",
   "metadata": {},
   "source": [
    "最后测试准确率："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ff67d64a-e8a3-4834-b8da-26892cb638b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8087845513063233"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score((eval_predict_proba_lr >= 0.5) * 1, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b50aa91-3e56-4b19-abe8-3096792b7c4b",
   "metadata": {},
   "source": [
    "同时测试逻辑回归模型组在测试集上的准确率："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6a71015e-ba8a-46c5-9fed-35686f34029a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict_proba_lr = []\n",
    "\n",
    "for i in range(5):\n",
    "    test_predict_proba_lr.append(lr_l[i].predict_proba(X_test_OE)[:, 1])\n",
    "\n",
    "test_predict_proba_lr = np.array(test_predict_proba_lr)\n",
    "test_predict_proba_lr = test_predict_proba_lr.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "27370858-7e31-4e91-8352-65b97538603d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.045946  , 0.2337113 , 0.00519206, ..., 0.12532499, 0.5019908 ,\n",
       "       0.0627869 ])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predict_proba_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd68c757-9357-45f7-95f0-7ea0a0940e03",
   "metadata": {},
   "source": [
    "计算最终准确率："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "be8c84c2-4a76-47c7-8a94-663332d924bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7887563884156729"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score((test_predict_proba_lr>=0.5)*1, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83aafd1-f7e1-4726-9c93-83b7e2516e53",
   "metadata": {},
   "source": [
    "能够看出，和决策树类似，逻辑回归通过这个交叉训练的过程，最终集成的效果也有所提升。不过也是因为带有正则化项的逻辑回归较为稳定，因此提升幅度并不服决策树提升幅度这么大。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017abfff-48d0-480d-9c72-1afc12bcb8f6",
   "metadata": {},
   "source": [
    "|Models|eval_train_score|test_score|\n",
    "|:--:|:--:|:--:|\n",
    "|Logistic+grid|0.8104|0.7836|\n",
    "|lr_l|0.8087|<font color=\"red\">**0.7887(↑)**</font>|\n",
    "|tree+grid|0.7991|0.7683|\n",
    "|tree_l|0.7913|<font color=\"red\">**0.7745(↑)**</font>|\n",
    "|RF+grid|0.8104|0.7955|\n",
    "|RF_l|0.8173|<font color=\"green\">**0.7915(↓)**</font>|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89285403-3846-40ec-a82e-6b6114d7210f",
   "metadata": {},
   "source": [
    "&emsp;&emsp;当然我们创建这三组模型，并不是为了让其平均投票以实现类似Bagging的集成过程，而是采用更加灵活的融合策略，获得一个更好的模型融合结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f649b849-b21b-42a1-a352-7f32c0212b9d",
   "metadata": {},
   "source": [
    "### 3.基于交叉训练的融合权重搜索"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba287d8a-8bbc-491a-8435-8cc390818dfa",
   "metadata": {},
   "source": [
    "- 基础流程测试"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e80ec50-e912-417b-9704-f555d49446a0",
   "metadata": {},
   "source": [
    "&emsp;&emsp;在训练了3组验证集信息严格隔离的模型后，接下来让我们回到权重搜索的问题上来：即测试在验证集信息严格隔离的情况下，能否搜索得到一组更优的融合权重。TPE的搜索过程此前已经尝试过多次，基本流程并不复杂，但面对训练的“多组”模型，我们应该如何确定某组权重和阈值的表现呢？此前的搜索过程都是基于验证集的平均准确率来判断，但此时我们通过手动划分数据集进行交叉计算，已经得到了一组信息完全隔离的、基于验证集的、完整的训练集上的预测结果，需要注意的是，该预测结果会比此前介绍的验证集的均值更能代表模型的泛化能力，因此我们接下来就以每一组模型输出的（基于验证集的）训练集上的预测结果来进行权重搜索，该计算流程的基本流程图如下："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09919d52-4889-470b-9867-78ed7b66ee05",
   "metadata": {},
   "source": [
    "<center><img src=\"https://s2.loli.net/2022/05/23/ZJs9oHAFQ2wa8Vt.png\" alt=\"image-20220523213524224\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80750e4a-3d43-4b86-b31c-c1f3c20da771",
   "metadata": {},
   "source": [
    "例如，在一组10:1:100的权重时，阈值为0.5时，加权融合预测过程如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "174c843f-f5f0-42d3-94be-880b5b99a34e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8053767512305945"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = [10, 1, 100]\n",
    "thr = 0.5\n",
    "\n",
    "weight1 = weights[0]\n",
    "weight2 = weights[1]\n",
    "weight3 = weights[2]\n",
    "\n",
    "weights_sum = weight1 + weight2 + weight3\n",
    "\n",
    "predict_probo_weight = (eval_predict_proba_lr * weight1 + \n",
    "                        eval_predict_proba_tree * weight2 + \n",
    "                        eval_predict_proba_RF * weight3) / weights_sum\n",
    "\n",
    "res_weight = (predict_probo_weight >= thr) * 1\n",
    "\n",
    "accuracy_score(res_weight, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51901a36-d338-45cc-b721-f6268c61809c",
   "metadata": {},
   "source": [
    "- 全域搜索"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99444f4-ae08-4634-bd83-3fa4a0dd11c7",
   "metadata": {},
   "source": [
    "&emsp;&emsp;据此，我们就可以进一步制定TPE超参数搜索流程，基本过程如下。需要注意的是，由于本轮模型训练过程中，我们进行了非常严格的信息隔离，因此验证集上的表现应该能够较好的衡量模型泛化能力，因此我们先尝试不对搜索空间进行裁剪，测试这个权重和阈值的搜索过程是否还会有严重的过拟合倾向："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "1a191c95-aa40-444c-81ee-b7f32b5885b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义超参数空间\n",
    "params_space = {'thr': hp.uniform(\"thr\", 0.4, 0.6), \n",
    "                'weight1': hp.uniform(\"weight1\",0,1),\n",
    "                'weight2': hp.uniform(\"weight2\",0,1),\n",
    "                'weight3': hp.uniform(\"weight3\",0,1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "effe80db-b1d0-4e48-b98b-fc6173928b9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 定义目标函数\n",
    "def hyperopt_objective_weight(params):\n",
    "    thr = params['thr']\n",
    "    weight1 = params['weight1']\n",
    "    weight2 = params['weight2']\n",
    "    weight3 = params['weight3']\n",
    "    \n",
    "    weights_sum = weight1 + weight2 + weight3\n",
    "\n",
    "    predict_probo_weight = (eval_predict_proba_lr * weight1 + \n",
    "                            eval_predict_proba_tree * weight2 + \n",
    "                            eval_predict_proba_RF * weight3) / weights_sum\n",
    "\n",
    "    res_weight = (predict_probo_weight >= thr) * 1\n",
    "\n",
    "    eval_score = accuracy_score(res_weight, y_train)\n",
    "    \n",
    "    return -eval_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "a016c082-14c4-4f77-9acc-f3c5ae36c802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义优化函数\n",
    "def param_hyperopt_weight(max_evals):\n",
    "    params_best = fmin(fn = hyperopt_objective_weight,\n",
    "                       space = params_space,\n",
    "                       algo = tpe.suggest,\n",
    "                       max_evals = max_evals, \n",
    "                       rstate = np.random.default_rng(17))    \n",
    "    return params_best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05c026b-24dc-44c2-b2ec-c3b4079d2e18",
   "metadata": {},
   "source": [
    "这里需要注意，由于我们带入的是验证集上的结果直接进行计算，因此整体搜索效率要比VotingClassifier+cross_val_score效率高很多。搜索完成后即可查看搜索结果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "0487e822-51ef-4d45-957f-2cc47ed0742c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 5000/5000 [01:39<00:00, 50.50trial/s, best loss: -0.8199545626656569]\n"
     ]
    }
   ],
   "source": [
    "params_best = param_hyperopt_weight(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "2453dd3e-daff-4d97-9ae2-99fade766e3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'thr': 0.46902429302219506,\n",
       " 'weight1': 0.03440652839563954,\n",
       " 'weight2': 0.030945060261316243,\n",
       " 'weight3': 0.9086713560495386}"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab578ed-1b45-4150-a6fb-1be75b449cdc",
   "metadata": {},
   "source": [
    "&emsp;&emsp;能够看出，在设置了相同的搜索空间时，搜索结果中分配给了随机森林模型组非常大的权重，而逻辑回归模型组和决策树模型组权重类似，且数值非常小，该权重分配结果和各模型组在验证集上的表现一致——即验证集表现越好的模型权重越高。此时，如果验证集上的模型表现是可信的话，那么最终将会得到一个不错的融合结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c231313d-ddd2-411f-9a11-9e9957631be8",
   "metadata": {},
   "source": [
    "&emsp;&emsp;接下来，我们需要测试该加权融合过程在测试集上的表现，类似的我们可以创建一个函数来完成该过程，并且和此前一样，测试集上的得分是三组模型的加权平均，并且每一组模型输出的测试集评分就是简单的组内5个模型预测概率的均值，也就是此前创建的test_predict_proba_lr、test_predict_proba_tree和test_predict_proba_RF。测试集评分计算过程如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "2de8762a-93d4-4ef3-997f-2ae325b11712",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_acc(params_best):\n",
    "    thr = params_best['thr']\n",
    "    weight1 = params_best['weight1']\n",
    "    weight2 = params_best['weight2']\n",
    "    weight3 = params_best['weight3']\n",
    "\n",
    "    weights_sum = weight1 + weight2 + weight3\n",
    "\n",
    "    test_predict_proba = (((test_predict_proba_lr * weight1 + \n",
    "                            test_predict_proba_tree * weight2 + \n",
    "                            test_predict_proba_RF * weight3) / weights_sum) >= thr) * 1\n",
    "\n",
    "    print(accuracy_score(test_predict_proba, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55937777-6f47-4c30-916c-1d57f3791c41",
   "metadata": {},
   "source": [
    "然后计算测试集上的准确率："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "52a8c205-d0ca-4b44-ada5-73eb1af20969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.797274275979557\n"
     ]
    }
   ],
   "source": [
    "test_acc(params_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b38c43c-a1d8-4e28-b9ec-367ca331feae",
   "metadata": {},
   "source": [
    "能够发现，此时融合结果达到了0.797，该结果也是目前我们在不裁剪超参数搜索空间下获得的最佳结果，同时也验证了训练集和验证集的信息严格隔离对模型泛化能力的提升是有明显作用的。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89063ab0-ff36-4f78-afb5-b87cd7f1332e",
   "metadata": {},
   "source": [
    "|Models|eval_train_score|test_score|\n",
    "|:--:|:--:|:--:|\n",
    "|Logistic+grid|0.8104|0.7836|\n",
    "|lr_l|0.8087|<font color=\"red\">**0.7887(↑)**</font>|\n",
    "|tree+grid|0.7991|0.7683|\n",
    "|tree_l|0.7913|<font color=\"red\">**0.7745(↑)**</font>|\n",
    "|RF+grid|0.8104|0.7955|\n",
    "|RF_l|0.8173|<font color=\"green\">**0.7915(↓)**</font>|\n",
    "|weight_search_auto|0.8199|<font color=\"red\">**0.7972(↑)**</font>|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1192f4b2-3f8f-4604-a73b-c1c1933cacfa",
   "metadata": {},
   "source": [
    "同时，该融合结果也显著好于所有参与融合的模型组在测试集上的效果，也能看出模型融合方法的实际效果。并且，相比经验法+搜索空间裁剪的方法，上述基于交叉训练的加权融合过程会更加稳定的输出一个较好的结果，我们无需根据经验进行大量反复尝试，只需要按部就班的训练好一组组模型，然后设置一个较大的迭代次数进行TPE搜索即可。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d560fbbb-db7e-4a28-98c9-6aa528ff9855",
   "metadata": {},
   "source": [
    "- 硬投票效果测试"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f785c2d8-2958-4d2a-9393-17afcb00b41a",
   "metadata": {},
   "source": [
    "&emsp;&emsp;在加权软投票得到了一个不错的结果之后，接下来我们继续尝试加权硬投票。不过，由于加权硬投票在中间将概率值转化为投票结果的过程会损失掉很多有效信息，因此在绝大多数情况下，加权硬投票效果会“稳定的弱于”加权软投票，这里我们可以简单测试加权硬投票的效果："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af536c15-063c-4fec-b0af-49eae75ee4fc",
   "metadata": {},
   "source": [
    "&emsp;&emsp;首先是将概率结果转化为投票结果，需要输出验证集投票结果和测试集投票结果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "0b221f9a-e84b-4c20-92f3-6aa54cf0d1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_predict_lr = (eval_predict_proba_lr >= 0.5) * 1\n",
    "eval_predict_tree = (eval_predict_proba_tree >= 0.5) * 1\n",
    "eval_predict_RF = (eval_predict_proba_RF >= 0.5) * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "8b2cb154-1f39-434a-afec-d99ef7c5aa34",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict_lr = (test_predict_proba_lr >= 0.5) * 1\n",
    "test_predict_tree = (test_predict_proba_tree >= 0.5) * 1\n",
    "test_predict_RF = (test_predict_proba_RF >= 0.5) * 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aed184d-25fe-460b-a876-58ccde9969b6",
   "metadata": {},
   "source": [
    "然后仍然是在验证集投票结果上进行搜索："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "186d4053-127c-49d1-b48a-f99f561a0d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义超参数空间\n",
    "params_space = {'thr': hp.uniform(\"thr\", 0.4, 0.6), \n",
    "                'weight1': hp.uniform(\"weight1\",0,1),\n",
    "                'weight2': hp.uniform(\"weight2\",0,1),\n",
    "                'weight3': hp.uniform(\"weight3\",0,1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "c11c17d8-e4ad-422f-871b-ffa44c032512",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 定义目标函数\n",
    "def hyperopt_objective_weight(params):\n",
    "    thr = params['thr']\n",
    "    weight1 = params['weight1']\n",
    "    weight2 = params['weight2']\n",
    "    weight3 = params['weight3']\n",
    "    \n",
    "    weights_sum = weight1 + weight2 + weight3\n",
    "\n",
    "    predict_probo_weight = (eval_predict_lr * weight1 + \n",
    "                            eval_predict_tree * weight2 + \n",
    "                            eval_predict_RF * weight3) / weights_sum\n",
    "\n",
    "    res_weight = (predict_probo_weight >= thr) * 1\n",
    "\n",
    "    eval_score = accuracy_score(res_weight, y_train)\n",
    "    \n",
    "    return -eval_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "086ba95d-bf2f-4f2a-b90f-9cacd6e2f138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义优化函数\n",
    "def param_hyperopt_weight(max_evals):\n",
    "    params_best = fmin(fn = hyperopt_objective_weight,\n",
    "                       space = params_space,\n",
    "                       algo = tpe.suggest,\n",
    "                       max_evals = max_evals, \n",
    "                       rstate = np.random.default_rng(17))    \n",
    "    return params_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "f830e3f9-6b32-4c36-9c40-0d2bc8bf1506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 5000/5000 [01:41<00:00, 49.06trial/s, best loss: -0.8173040514956456]\n"
     ]
    }
   ],
   "source": [
    "params_best = param_hyperopt_weight(5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d080195c-1478-4aea-8700-c94732278514",
   "metadata": {},
   "source": [
    "搜索出一组最佳权重后带入测试集测试效果，能发现，硬投票的验证集和测试集上的融合结果都明显低于软投票的结果。因此，在加权投票融合的过程中，可以优先考虑加权软投票。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "c360273e-cc27-4563-a38a-44b9ef955950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7915956842703009\n"
     ]
    }
   ],
   "source": [
    "thr = params_best['thr']\n",
    "weight1 = params_best['weight1']\n",
    "weight2 = params_best['weight2']\n",
    "weight3 = params_best['weight3']\n",
    "\n",
    "weights_sum = weight1 + weight2 + weight3\n",
    "\n",
    "test_predict_proba = (((test_predict_lr * weight1 + \n",
    "                        test_predict_tree * weight2 + \n",
    "                        test_predict_RF * weight3) / weights_sum) >= thr) * 1\n",
    "\n",
    "print(accuracy_score(test_predict_proba, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40547810-88d2-419b-adcd-abe2e92f092a",
   "metadata": {},
   "source": [
    "&emsp;&emsp;至此，我们就完成了完整的基于交叉训练的权重搜索融合的全过程。接下来，我们将进一步探讨这个流程的优化方法。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
