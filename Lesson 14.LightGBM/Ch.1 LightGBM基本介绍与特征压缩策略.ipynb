{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ae4de2e-4784-4861-911a-ed8bade3d34d",
   "metadata": {},
   "source": [
    "# <center> LightGBM原理与实践"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d7c10a-f070-4ced-b9f8-0f7baf54f2a8",
   "metadata": {},
   "source": [
    "- 高阶集成学习算法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3675dc4-f52a-4145-922b-5ce5917f666e",
   "metadata": {},
   "source": [
    "&emsp;&emsp;在学习了一系列梯度提升树的改进算法后，接下来，我们将进入到更加前沿的集成学习算法中，即LightGBM算法（全称为Light Gradient Boosting Machine，以下简称LGBM算法）和CatBoost算法（全称为Categorical Boosting）的学习中。和XGBoost算法（以下简称XGB算法）类似，这两个算法也是GBDT的改进算法，并且由于这两个算法诞生时间更晚，因此相比之下，LGBM和CatBoost拥有更多功能上的优化，以便应对更加复杂的当前机器学习应用情况。例如，相比XGB，LGBM有更高效的计算效率和更低的内存占用，并且面对高维数据，LGBM算法拥有更好的过拟合特性，这使得在建模数据量日趋增加的今天，LGBM会更适合作为前期探索性建模的模型（Baseline模型），并且在具体建模效果上，对比XGB也是不遑多让。而CatBoost算法同样在训练效率上比XGB更快，并且更加自动化——在特征衍生和超参数优化已经成为机器学习模型训练标配的今天，CatBoost能够（一定程度上）实现对输入的特征进行自动特征衍生和对超参数进行自动超参数优化。不难看出，LGBM和CatBoost是诞生于新应用环境中的新型集成学习算法，而对LGBM和CatBoost算法的学习，也成为了当今算法工程师的必修课。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a1f182-d3b6-4f21-aba3-9503478c7bb5",
   "metadata": {},
   "source": [
    "&emsp;&emsp;不过同样需要说明的是，尽管LGBM和CatBoost算法对比XGB有诸多方面的优化，但这并不代表这两种算法相比XGB具有全方位的效果优势。在真实的实战应用，XGB（甚至是随机森林）仍然具有非常高的实践价值，很多时候我们需要尝试多种不同类型的算法，才能获得一个更好的结果。并且，由RF、XGB、LGBM、CatBoost属于“强而不同”的算法，这会导致这些模型结果会非常适合进行更进一步的模型融合，以达到更好的效果，因此在大多数追求极致建模效果的场景下，这些模型都需要训练，并得到一个尽可能好的结果，然后再进行融合。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949e0e45-2895-476e-9652-4cb91d532204",
   "metadata": {},
   "source": [
    "> 而相比其他集成学习算法，例如Bagging、AdaBoost等，RF、XGB、LGBM和CatB可以说是有全方位的效果优势，因此，除非是某些特殊场景，否则一般不会优先考虑使用这些算法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afca1a3-e139-42d2-98b9-612396cf1579",
   "metadata": {},
   "source": [
    "- LightGBM算法简介"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8267523-357e-4ca6-bbaa-856da8fed479",
   "metadata": {},
   "source": [
    "&emsp;&emsp;LightGBM 是一种高效的 Gradient Boosting 算法，由 Microsoft Research Asia 团队开发，早期为Microsoft内部处理海量高维数据的专用算法，并于2017年由Guolin Ke, Qi Meng, Thomas Finley等人通过论文形式正式发布。如果说XGB为GBDT类算法在提升计算精度上做出了里程碑式的突破，那么LGBM则是在计算效率和内存优化上提出了开创性的解决方案，一举将GBDT类算法计算效率提高了近20倍、并且计算内存占用减少了80%，这也最终使得GBDT类算法、这一机器学习领域目前最高精度的预测类算法，能够真正应用于海量数据的建模预测。以下是官网给出的XGB、基于直方图优化的XGB和LGBM算法的在相同计算任务下计算时间的对比："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4928998d-e324-423d-86c4-c0a98f4b29ec",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202304081540395.png\" alt=\"0a747b1752ff4c7c9b368d7415b398c\" style=\"zoom:40%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb817f0c-a7ad-4072-9b63-e903b416189d",
   "metadata": {},
   "source": [
    "而在内存占用方面，LGBM算法的优势也同样非常明显，以下是相同计算任务下不同算法的内存占用对比："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d7ead8-0ad6-4b14-ab99-4835a8a13a91",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202304081540578.png\" alt=\"a884b5b53ebd9665f526b82d74ca56b\" style=\"zoom:40%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0304233d-614d-45f9-b5cb-79a138e34d91",
   "metadata": {},
   "source": [
    "> XGBoost_hist 是在 LightGBM 提出之后，针对 XGBoost 的一种优化。XGBoost_hist 是 XGBoost 的一种变体，使用了直方图近似的技术。XGBoost_hist是受到了 LightGBM 的启发，LightGBM 则是第一个广泛使用直方图近似技术的梯度提升决策树算法。课程中将详细介绍这种直方图优化算法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a7202d-4c78-44cc-94be-bd472431c0c3",
   "metadata": {},
   "source": [
    "而与此同时，LGBM能够保持和XGB几乎一样的预测精度，相同计算任务三种算法计算准确率如下："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8648534b-bddd-49a8-91b4-7bd1be95e83b",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202304081550947.png\" alt=\"1680940216389\" style=\"zoom:40%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca137db-5a22-452c-acf7-346e25418c47",
   "metadata": {},
   "source": [
    "不难发现，预测精准而计算过程高效，这也是Light一词的核心精髓，并且经过这么多年的实践验证，可以说目前来看，LightGBM已然成为处理海量数据最高效、最通用的机器学习算法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ec7c3a-df12-4cda-8b03-718040fd0079",
   "metadata": {},
   "source": [
    "- LightGBM算法相关论文"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f0b31b-e905-4f5f-a75a-ecf3004a0c31",
   "metadata": {},
   "source": [
    "&emsp;&emsp;对于新兴机器学习算法，最权威的介绍材料毫无疑问就是提出者发布的相关论文，这里我们重点推荐开发团队在2017年提出LGBM原理论文以及2019年由Essam Al Daoud提出的算法性能对比论文，两篇论文介绍及地址如下："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a49c768-8b28-49ab-a547-8ea063d4165d",
   "metadata": {},
   "source": [
    "&emsp;&emsp;[LightGBM: A Highly Efficient Gradient Boosting Decision Tree (2017)](https://papers.nips.cc/paper/6907-lightgbm-a-highly-efficient-gradient-boosting-decision-tree)        \n",
    "&emsp;&emsp;作者：Guolin Ke, Qi Meng, Thomas Finley, Taifeng Wang, Wei Chen, Weidong Ma, Qiwei Ye, Tie-Yan Liu      \n",
    "&emsp;&emsp;该论文是 LightGBM 的最初论文，详细阐述了 LightGBM 算法的设计思想、技术特点和实验结果。\n",
    "\n",
    "&emsp;&emsp;[Comparison between XGBoost, LightGBM and CatBoost using a home credit dataset (2019)](https://publications.waset.org/10009954/comparison-between-xgboost-lightgbm-and-catboost-using-a-home-credit-dataset)      \n",
    "&emsp;&emsp;作者：Essam Al Daoud      \n",
    "&emsp;&emsp;该论文详细对比了LGBM、XGB和CatB三个模型在信用卡数据上的性能差异，并提出了不同模型的超参数优化基本思路。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c52f1f-f593-4786-910b-e37a7c1dc6e4",
   "metadata": {},
   "source": [
    "在后续的LGBM算法原理讲解中，我们也将大量借鉴这些论文中的原理介绍相关内容和性能验证方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe59715f-708f-419a-a434-edac8e026a60",
   "metadata": {},
   "source": [
    "> 上述论文可通过点击课件中蓝色链接在线观看，或查看课件网盘中的PDF版本论文。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fef0b8-0dbe-4c60-a9d6-d7b902cdf254",
   "metadata": {},
   "source": [
    "- LightGBM官方文档与开源项目地址"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0309e5bc-22c0-45c3-9dcf-0122fbd83ad3",
   "metadata": {},
   "source": [
    "&emsp;&emsp;此外官方说明文档和Github项目说明也是必不可少的学习材料。对于LightGBM来说，论文中隐藏了大量细节，这些都需要我们通过查阅官方说明文档和项目源码来进行补充。因此在后续的教学过程中，我们也将大量参考或者回归到这些全文说明文档中进行讲解和介绍，具体地址如下："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52171d30-df4f-463c-97b9-2c662e338094",
   "metadata": {},
   "source": [
    "&emsp;&emsp;LightGBM的官方文档：https://lightgbm.readthedocs.io/en/v3.3.5/index.html\n",
    "\n",
    "&emsp;&emsp;LightGBM的GitHub地址：https://github.com/microsoft/LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4ef6a1-0cbf-4882-9a18-c26b9d0ba125",
   "metadata": {},
   "source": [
    "最后，需要导入本节课程需要用到的第三方库："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "416b8f25-a6b4-40d4-b4c9-2f34598eb338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 科学计算模块\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 绘图模块\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Scikit-Learn相关模块\n",
    "# 评估器类\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# 实用函数\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 数据准备\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9642a55-ccf3-487e-b2f0-078898fb402d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a70845-4aa1-481d-a580-4b8c35af791d",
   "metadata": {},
   "source": [
    "## <center>Ch.1 LightGBM基本原理与EFB降维方法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968ec67e-0c4f-4dc4-b0b1-01d79c9dde4d",
   "metadata": {},
   "source": [
    "- LightGBM原理简介"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19640c48-552a-45c9-b37c-9849547cdb0b",
   "metadata": {},
   "source": [
    "&emsp;&emsp;LightGBM（Light Gradient Boosting Machine，以下简称LGBM）是一个基于梯度提升决策树（Gradient Boosted Decision Trees，GBDT）的高效、可扩展的机器学习算法，作为GBDT框架的算法的一员，并且作为XGB算法的后来者，LGBM非常好综合了包括XGB在内的此前GBDT算法框架内各算法的一系列优势，并在此基础上做了一系列更进一步的优化。LGBM算法提出的核心目的是为了解决GBDT算法框架在处理海量数据时计算效率低下的问题，而从实践效果来看，LGBM也确实做到了这点——LGBM以牺牲极小的计算精度为代价，将GBDT的计算效率提升了近20倍！这也最终使得LGBM算法是第一个真正意义上能处理海量数据的GBDT框架算法。并且，尽管计算精度存在“选择性的牺牲”，但LGBM的实际建模效果也能达到几乎和XGB同等水平，而且由于LGBM“选择性的牺牲精度”从另一个角度来看其实就是抑制模型过拟合，因此在很多场景下，LGBM的算法效果甚至会好于XGB。种种实践证明，LGBM是一个拥有超高计算效率的同时、又能够保持超高精度的算法，是目前机器学习领域当之无愧的顶级算法之一。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d95f9d-01b1-44f7-93f2-6553737d584c",
   "metadata": {},
   "source": [
    "&emsp;&emsp;而LGBM是如何做效率和精度“两手抓”的呢？简而言之就是LGBM充分借鉴了XGB提出的一系列提升精度的优化策略，同时在此基础之上进一步提出了一系列的数据压缩和决策树建模流程的优化策略。尽管在算法的数学原理层面LGBM并没有翻越XGB创建的理论高峰，但其提出的一系列优化策略也同样是极具开创性的，其中数据压缩方法能够让实际训练的数据量在大幅压缩的同时仍然保持较为完整的信息，而决策树建模流程方面的优化，则是在XGB提出的直方图优化算法基础上进行了大幅优化，不仅能够加速决策树建模速度，同时也能非常好的处理经过压缩后的数据，从而最终大幅提升每棵树的训练效率（甚至在LGBM提出的一段时间后，新版XGB也采用了LGBM类似的直方图算法来加速建模效率）。并且最重要的是，有理论能够证明，哪怕LGBM实际建模是基于压缩后的数据进行训练，但其预测精度受到的影响也是微乎其微。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84e0787-9c38-4311-b4a4-d2882686fc15",
   "metadata": {},
   "source": [
    "&emsp;&emsp;当然，除了算法原理层面的优化方法外，LGBM还提出了非常多针对于实际计算过程的优化，例如Voting Parallel（投票特征并行）方法、特征多线程并行处理方法、GPU加速方法和分布式计算等，这些方法进一步提升了LGBM实际建模效率，并且一定程度拓宽了算法的使用场景。并且需要注意的是，所谓的计算效率优化，不仅体现在计算时间的大幅缩短，同时得益于LGBM所提出的一系列数据压缩技术，使得实际建模时数据内存占用也大幅减少。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d18543a-5568-4240-b923-818bb3a4626d",
   "metadata": {},
   "source": [
    "&emsp;&emsp;总的来说，LGBM算法可以看成是迭代过程几乎全盘借鉴XGB、而在数据压缩方法和决策树训练方法上有大量创新的算法，因此在原理相关内容我们将分为两部分进行讲解，第一部分我们重点介绍LGBM创新性提出的一系列方法，第二部分再来探讨LGBM损失函数求解流程。考虑到LGBM的推导流程和XGB几乎完全一样，原理部分的讲解的重点将会是LGBM创新性提出的一系列数据压缩和优化策略。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ec554e-e411-41bd-8578-a62414dabb5b",
   "metadata": {},
   "source": [
    "> XGB几乎可以说是GBDT类算法的原理层面的里程碑，开创性的提出了拟合二阶泰勒展开的思路，并据此设计了全套关键数学表达式，包括包含Hessian值得伪残差、分裂增益计算公式化和叶节点权重计算公式。而后继的LGBM和CatBoost，在损失函数求解过程几乎没有再提出超出XGB理论框架的内容，而是在数据预处理和决策树训练方法上提出了进一步优化方法。这点甚至也可以从LGBM原论文中看出，在LGBM原始论文中几乎没有任何关于损失函数求解的说明，通篇几乎都在强调数据压缩方法和决策树优化流程的有效性，我们也是通过查阅官方文档和源码才得知LGBM的具体迭代流程。因此，从这个角度来说，XGB是迄今为止GBDT类算法框架的理论最高峰。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc52670-22d2-46c4-b1e5-e17baa1721f7",
   "metadata": {},
   "source": [
    "- LightGBM的数据压缩策略"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40498615-21db-4b43-bfe2-94ad4b382a4e",
   "metadata": {},
   "source": [
    "&emsp;&emsp;LightGBM建模过程总共会进行三方面的数据压缩，根据实际建模顺序，会现在全样本上连续变量分箱（连续变量离散化），然后同时带入离散特征和离散后的连续变量进行离散特征捆绑（合并）降维，最终在每次构建一颗树之前进行样本下采样。其中连续变量的分箱就是非常简单的等宽分箱，并且具体箱体的数量可以通过超参数进行人工调节；而离散特征的降维，则是采用了一种所谓的互斥特征捆绑（Exclusive Feature Bundling, EFB）算法，该算法也是由LGBM首次提出，该方法的灵感来源于独热编码的逆向过程，通过把互斥的特征捆绑到一起来实现降维，这种方法能够很好的克服传统降维方法带来的信息大量损耗的问题，并且需要注意的是，输入EFB进行降维的特征，即包括原始离散特征，也包括第一阶段连续变量离散化之后的特征；在这一系列数据压缩之后，LGBM在每次迭代（也就是每次训练一颗决策树模型）的时候，还会围绕训练数据集进行下采样，此时的下采样不是简单的随机抽样，而是一种名为基于梯度的单边采样（Gradient-based One-Side Sampling, GOSS）的方法，和EFB类似，这种方法能够大幅压缩数据，但同时又不会导致信息的大量损失。不难发现，最终输入到每颗决策树进行训练的数据，实际上是经过大幅压缩后的数据，这也是LGBM计算高效的根本原因之一。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123a13cb-4a01-4eff-b599-2267761e5f52",
   "metadata": {},
   "source": [
    "- LightGBM决策树建模优化方法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7927b7fe-d6b1-4e65-812c-92a63b5eb693",
   "metadata": {},
   "source": [
    "&emsp;&emsp;而进入到具体的决策树训练环节，总的来说LGBM采用的决策树建模优化方法有两个，其一是直方图优化算法，这种方法本质上是通过直方图的形式更加高效简洁的表示每次分裂前后数据节点的核心信息，并且父节点和子节点也可以通过直方图减法计算直接算得，从而加速数据集分裂的计算过程:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7666c9f6-7cd4-47eb-9c2b-21f2a9f81346",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202303221537628.png\" alt=\"981861843f708f9efb5f74829c336b3\" style=\"zoom: 40%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6d7004-4467-4046-acf4-009fc18c203e",
   "metadata": {},
   "source": [
    "> 直方图优化算法看似简单，实际上计算过程非常复杂，后面我们会通过一个手写的例子来进行详细讲解。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bdf41e-0e91-4fa8-a496-5b73d9444dba",
   "metadata": {},
   "source": [
    "其二则是leaf wise tree growth的叶子节点优先的决策树生长策略，这其实是一种树生长的模式，对于其他大多数决策树算法和集成算法来说，树都是一次生长一层，也就是所谓的Level-wise tree growth（深度优先的生长策略），生长过程如下。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c6b54e-ca53-49b3-9cb0-1ea183ead753",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202303221541288.png\" alt=\"b4030247c4f8acaee3a8337bb6e7bb2\" style=\"zoom:50%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87813d45-1d45-4cf0-a599-4e95bcd54bea",
   "metadata": {},
   "source": [
    "而LGBM则允许决策树生长过程优先按照节点进行分裂，即允许决策树“有偏”的生长，也就是所谓的leaf wise tree growth的叶子节点优先的决策树生长策略，具体生长过程如下："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee99a3e-1c28-4fe4-b6e2-5b41ebd46665",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202303221543679.png\" alt=\"33f0d4c90d591b2577698a730d24dfc\" style=\"zoom:50%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86d015d-86e2-4e33-bca1-8f135d21ef7c",
   "metadata": {},
   "source": [
    "根据LGBM论文的论述，但从Level-wise tree growth远离层面，这种方法其实是有利有弊，其优势在于能够大幅提升每颗树的收敛速度，从总体来看相当于是提升了每次迭代效率；而问题则在于会每棵树的计算过程会变得更加复杂，并且存在一定的过拟合风险。不过对于LGBM来说，这些问题都能够被很好的克服，比如计算过程复杂的问题可以通过数据压缩来对冲，而过拟合风险则可以通过限制最大树深度来解决，因此总的来看Level-wise tree growth就是最适合LGBM的决策树生长策略。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68e91e0-7569-4fbf-9459-cacc0f01385d",
   "metadata": {},
   "source": [
    "&emsp;&emsp;接下来，我们就这些技术逐一来进行介绍，并借助一个精心设计的手动实现的例子，来串联起LGBM在进行Boosting迭代前的全部数据计算流程，借此深化大家对本部分内容的理解。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e8532c-a2ec-450a-b482-d819d414a11a",
   "metadata": {},
   "source": [
    "### 1.连续变量分箱"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bf2e13-a918-49fa-8c49-2ea0438dccda",
   "metadata": {},
   "source": [
    "- 等宽分箱基本概念回顾"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be91c374-591e-46f0-a617-71ac9beba492",
   "metadata": {},
   "source": [
    "&emsp;&emsp;首先是连续变量分箱。LGBM采用的连续变量分箱方法就是简单的等宽分箱，和我们在特征工程部份介绍的等宽分箱方法无异：首先计算连续变量的取值范围，然后人工输入的max_bin超参数，进行数量为max_bin等宽度的区间划分，并把连续变量的值划归到一个个箱体内部。例如某连续变量取值范围为[0, 10]，max_bin=2，则两个等宽的区间划分为bin0=[0, 5)和bin1=[5, 10]，并且如果某连续变量取值为1，则经过分箱后会被标记为bin0（或者0），如果某各连续变量取值为10，则分箱后会被标记为bin1（或者1）。至此，就将连续变量转化为了离散变量。具体手动实现过程和sklearn实现过程可以回顾特征工程Part 2中的内容介绍。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e664ec1b-084b-4dce-8813-230253e8f029",
   "metadata": {},
   "source": [
    "> 这里需要注意，XGB也会对连续变量进行分箱，但XGB的分箱是分位数分箱，而不是等宽分箱。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef39717-ac16-4b43-97d1-bb561d008d75",
   "metadata": {},
   "source": [
    "- 手动示例"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52f45e0-0772-47da-ac2f-0fb82cc5bdf6",
   "metadata": {},
   "source": [
    "&emsp;&emsp;接下来，我们通过一个手动实现的例子来说明这一过程，需要注意的是，这个手动创建数据集将贯穿本节的各部分内容。数据集基本情况如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "087d03a7-c1fb-4168-b291-008e6d02536f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.9</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.6</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.3</td>\n",
       "      <td>6.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.4</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.1</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.7</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    x1   x2  x3  x4  y\n",
       "0  1.2  4.7   1   0  1\n",
       "1  2.9  5.5   1   0  0\n",
       "2  2.6  3.9   0   1  1\n",
       "3  3.3  6.2   1   0  0\n",
       "4  2.0  3.5   1   0  1\n",
       "5  2.5  4.5   1   1  1\n",
       "6  1.4  5.1   1   0  0\n",
       "7  2.1  2.7   0   1  0\n",
       "8  1.7  4.1   1   0  1\n",
       "9  3.0  3.8   1   1  1"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(11)\n",
    "\n",
    "x1 = np.array([1.2, 2.9, 2.6, 3.3, 2.0, 2.5, 1.4, 2.1, 1.7, 3.0])\n",
    "x2 = np.array([4.7, 5.5, 3.9, 6.2, 3.5, 4.5, 5.1, 2.7, 4.1, 3.8])\n",
    "x3 = np.random.randint(0, 2, 10)\n",
    "x4 = np.random.randint(0, 2, 10)\n",
    "y = np.array([1, 0, 1, 0, 1, 1, 0, 0, 1, 1])\n",
    "data = pd.DataFrame({'x1':x1, 'x2':x2, 'x3':x3, 'x4':x4, 'y':y})\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee51c88-2968-4f8d-9cbc-8b1e30a89b47",
   "metadata": {},
   "source": [
    "数据集总共包含10条数据，其中x1和x2是连续特征，x3和x4是离散特征，y是标签，该数据集是各二分类数据集。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e824e9e-852d-40f6-996b-301702c7575e",
   "metadata": {},
   "source": [
    "&emsp;&emsp;接下来，我们对其中的连续变量进行分箱，这里我们设置max_bin=2，即进行两个箱体的等宽分箱。具体实现过程及分箱结果如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c8dc59fb-a1c4-4418-8184-4b8be9ba17cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    x1   x2  x3  x4  y  x1_binned  x2_binned\n",
      "0  1.2  4.7   1   0  1        0.0        1.0\n",
      "1  2.9  5.5   1   0  0        1.0        1.0\n",
      "2  2.6  3.9   0   1  1        1.0        0.0\n",
      "3  3.3  6.2   1   0  0        1.0        1.0\n",
      "4  2.0  3.5   1   0  1        0.0        0.0\n",
      "5  2.5  4.5   1   1  1        1.0        1.0\n",
      "6  1.4  5.1   1   0  0        0.0        1.0\n",
      "7  2.1  2.7   0   1  0        0.0        0.0\n",
      "8  1.7  4.1   1   0  1        0.0        0.0\n",
      "9  3.0  3.8   1   1  1        1.0        0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "# 将 x1 和 x2 分别进行等宽分箱，分成 2 个箱子\n",
    "n_bins = 2\n",
    "strategy = 'uniform'\n",
    "\n",
    "kbins_x1 = KBinsDiscretizer(n_bins=n_bins, encode='ordinal', strategy=strategy)\n",
    "kbins_x2 = KBinsDiscretizer(n_bins=n_bins, encode='ordinal', strategy=strategy)\n",
    "\n",
    "x1_binned = kbins_x1.fit_transform(data['x1'].values.reshape(-1, 1))\n",
    "x2_binned = kbins_x2.fit_transform(data['x2'].values.reshape(-1, 1))\n",
    "\n",
    "# 将分箱后的结果保存到原始数据集中\n",
    "data['x1_binned'] = x1_binned\n",
    "data['x2_binned'] = x2_binned\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a83aef-7ef1-49d0-b098-2f289eace412",
   "metadata": {},
   "source": [
    "至此，我们就完成了LGBM的第一阶段数据处理——连续变量的分箱处理。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f24bef-1c07-48eb-9b60-8ff15b40238c",
   "metadata": {},
   "source": [
    "### 2.互斥特征捆绑（Exclusive Feature Bundling，EFB）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbb21d7-69b3-41ff-9eab-78cc0fac43da",
   "metadata": {},
   "source": [
    "&emsp;&emsp;接下来则是围绕这些离散特征进行降维。LGBM采用了一种名为互斥特征捆绑（Exclusive Feature Bundling，EFB）的降维方法，这种方法在LGBM论文LightGBM: A Highly Efficient Gradient Boosting Decision Tree (2017)中首次提出，不同于第一阶段的简单的等宽分箱，EFB实际计算过程非常复杂，我们这里从EFB方法提出背景、计算原理和手动示例三个方面对其进行介绍。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d827d9-b157-4a71-bc81-77b0989395ed",
   "metadata": {},
   "source": [
    "#### 2.1 EFB算法简介与基本流程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48b8a48-82f9-49bb-8b43-21ae4fa2fcec",
   "metadata": {},
   "source": [
    "- EFB算法提出背景"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8691c947-e0b6-4d63-a09b-a86c98e204b9",
   "metadata": {},
   "source": [
    "&emsp;&emsp;根据LightGBM: A Highly Efficient Gradient Boosting Decision Tree (2017)论文描述，原始的GBDT在进行每颗树的训练时，需要带入全部数据来进行信息增益的计算，从而寻找到决策树生长过程中的最佳切分点，这个过程也就是所谓的扫描全部数据来决定切分点的过程。这个过程尽管非常精准，但计算复杂度非常高（直接和特征数量及样本数量成正比），在进行海量数据建模训练的时候会耗费大量的算力和时间。因此，为了能够更好的应对海量数据的模型训练，样本采样和特征降维是非常必要的。但传统的方法在这方面往往效果不佳，例如简单的欠采样（样本随机抽样）可能会造成模型训练过程非常不稳定，而PCA降维则只适用于处理冗余特征，当每个特征都具有相当信息体量时强行进行降维则会导致信息大量丢失。为了解决这个问题，LGBM开创性的提出了基于梯度的单边采样方法（GOSS）进行样本数量的压缩，提出了互斥特征捆绑方法（EFB）来进行特征压缩。不同于以往的方法，GOSS和EFB能够非常好的兼顾预测精度与计算效率。此外，对连续变量进行离散化也是非常有效的数据压缩的手段，LGBM在XGB提出的直方图优化的基础上，进一步提出了一种改进策略，和GOSS和EFB类似，这种LGBM直方图优化方法同样能够在大幅提高计算效率的同时保证预测精度。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3115801-253d-4ac1-a9b6-dfad9afb9c14",
   "metadata": {},
   "source": [
    "- 简化后的EFB计算流程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2d0aab-ade4-4695-b13d-26ab17841083",
   "metadata": {},
   "source": [
    "&emsp;&emsp;而具体到EFB降维算法，其实是受到独热编码启发，设计的类似于独热编码逆向过程的一种算法。例如一组数据情况如下，独热编码是从左往右的计算过程，把一列展开为多列，而EFB则是从右往左进行计算，将多列压缩为一列："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ba36dc-c4f7-4a51-b50c-1d107e6ad7a7",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202303222002280.png\" alt=\"0be767e9953d7db2a66752f524e6ba4\" style=\"zoom:50%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2e9ebd-392e-4d63-9833-bf89fab2d51e",
   "metadata": {},
   "source": [
    "> 具体独热编码的相关内容，可回顾特征工程Part 2数据重编码部分内容。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3dccad-9d97-4fb9-8a75-32eb47c14f7a",
   "metadata": {},
   "source": [
    "&emsp;&emsp;那既然是独热编码的逆向计算，我们就需要首先讨论为什么LGBM不需要独热编码。我们知道，独热编码本质上是对离散特征更加细粒度的信息呈现，在某些场景下能够提升模型效果。当然更重要的是独热编码能够非常好的用于表示离散变量，对于大多数无法区分连续变量和离散变量的机器学习算法来说，通过独热编码重编码的数据将能够非常方便进行例如离散变量之间的距离计算等操作。但是这些独热编码的优势对于LGBM来说并不存在。首先LGBM带入模型计算的全部变量都是离散变量（连续变量也会被离散化），其次独热编码带来的更细粒度的信息呈现也不会进一步提升模型效果（对于大多数集成学习算法来说都是如此），当然更重要的是，LGBM的算法设计就是为了处理海量高维数据，独热编码只会进一步造成维度灾难。因此，LGBM不仅不需要进行独热编码，还需要进行独热编码的逆操作来进行特征降维。当然，我们这里只是借用独热编码的计算过程帮大家理解EFB的降维过程，在实际计算过程中，EFB的降维的目标并不是把独热编码之后的特征再转换回来，而是找到那些原始状态下就存在类似上图中x1和x2这种关系的特征，来将其合成为一个特征。这里我们注意观察，上图中x1和x2两个特征存在一种这样的关系——任何一条样本都不会同时在x1和x2上取值非0，在EFB原理的定义中，这种关系的特征又被称作互斥特征，而互斥特征其实是可以合成一个特征的，比如上图中的x，这个合成的过程并不会有任何的信息损失，而合成的过程又被称作特征捆绑。这也就是所谓的互斥特征捆绑算法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e07711-2180-4c9a-94e1-3db64f5c1a99",
   "metadata": {},
   "source": [
    "&emsp;&emsp;我们这里再看一个互斥特征捆绑的例子，比如如下x3和x4，也是互斥的，此时我们可以将x3和x4捆绑为一个新的x_b1特征，新特征中可以用0、1、2来表示x3和x4的不同组合，从而在不损失信息的情况下，进行了降维。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392d5ce3-bec3-40bc-a3b3-197b9656d542",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202303222003609.png\" alt=\"6a6d2ee962754f94b7232cb069835ce\" style=\"zoom:50%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af046e91-2a61-44c7-aba5-23eed08dcb01",
   "metadata": {},
   "source": [
    "&emsp;&emsp;当然，这只是一个简化后的示例，真实的EFB特征降维情况会非常复杂，并不是简单的将多个离散变量的不同取值组合进行重新赋值，这个例子只是用于帮大家建立对EFB的感性的认识，接下来我们就围绕原论文中提出的EFB算法来进行更加严谨的算法流程介绍。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65bdb8e-70bc-436b-b5f5-c4c4ecc28ebe",
   "metadata": {},
   "source": [
    "#### 2.2 EFB算法基本原理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89667e54-957d-4be4-8c05-e95c87931ff4",
   "metadata": {},
   "source": [
    "- 放宽互斥的条件：冲突比例（conflict_rate）概念介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65804eaa-dd0d-4ddd-8dd3-0375062f618b",
   "metadata": {},
   "source": [
    "&emsp;&emsp;真实数据的EFB计算过程会非常复杂，首先是关于“互斥”关系的定义，EFB并不是只压缩完全互斥的特征，而是非常灵活的定义了一个冲突比例（又称非互斥比例），这个比例用于表示两个特征中冲突（即非互斥、同时取非零值）的取值占比，来衡量两个特征互斥程度。当然，冲突比例越大说明互斥程度越低。例如对于如下数据集，总共包含四条数据，其中只有第四条数据是同时取得了非零值，因此只有一条数据是冲突的，其他数据都是互斥的，因此冲突比例为1/4=0.25："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d49845-0c4d-44a9-85db-2764ce836a59",
   "metadata": {},
   "source": [
    "|特征1|特征2|      \n",
    "|:--:|:--:|\n",
    "|0|1|\n",
    "|1|0|\n",
    "|0|0|\n",
    "|1|1|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9254b1c5-57ad-4e1a-9575-38b24f7c9987",
   "metadata": {},
   "source": [
    "同时，LGBM提供了一个名为max_conflict_rate的超参数，用于表示最大冲突比例，当两个特征的冲突比例小于我们设置的最大冲突比例（max_conflict_rate）时，我们就认为这两个特征并不冲突，而是互斥的，是可以进行捆绑的。例如假设我们设置max_conflict_rate=0.3，则上述两个特征可以进行捆绑，而如果我们设置max_conflict_rate=0.2，则上面两个特征超过了我们认为冲突的阈值，因此这两个特征是冲突的，而不是互斥的，是不能进行进一步捆绑的。很明显，max_conflict_rate设置的越小，对互斥的要求就越高，特征就越不容易被捆绑，模型计算量就越大、精度也越高，而如果max_conflict_rate设置的很大，则更多的特征会被捆绑，模型计算速度会更快，但精度也会降低。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27bbb314-fbac-46af-9e02-00a685356736",
   "metadata": {},
   "source": [
    "- 借助图着色(Graph Coloring Problem)问题来解决特征捆绑流程问题"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee66484d-bf24-43eb-97a3-252e952ebd14",
   "metadata": {},
   "source": [
    "&emsp;&emsp;通过最大冲突比例的概念引入，相当于是放宽的互斥的条件，或者说给是否互斥添加了一个可以量化计算的阈值。而真正开始进行特征捆绑的时候，面对海量特征，LGBM是如何进行EFB计算的呢？实际上LGBM会将特征捆绑问题视作（或者说是转化为）一个图着色的问题(Graph Coloring Problem)。图着色问题一种经典的组合优化问题，其问题描述为：给定一个无向图，如何用尽量少的颜色对图中的每个顶点进行着色，使得相邻的顶点颜色不同。这里的“颜色”可以是任意一种符号或编号，只要保证相邻的顶点颜色不同即可。在EFB计算过程中，会将不同特征视作图上的一个个点，若特征之间存在冲突，则用一条无向边进行连接，边的权重就是冲突比例，而如果两个特征互斥，则彼此没有边进行相连。而在将特征及其冲突情况用图进行展示后，即可进一步进行图着色——即在相邻的点颜色不同的前提条件下，用尽可能少的颜色对图上的点进行着色，既然相互冲突的特征都有边进行相连，那么相同颜色的点其实就是互斥的特征，接下来我们仅需把相同颜色的特征进行合并即可。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fadde0d-2fcd-4d6c-854d-76fbc9a1742e",
   "metadata": {},
   "source": [
    "&emsp;&emsp;当然，这个过程听起来较为抽象，我们这里还是以上面的data数据集为例，来展示一个借助图着色来进行特征捆绑的完整过程。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59464c5-aa71-4192-87d7-893eada7a46a",
   "metadata": {},
   "source": [
    "#### 2.3 EFB算法计算流程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379117b4-555e-4ea7-86e0-faebe135fcad",
   "metadata": {},
   "source": [
    "- 计算冲突比例矩阵"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45438039-5832-41ae-b709-6aa016db5e01",
   "metadata": {},
   "source": [
    "&emsp;&emsp;经过连续变量离散化，现在我们的data数据就已经变成了四个离散特征的数据集，四个离散特征分别为：'x1_binned'、'x2_binned'、'x3'、'x4'："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3b93edc0-3042-482c-b63c-8d1d13757329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>y</th>\n",
       "      <th>x1_binned</th>\n",
       "      <th>x2_binned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.9</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.6</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.3</td>\n",
       "      <td>6.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.4</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.1</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.7</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    x1   x2  x3  x4  y  x1_binned  x2_binned\n",
       "0  1.2  4.7   1   0  1        0.0        1.0\n",
       "1  2.9  5.5   1   0  0        1.0        1.0\n",
       "2  2.6  3.9   0   1  1        1.0        0.0\n",
       "3  3.3  6.2   1   0  0        1.0        1.0\n",
       "4  2.0  3.5   1   0  1        0.0        0.0\n",
       "5  2.5  4.5   1   1  1        1.0        1.0\n",
       "6  1.4  5.1   1   0  0        0.0        1.0\n",
       "7  2.1  2.7   0   1  0        0.0        0.0\n",
       "8  1.7  4.1   1   0  1        0.0        0.0\n",
       "9  3.0  3.8   1   1  1        1.0        0.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e91afaba-f1d3-4d27-8462-f9a312105df8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1_binned</th>\n",
       "      <th>x2_binned</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x1_binned  x2_binned  x3  x4\n",
       "0        0.0        1.0   1   0\n",
       "1        1.0        1.0   1   0\n",
       "2        1.0        0.0   0   1\n",
       "3        1.0        1.0   1   0\n",
       "4        0.0        0.0   1   0\n",
       "5        1.0        1.0   1   1\n",
       "6        0.0        1.0   1   0\n",
       "7        0.0        0.0   0   1\n",
       "8        0.0        0.0   1   0\n",
       "9        1.0        0.0   1   1"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['x1_binned', 'x2_binned', 'x3', 'x4']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ffe0fc-b3dd-4939-8fb5-5d9bb6e3b22b",
   "metadata": {},
   "source": [
    "然后我们需要计算这四个特征彼此之间的冲突比例，我们可以通过定义如下函数来完成计算。该函数定义了多个特征彼此之间冲突比例矩阵的计算过程，这里的冲突比例矩阵就类似于相关系数矩阵，用于表示多个特征彼此之间冲突比例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2238f897-fe93-4aef-b10a-aa7829505355",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conflict_ratio_matrix(data):\n",
    "    \"\"\"\n",
    "    冲突比例计算函数\n",
    "    \n",
    "    :param data: 计算冲突比例的dataframe\n",
    "    :return:冲突比例矩阵\n",
    "    \"\"\"\n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        data = data.values\n",
    "\n",
    "    num_features = data.shape[1]\n",
    "    # 创建空特征比例矩阵\n",
    "    conflict_matrix = np.zeros((num_features, num_features))\n",
    "\n",
    "    # 两层循环挑选两个特征\n",
    "    for i in range(num_features):\n",
    "        for j in range(i+1, num_features):\n",
    "            # 计算特征冲突特征总数\n",
    "            conflict_count = np.sum((data[:, i] != 0) & (data[:, j] != 0))\n",
    "            # 计算不为0的特征总数\n",
    "            total_count = np.sum((data[:, i] != 0) | (data[:, j] != 0))\n",
    "            # 计算冲突比例\n",
    "            conflict_ratio = conflict_count / total_count\n",
    "            conflict_matrix[i, j] = conflict_ratio\n",
    "            conflict_matrix[j, i] = conflict_ratio\n",
    "\n",
    "    return conflict_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6505b525-fb23-4c1f-9cae-370241b64907",
   "metadata": {},
   "source": [
    "然后尝试带入四个离散变量，进行冲突比例的计算："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9305dd99-f173-419e-84bd-018ac2b48df6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.42857143, 0.44444444, 0.5       ],\n",
       "       [0.42857143, 0.        , 0.625     , 0.125     ],\n",
       "       [0.44444444, 0.625     , 0.        , 0.2       ],\n",
       "       [0.5       , 0.125     , 0.2       , 0.        ]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conflict_ratio_matrix(data[['x1_binned', 'x2_binned', 'x3', 'x4']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef14c9b-ad1a-470b-a3e4-569fe965998c",
   "metadata": {},
   "source": [
    "其中，矩阵中的第(i, j)个元素代表第i个特征和第j个特征的冲突比例，例如(1, 2)=0.42857表示第一个特征和第二个特征冲突比例为0.42857。能够看出，这四个特征中并不存在没有冲突（即互斥）的特征，只能看到2、4和3、4特征冲突比例较小："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "792490e7-a1df-4a90-8fd8-b0cdc9a017e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1_binned</th>\n",
       "      <th>x2_binned</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x1_binned  x2_binned  x3  x4\n",
       "0        0.0        1.0   1   0\n",
       "1        1.0        1.0   1   0\n",
       "2        1.0        0.0   0   1\n",
       "3        1.0        1.0   1   0\n",
       "4        0.0        0.0   1   0\n",
       "5        1.0        1.0   1   1\n",
       "6        0.0        1.0   1   0\n",
       "7        0.0        0.0   0   1\n",
       "8        0.0        0.0   1   0\n",
       "9        1.0        0.0   1   1"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['x1_binned', 'x2_binned', 'x3', 'x4']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5edcb40-ba26-4b9d-a128-7eac9ddbfb8c",
   "metadata": {},
   "source": [
    "- 图展示与着色"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdfad6a-14fd-4c0e-80ff-66ab06027950",
   "metadata": {},
   "source": [
    "&emsp;&emsp;然后我们将冲突比例矩阵转化为如下所示的图，即不同的点代表着不同的特征，而如果两个特征存在冲突，则两个点之间构建一条无向边，边的权重就是冲突比例："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4257986e-1965-41cb-8fcd-09bf02eb7461",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202303231529895.png\" alt=\"1679556539065\" style=\"zoom:50%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb341c7-3a13-45b2-a05f-1e5c57d3dfdc",
   "metadata": {},
   "source": [
    "当然，关于是否互斥，其实可以通过max_conflict_rate进行调节，我们假设max_conflict_rate=0.3，则上图中x3和x4、x2_binned和x4的冲突比例小于0.3，所以这两组特征是互斥的，我们可以将连接这两组特征的边删除，删除后的图如下："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76f9071-1d40-45c6-8756-7a4f5bbf0247",
   "metadata": {},
   "source": [
    "> 这里需要注意，这里我们设置的max_conflict_rate=0.3只是用于当前例子展示所用。真实情况下max_conflict_rate的取值建议设置为0.1或者更小的数，以确保模型精度。相关超参数取值推荐会在本章课程的最后进行讨论。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9a41a1-b0c9-4220-a6a8-f41c2a6fff25",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202303231538803.png\" alt=\"1679557086174\" style=\"zoom:50%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ed25b0-e328-4c89-b80b-0043b3b93a95",
   "metadata": {},
   "source": [
    "在完成图转化之后，接下来我们将特征捆绑问题视作一个图着色的问题，即需要用最少的颜色对图上的四个点进行着色，并要求相邻的点（彼此有线段连接的点）颜色不同。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39241a0-1398-4db2-a0b4-52f410b08b54",
   "metadata": {},
   "source": [
    "&emsp;&emsp;具体着色的流程是会先从度（边的个数，也被成为degree）更大的点进行着色，例如上图中的四个点的degree如图所示，很明显x1_binned的度最大，然后是x2_binned和x3，这里我们先将x1_binned着色为红色（颜色可以随机选取），然后由于x3和x2_binned彼此相连，并且都和x1_binned相连，因此x3和x2_binned颜色不能相同，且不能和x1_binned相同，因此这里分别给x3和x2_binned着色为黄色和绿色，最后是x4，由于x4和x1_binned相连，所以x4不能用红色，而x4和x3、x2_binned没有相连，并且为了图上出现的颜色尽可能少，所以x4可以用绿色或者黄色，考虑到x4和x2_binned冲突比例较小，互斥程度较大，因此可以给x4使用绿色，最后着色结果如上图所示。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca7e78c-dd46-4098-a790-2646e3d641e3",
   "metadata": {},
   "source": [
    "- 特征捆绑过程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5aa289-beea-41cf-abd4-90f1494ab974",
   "metadata": {},
   "source": [
    "&emsp;&emsp;最后，我们把相同着色的点（特征）进行捆绑。捆绑过程并不复杂，核心是需要对特征取值进行合理转化。而具体的转化过程中，LGBM会根据主特征的最大取值设置一个offset值，然后对合并进来特征的非零值加上这个offset值，然后再让这两个特征取值相加。例如data数据集中，我们将x4并入x2_binned中，则offset=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b173c9a7-4a20-462f-b406-0a3e57d77a6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.0\n",
       "1    1.0\n",
       "2    0.0\n",
       "3    1.0\n",
       "4    0.0\n",
       "5    1.0\n",
       "6    1.0\n",
       "7    0.0\n",
       "8    0.0\n",
       "9    0.0\n",
       "Name: x2_binned, dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['x2_binned']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650bb0f8-2319-4de4-b10d-0b92aa6fcdfe",
   "metadata": {},
   "source": [
    "然后对x4的非零值+offset，并构成新的特征'x2_binned&x4'具体计算过程如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f74bfff9-e7d8-42ae-ac29-9cf717768de7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 2, 0, 0, 2, 0, 2, 0, 2])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.array(data['x4'])\n",
    "arr[arr != 0] += 1\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "26c00382-4583-447f-8b05-c5505e551003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>y</th>\n",
       "      <th>x1_binned</th>\n",
       "      <th>x2_binned</th>\n",
       "      <th>x2_binned&amp;x4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.9</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.6</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.3</td>\n",
       "      <td>6.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.4</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.1</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.7</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    x1   x2  x3  x4  y  x1_binned  x2_binned  x2_binned&x4\n",
       "0  1.2  4.7   1   0  1        0.0        1.0           1.0\n",
       "1  2.9  5.5   1   0  0        1.0        1.0           1.0\n",
       "2  2.6  3.9   0   1  1        1.0        0.0           2.0\n",
       "3  3.3  6.2   1   0  0        1.0        1.0           1.0\n",
       "4  2.0  3.5   1   0  1        0.0        0.0           0.0\n",
       "5  2.5  4.5   1   1  1        1.0        1.0           3.0\n",
       "6  1.4  5.1   1   0  0        0.0        1.0           1.0\n",
       "7  2.1  2.7   0   1  0        0.0        0.0           2.0\n",
       "8  1.7  4.1   1   0  1        0.0        0.0           0.0\n",
       "9  3.0  3.8   1   1  1        1.0        0.0           2.0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['x2_binned&x4'] = arr + data['x2_binned']\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bb59ee-05b9-491e-89fe-e1b7a07724dc",
   "metadata": {},
   "source": [
    "至此，我们就在data这个简化的数据集上完成了EFB特征捆绑过程，经过连续变量分箱和特征捆绑，实际上接下来带入进行模型训练的特征就只有x1_binned、x2_binned&x4和x3这三个特征："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "628beb2a-3202-47ea-9652-c0ace241866c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1_binned</th>\n",
       "      <th>x2_binned&amp;x4</th>\n",
       "      <th>x3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x1_binned  x2_binned&x4  x3\n",
       "0        0.0           1.0   1\n",
       "1        1.0           1.0   1\n",
       "2        1.0           2.0   0\n",
       "3        1.0           1.0   1\n",
       "4        0.0           0.0   1\n",
       "5        1.0           3.0   1\n",
       "6        0.0           1.0   1\n",
       "7        0.0           2.0   0\n",
       "8        0.0           0.0   1\n",
       "9        1.0           2.0   1"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['x1_binned', 'x2_binned&x4', 'x3']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e882f2f9-06c1-4b7a-a2a6-b37dfab6fd1b",
   "metadata": {},
   "source": [
    "为了方便我们后续调用，我们将data进行本地保存："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "938f1150-f320-4db8-be62-8e34dc77affb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a8d925-af35-493a-8d39-1cb010da781f",
   "metadata": {},
   "source": [
    "&emsp;&emsp;至此，我们就完整介绍了LGBM算法在建模前的特征压缩部分算法的原理及其实践过程。下一小节我们将继续介绍每次建树前的GOSS采样、LGBM决策树训练方法与直方图优化算法。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
